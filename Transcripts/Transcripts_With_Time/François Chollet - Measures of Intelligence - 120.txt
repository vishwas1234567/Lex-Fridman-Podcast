0:00:00
Speaker 0 :the following is a conversation with
 francois chalet his second time in the podcast he's botha world-class engineer
 and a philosopher in the realm of deep learning and artificial intelligencethis time we talk a lot about his paper
 titled on the measure of intelligence that discusses how we might define andmeasure
 general intelligence in our computing machineryquick summary of the sponsors babel
 masterclass and cash app click the sponsor links inthe description to get a discount and
 to support this podcast as a side note let me say that the seriousrigorous scientific study of artificial
 general intelligence is a rare thing the mainstream machinelearning community works on
 very narrow ai with very narrow benchmarksthis is very good for incremental and
 sometimes big incremental progress on the otherhand
 the outside the mainstream renegade you could sayagi community works on approaches that
 verge on the philosophical and even the literarywithout big public benchmarks walking
 the line between the two worlds is a rare breedbut it doesn't have to be i ran the agi
 series at mit as an attempt to inspire more people to walk this linedeep mind and open ai for time and still
 on occasion walk this line francois choledoes as well i hope to also
 it's a beautiful dream to work towards and to make realone day if you enjoy this thing
 subscribe on youtube review it with five stars on applepodcast follow on spotify
 support on patreon or connect with me on twitter at lex friedmanas usual i'll do a few minutes of ads
 now and no ads in the middle i try to make these interesting but igive you time stamps so
 you can skip but still please do check out the sponsors by clicking the linksin the description
 it's the best way to support this podcastthis show is sponsored by babel an app
 and website that gets you speaking in a new language within weeksgo to babble.com and use colex to get
 three months free they offer 14 languages includingspanish french italian german
 and yes russian daily lessons are 10 to 15 minutessuper easy effective designed by over
 100 language experts let me read a few lines from the russianpoem
 by alexander bloch that you'll start to understand if you sign up to babbleno it's
 now i say that you'll start to understand this poembecause russian starts with a language
 and ends with the vodka now the latter partis definitely not endorsed
 or provided by babel it will probably lose me this sponsorshipalthough it hasn't yet but once you
 graduate with babel you can roll my advanced course of latenight russian conversation over vodka
 no app for that yet so get started by visiting babel.comand use codelex to get three months free
 this show is also sponsored by masterclass sign upat masterclass.com lex to get a discount
 and to support this podcast when i first heard about masterclass ithought it was too good to be true
 i still think it's too good to be true for 180a year you get an all-access pass to
 watch courses from to list some of my favorites chrishadfield on space exploration
 hope to have him in this podcast one day neil degrasse tyson on scientificthinking communication
 neil two will wright creator of simcity and sims on game design carlos santanaon guitar
 carrie casparov von chasse daniel negrano and poker and many morechris hadfield explaining how rockets
 work and the experience of being launched at the space alone is worth themoney
 by the way you can watch it on basically any deviceonce again sign up at masterclass.com
 lex to get a discount and to support this podcast this showfinally is presented by
 cash app the number one finance app in the app storewhen you get it use code lex podcast
 cash app lets you send money to friends buy bitcoin and invest in the stockmarket with as little as one dollar
 since cash app allows you to send and receive money digitallylet me mention a surprising fact related
 to physical money of all the currency in the world roughlyeight percent of it
 is actually physical money the other 92 percent of the money only existsdigitally
 and that's only going to increase so againif you get cash out from the app store
 google play and use code lex podcast you get ten bucks and cashapp will also donate ten dollars to
 first an organization that is helping toadvance robotics and stem education
 for young people around the world and now here's my conversationwith francois chalet what philosophers
 thinkers or ideas had a big impact on you growing up

0:05:10
Speaker 1 :and today so one
 author that had a big impact on me when i readthese books as a teenager with jean
 pierre who is a swiss psychologist is consideredto be the father of developmental
 psychology and he has a large body of work aboutum basically how intelligence develops
 uh in children and so it's really old work like most of it is from the 1930s1940s
 so it's not quite up to date it's actually superseded by manyneural developments in developmental
 psychology but to me it was it was very uh very interesting verystriking and actually shaped
 the early ways in which i started thinking about the mindand development of intelligence as a


0:05:55
Speaker 0 :teenager his actual ideas or the way he
 thought about it or just the fact that you could think about the developingmind at all


0:06:01
Speaker 1 :i guess both jean-pierre is the author
 that's reintroduced me to the notion that intelligence and the mind issomething that you construct
 through throughout your life and that you the childrenuh construct it in stages and i thought
 that was a very interesting idea which is you know of course very relevantuh to ai to building artificial minds
 another book that i read around the same time that had a big impact on meuh and and there was actually a little
 bit of overlap with john pierre as well and i read it around the sametime is jeff hawkins on
 intelligence which is a classic and he has this visionof the mind as a multi-scale hierarchy
 of temporal prediction modules and these ideas really resonated with melike the the notion of a modular
 hierarchy um of you know potentially umof compression functions or prediction
 functions i thought it was really reallyinteresting and it reshaped
 uh the way it started thinking about how to build

0:07:09
Speaker 0 :minds the hierarchical nature
 the which aspect also he's a neuroscientist so he was thinking yesactual he's basically talking about how


0:07:19
Speaker 1 :our mind works yeah the notion that
 cognition is prediction was an idea that was kind of new to meat the time and that i really loved at
 the time and yeah and the notion that yeah thereare multiple scales of processing


0:07:34
Speaker 0 :uh in the brain the hierarchy
 yes this is before deep learning these

0:07:38
Speaker 1 :ideas of hierarchies
 in here i've been around for a long time even before on intelligence i meanthey've been around since the
 1980s um and yeah that was before deep learning but of coursei think these ideas really found their
 practical implementation in deep learning what about the memory side of

0:07:58
Speaker 0 :things
 i think he's talking about knowledge representationdo you think about memory a lot one way
 you can think of neural networks as a kind of memory you're memorizingthings
 but it doesn't seem to be the kind of memory that's in ourbrains or it doesn't have the same rich
 complexity long-term nature that's in our brains

0:08:20
Speaker 1 :yes the brain is more for sparse access
 memory so that you can actually retrieve um very precisely like bits of yourexperience


0:08:29
Speaker 0 :the retrieval aspect you can like
 introspect you can ask yourself questions again yes

0:08:35
Speaker 1 :you can program your own memory and
 language is actually the tool you used to do that i thinklanguage is a kind of
 operating system for the mind and use languagewell one of the uses of language is as
 a query that you run over your own memory usewords as keys to retrieve specific
 experiences of basic concepts specific startslike language is the way you store
 thoughts not just in writing in the in the physical world but also in your ownmind
 and it's also how you reach with them like imagine if you didn't have languagethen you would have to you would not
 have really have a self internally triggered uh way ofretrieving
 past thoughts you would have to rely on external experiencesfor instance you you see a specific site
 you smell specific smell and it brings up memoriesbut you would naturally have a way to
 deliberately deliberately access these memories

0:09:32
Speaker 0 :without language well the interesting
 thing you mentioned is you can also programthe memory you can change it probably


0:09:39
Speaker 1 :with language yeah using language yes


0:09:41
Speaker 0 :well
 let me ask you a chomsky question which is likefirst of all do you think language is
 like fundamental like uh there's turtleswhat's at the bottom of the turtles they
 don't go it can't be turtles all the way downis language at the bottom of cognition
 of everything is like language the fundamentalaspect of like what it means to be


0:10:09
Speaker 1 :a thinking thing no i don't think so
 i think language you disagree with noam

0:10:13
Speaker 0 :

0:10:13
Speaker 1 :chomsky yes
 language is a layer on top of cognition soit is fundamental to cognition in the
 sense that to to use a computing metaphor i seelanguage as
 the operating system uh of the brain of the human mindyeah and the operating system you know
 is a layer on top of the computer the computer exists before the operatingsystem but the operating system is how
 you make it truly useful

0:10:39
Speaker 0 :and the operating system is most likely
 windows not not linux because it's uh language is

0:10:45
Speaker 1 :messy
 yeah it's messy and it's uh it's um pretty difficult to uhuh inspect it introspect it how do you


0:10:53
Speaker 0 :think about language
 like we use actually sort of human interpretable language but is theresomething like
 a deeper that's closer to like like logical type of statements umlike yeah what is the nature of
 language do you think because there's something deeper than like the syntacticrules we construct is there something
 that doesn't require utterances or

0:11:25
Speaker 1 :writing or so on are you asking about
 the possibility that there could exist uh languages for thinking that are notmade of words
 yeah yeah i think so i think so uh the mind is layers right and languageis almost like the
 the outermost the uppermost layer um but before we think in words i thinkwe think
 in in terms of emotion in space and we think in terms of physicalactions
 and i think a baby babies in particular probably express his thoughts in termsof
 um the actions uh that they've seen of that or that they can performand in terms of the in in terms of
 motions of objects in their environment before they start thinking in terms of

0:12:10
Speaker 0 :words it's amazing to
 think about that as the building blocks of language so like the kind ofactions and
 ways the babies see the world as like more fundamental than thebeautiful shakespearean language you
 construct on top of it and we we probably don't have any ideawhat that looks like right
 like what because it's important for them trying toengineer it into ai systems


0:12:37
Speaker 1 :i think visual analogies and motion
 is a fundamental building block of the mind and youyou actually see it reflected in
 language like language is full of special metaphors and when you thinkabout things
 i consider myself very much as a visual thinkeryou you often express your thoughts
 um by using things like uh visualizing concepts umin in 2d space or like you solve
 problems by image imagining yourself navigating a conceptspace i don't know if you have this sort
 of experience

0:13:17
Speaker 0 :you said visualizing concept space so
 like so i certainly think about

0:13:22
Speaker 1 :

0:13:24
Speaker 0 :i certainly met i certainly visualize
 mathematical concepts but you mean like in concept spacevisually you're embedding ideas into
 some into a three-dimensional space you canexplore with your mind essentially


0:13:38
Speaker 1 :

0:13:40
Speaker 0 :yeah 2d you're a flatlander
 you're um okay no i i i do not i always have to uh beforei jump from concept to concept i have to
 put it back down on pape and it has to be on paper i can onlytravel
 on 2d paper not inside my mind you're able to move inside your mind but

0:14:04
Speaker 1 :even if you're writing
 like a paper for instance don't you have like a special representation of yourpaper
 like you you visualize where ideas lie topologically in relationship to otherideas
 kind of like a subway map of the ideas in your paper

0:14:22
Speaker 0 :yeah that's true i mean there there is
 uh in papers i don't know about you butthere feels like there's a destination
 um there's a there's a key idea that you want to arrive at and alot of it is in
 in the fog and you're trying to kind of it's almost like umwhat's that called when um you do a path
 planning search from both directions from the start and from the endbut and then you find you do like
 shortest path but like uh you know in game playing you do thiswith like a star


0:15:00
Speaker 1 :from both sides when you see where they


0:15:02
Speaker 0 :join
 yeah so you kind of do at least for me i think likefirst of all just exploring from the
 start from like uh first principles what do i know uh whatcan i
 start proving from that right and then from the destinationif i you start backtracking like
 if if i want to show some kind of sets of ideaswhat would it take to show them and you
 kind of backtrack but yeah i don't think i'm doing all that inmy mind though like i'm putting it down
 on paper

0:15:32
Speaker 1 :do you use mind maps to organize your
 ideas yeah i like mind maps

0:15:37
Speaker 0 :let's get into this i've been so jealous
 of people i haven't really tried it i've been jealous ofpeople that seem to like they get like
 this fire of passion in their eyes because everything starts making senseit's like uh tom cruise in the movie was
 like moving stuff around some of the most brilliant people i knowuse mind maps i haven't tried
 really can you explain what the hell a mind map is

0:16:01
Speaker 1 :i guess mind map is a way to make
 connected mess inside your mind to just put it on paper so that you gainmore control over it
 it's a way to organize things on paper and as as kind of like a consequence fororganizing things on paper it start
 being more organized inside inside your

0:16:19
Speaker 0 :own mind what what does that look like
 you put like do you have an example like what whatwhat do you what's the first thing you
 write on paper what's the second thing

0:16:28
Speaker 1 :you write
 i mean typically uh you you draw a mind map toorganize the way you think about a topic
 so you would start by writing down like the the key conceptabout that topic like you would write
 intelligence or something and then you would start addinguh associative connections like what do
 you think about when you think about intelligence what do you think are thekey elements of intelligence so maybe
 you would have language for instance instead of motionand so you would start drawing notes
 with these things and then you would see what do you think about when you thinkabout motion
 and so on and you would go like that

0:17:00
Speaker 0 :like a tree it's a
 tree or a tree mostly there's a graph to like

0:17:05
Speaker 1 :a tree oh it's it's more of a graph than
 a tree and um and it's not limited to just you knowwriting down
 words you can also uh draw things and it's not it's not supposed to bepurely hierarchical right
 like you can um the point is that you can start once once you start writing itdown you can start reorganizing it so
 that it makes more sense so that it's connected in a more effective way see

0:17:29
Speaker 0 :but i'm so
 ocd that you just mentioned intelligence and language emotioni would start becoming paranoid that the
 categorization isn't perfect like that i'll become paralyzedwith the mind map that like this may not
 be so like the even though you're justdoing associative kind of
 connections there's an implied hierarchy that's emergingand i would start becoming paranoid
 that's not the proper hierarchy so you're not just one way to see mindmaps is you're putting
 thoughts on paper it's like a stream of consciousness but then you canalso start getting paranoid well
 if is this the right hierarchy sure like

0:18:15
Speaker 1 :which it's a mind map it's your mind map
 you're free to draw anything you want you're free to draw any connection youwant and you can
 just make a different mind my opinion is if you think the central node is not theright node


0:18:25
Speaker 0 :yeah so i suppose there's a fear of
 being wrong

0:18:29
Speaker 1 :if you want to if you want to organize
 your ideas by writing down what you think which ithink is is very effective like
 how do you know what you think about something if you don't write it downright uh if you do that the thing is
 that it imposes a much more uh syntacticstructure
 over your ideas which is not required with mind map so mind map is kind oflike a lower level
 more freehand way of organizing your thoughtsand once you've drawn it then you can
 start uh actually voicing your thoughts interms of you know
 paragraphs it's a two-dimensional aspect

0:19:05
Speaker 0 :of layout too right
 yeah and it's it's a kind of flower i guessyou start there's usually you want to
 start with a central concept

0:19:15
Speaker 1 :yes typically it ends up more like a
 subway map so it ends up more like a grapha topological graph without a root note
 yeah so like in a subway map there are somenodes that are more connected than
 others and there are some nodes that are more important than othersright so there are destinations but
 it's it's not going to be purely like a tree for instance

0:19:36
Speaker 0 :yeah it's fascinating to think that if
 there's something to that about our about the way our mind thinks by the wayi just kind of remembered
 obvious thing that i have probably thousands of documents in google doc atthis point
 that bullet point lists uh which is you can probably map a minemap to a bullet point list
 it's the same it's a no it's not it's a treeit's a tree yeah so i create trees but
 also they don't have the visual element like um i guess i'm comfortable with thestructure it feels like
 it the narrowness the constraints feel more

0:20:17
Speaker 1 :comforting if you have thousands of
 documents with your own thoughts in google docs why don't youwrite
 uh some kind of search engine like maybe a mind mapum a piece of software mind mapping
 software where you write down a concept and then it gives yousentences or paragraphs from your
 thousand google docs document that match this concept

0:20:40
Speaker 0 :the problem is it's so deeply unlike
 mind maps it's so deeply rooted in naturallanguage
 so it's not um it's not semantically searchable i wouldsay
 because the categories are very you kind of mention intelligencelanguage and motion they're very strong
 semantic like it feels like the mind map forces you tobe
 semantically clear and specific the bullet points list i haveare are sparse desperate
 thoughts that uh poetically represent a categorylike motion as opposed to saying motion
 so unfortunately it's that's the same problem with the internet that's why theidea of semantic web is difficult to get
 it's uh most language on the internet is a giant messof natural language that's hard to
 interpret which so do you think uh do you thinkthere's something to mind maps
 as um you actually originally brought up as we were talking aboutkind of cognition and language do you
 think there's something to mind maps about how our brain actuallydeals like think reasons about things


0:22:00
Speaker 1 :it's possible i think it's reasonable to
 assume that there is some level of topological processing inthe brain that the brain
 is very associative in nature and i also believe thata topological space is a better medium
 to encode thoughts than a geometric spacethen so i think what's the difference in


0:22:28
Speaker 0 :topological and geometric space


0:22:30
Speaker 1 :well um if you're talking about
 topologies uh then points are either connected or notso the topology is more like a subway
 map and geometry is when you're interestedin the distance between things and in
 subway maps you don't really have the concept of distance you only have theconcept of whether there is a train
 going from station a to station b andwhat we do in deep learning is that
 we're we're actually dealing with uh geometric spaces we're dealing withconcept vectors
 word vectors uh that have a distance betweenthe gist expressed in terms of dot
 product um we are not we are not really buildingtopological models usually


0:23:10
Speaker 0 :i think you're absolutely right like
 distance is a fundamental importance in deep learningi mean it's the
 continuous aspect of it yes because

0:23:19
Speaker 1 :everything is a vector and everything
 has to be a vector because everything has to be differentiableif your space is discrete it's no longer
 differentiable you cannot do deep learning in it anymorewell you could but you could only do it
 by embedding it in a bigger continuous space so if you dotopology in the in the context of deep
 learning you have to do it by embedding your topology in a geometry right yeah

0:23:42
Speaker 0 :well let me uh let me zoom out for a
 second uh let's get into your paper on themeasure of intelligence
 that uh did you put on 2019 yes

0:23:52
Speaker 1 :

0:23:54
Speaker 0 :okay yeah november november
 yeah remember 2018 that was a different

0:24:00
Speaker 1 :time
 yeah i remember i still remember

0:24:05
Speaker 0 :it feels like a different and different
 different world

0:24:09
Speaker 1 :you could travel you can you know
 actually go outside and see friends yeah

0:24:14
Speaker 0 :let me ask the most absurd question i
 think uh there's some non-zero probabilitythere'll be a textbook one day
 like 200 years from now on artificial intelligenceor it'll be called like just
 intelligence because humans will already be goneit'll be your picture with a quote
 you know one of the early biological systems would considerthe nature of intelligence and they'll
 be like a definition of how they thought about intelligencewhich is one of the things you do in
 your paper on measure intelligence is to ask like wellwhat is intelligence and and uh how to
 test for intelligence and so on so is there a spiffy quoteabout what is intelligence
 what is the definition of intelligence according to francois charley

0:25:05
Speaker 1 :yes so do you think the the
 superintendent ais of the future will want to remember us do weremember humans from the past and do you
 think they would be you know they won't be ashamed of havinga biology called origin


0:25:22
Speaker 0 :uh no i i think it would be a niche
 topic it won't be that interesting but it'll beit'll be like the people that study in
 certain contexts like historical civilization that nolonger exist
 the aztecs and so on that that's how it'll be seenand it'll be studying also the context
 on social media there will be hashtags about the atrocity committed to humanbeings
 um when when the when the robots finally got rid of themlike it was a mistake it'll be seen as a
 as a giant mistake but ultimately in the name of progress andit created a better world because humans
 were uh over consuming the resources and allthey were not very rational and were
 destructive in the end in terms of productivity andputting more love in the world and so
 within that context there'll be a chapter about these biological systems

0:26:17
Speaker 1 :seems to have a very detailed vision
 of that feature you should write a sci-fi novel about it i said i'm working

0:26:22
Speaker 0 :i'm working on a sci-fi novel currently
 yes

0:26:27
Speaker 1 :yes self-published yeah the definition
 of intelligence so intelligence is the efficiencywith which you acquire new skills
 at tasks that you did not previously know about that you did not prepare forall right so it is not intelligence is
 not skill itself it's not what you know it's not what youcan do it's how
 well and how efficiently you can learn new things

0:26:54
Speaker 0 :new things yes the idea of newness there
 seems to be fundamentally important

0:27:00
Speaker 1 :yes so you would see intelligence on
 display for instance whenever you see a human being or youknow an ai
 creature adapt to a new environment that it has not seen before that its creatorsdid not anticipate
 when you see adaptation when you see improvisation when you seegeneralization that's intelligence
 uh in reverse if you have a system that's when you put it in aslightly new environment it cannot adapt
 it cannot improvise it cannot deviate from what it's hardcoded to do ohwhat what it has been trying to do
 um that is a system that is not intelligent there's actually a quotefrom
 einstein that captures this idea which isthe measure of intelligence is the
 ability to change i i like that quote i think it capturesat least part of this idea


0:27:55
Speaker 0 :you know there might be something
 interesting about the difference between your definition and einsteinsi mean he's just being einstein
 and clever but acquisition of new ability to deal with new thingsversus ability to just change
 what's the difference between those two things so justchanging itself do you think there's
 something to that just being able to change yes being able

0:28:26
Speaker 1 :to adapt so not
 not change but certainly uh changes direction being able to adaptyourself
 to your environment whatever the

0:28:37
Speaker 0 :

0:28:38
Speaker 1 :environment that's
 that's a big part of intelligence yes and intelligence is more precisely youknow
 how efficiently you're able to adapt how efficiently you're able tobasically master your environment how
 efficiently you can acquire new skills and i thinkthere's a there's a big distinction to
 be drawn between intelligence which is a processand the output of that process which is
 skill so for instance if you have a very smarthuman programmer
 that considers the game of chess and that writes downa static program that can play chess
 then the intelligence is the process ofdeveloping that program but the program
 itself is just encodingthe output artifact of that process the
 program itself is not intelligent and the way you tell it's not intelligentis that if you put it in a different
 context you ask it to play go or somethingit's not going to be able to perform
 well with human involvement because the source of intelligencethe entity that is capable of that
 process is the human programmer so we should be able to tell thedifference between
 the process and its output we should not confusethe output and the process it's the same
 as you know do not confuse a road building company and one specificroad because one specific road takes you
 from point a to point b but a road building company can take youfrom you can
 make a path from anywhere to anywhere

0:30:09
Speaker 0 :else yeah that's beautifully put but
 it's also to play devil's advocate a little bityou know um it's possible that there's
 something more fundamental than us humans soyou kind of said the programmer creates
 uh the difference between the the choir of the skill and the skill itselfthere could be something like you could
 argue the universe is more intelligent like the the deepthe base intelligence of um that we
 should be trying to measure is something thatcreated humans
 we should be measuring god or what the source the universe as opposed tolike there's there could be a deeper
 intelligence sure there's always deeper

0:30:56
Speaker 1 :intelligence you can argue that but that
 does not take anything away from the fact thathumans are intelligence and you can't
 tell that because they are capable of adaptationand and generality
 um and you see that in particular and the fact thatuh humans are capable of handling
 uh situations and tasks that are quite different from anything thatany of our
 evolutionary ancestors has ever encounteredso we are capable of generalizing very
 much out of distribution if you consider our evolutionary history as being in away else training data


0:31:33
Speaker 0 :course evolutionary biologists would
 argue that we're not going too far out of the distributionwe're like mapping the skills we've
 learned previously desperately trying to like jam them intolike
 these new situations i mean there's

0:31:46
Speaker 1 :definitely a little bit
 a little bit of that but it's pretty clear to me that we're able touh you know most of the things we do
 any given day in our modern civilization are things that arevery very different from what you know
 our ancestors a million years ago would have been doing in in a given day andyour
 environment is very different so i agree thatum everything we do we do it with
 cognitive building blocks that we acquired over the course ofrevolution
 right and that anchors um our cognition to a certain context which isthe human condition very much but still
 our mind is capable of a pretty remarkable degree of generalityfar beyond anything we can create in
 artificial systems today like the degree in which the mind cangeneralize
 from its evolutionary history can generalize away from itsevolutionary history is much greater
 than the degree to which a depending system todaycan generalize away from its training
 data

0:32:50
Speaker 0 :and like the key point you're making
 which i think is quite beautiful is like we shouldn't measure if we talk aboutmeasurement
 we shouldn't measure the skill we should measure like the creation of the newskill
 the ability to create that new skill yes but there it's temptinglike it's weird because the skill
 is a little bit of a small window into theinto the system so whenever you have a
 lot of skills it's tempting to measure the skills yes

0:33:20
Speaker 1 :i mean the skill is the
 uh only thing you can objectively measurebut yeah so the the thing to keep in
 mind is that when you see skill in the humanit gives you a strong signal that that
 human is intelligent because you knew they weren't born with that skilltypically like you say this you see a
 very strong chess player maybe you're a very stronger player yourself

0:33:47
Speaker 0 :i think you're and you're you're saying
 that because i'm russian and now now you'reyou're prejudiced you assume oh yeah


0:33:53
Speaker 1 :it's just biased


0:33:55
Speaker 0 :

0:33:56
Speaker 1 :i'm biased yeah well you're dead by us
 um so if you see a very strong chess player you know they weren't bornknowing how to play chess so they had to
 acquire that skill with their limited resources with theirlimited lifetime
 and you know they did that because they are generally intelligentand so they may as well have acquired
 any other skill you know they have this potentialand on the other hand if you see a
 computer playing a chess you cannot make the sameassumptions because you cannot you know
 just assume the computer is generally intelligentthe computer may be born knowing
 how to play chess in the sense that it may have been programmedby a human that has understood chess for
 the computer and and that has just encodedum the output of that understanding in
 aesthetic program and that program is not intelligent so let's zoom out

0:34:49
Speaker 0 :just for a second and say like
 what is the goal of the on the measure of intelligence paperlike what do you hope to achieve with it


0:34:58
Speaker 1 :so the goal of the paper
 is to clear up some long-standing misunderstandingsabout the way we've been conceptualizing
 intelligence in the ai community and in the way we've been evaluatingprogress
 in ai there's been a lot of progress recently in machine learning and peopleare you know extrapolating from that
 progress that we're about to solve general intelligenceand if you want to be able to evaluate
 these statements you need to precisely define what you'retalking about when you're talking about
 general intelligence and you need a formal way a reliable way to measurehow much intelligence how much general
 intelligence a system processes and ideally thismeasure of intelligence should be
 actionable so it should not just describewhat intelligence is it should not just
 be a binary indicator that tells you the system is intelligent or it isn'tum it should be actionable it should
 have explanatory power right so you could use it as afeedback signal
 it would show you uh the way towards building more intelligent systems

0:36:13
Speaker 0 :so at the first level you draw a
 distinction between two divergent views of intelligenceof um as we just talked about
 intelligence is a collection of tax task specific skills and a generallearning ability so what's the
 difference between kind of this memorization of skillsand a general learning ability we've
 talked about a little bit but can you try tolinger on this topic for a bit yeah so


0:36:42
Speaker 1 :the first part of the paper
 uh is uh an assessment of the different waysuh we've been thinking about
 intelligence and the different ways we've been evaluating progressin ai and the history
 of cognitive sciences has been shaped by two viewsof the human mind and one view is the
 evolutionary psychology view in which the mindis a collection of fairly static
 special purpose ad-hoc mechanisms that have been hard coded by evolutionover our our history as a species over a
 very long time and um earlyai researchers people like marvin minsky
 for instance they clearly subscribed to this viewand they saw they saw the mind as a kind
 of you know collection of static programsuh
 similar to the programs they would they would run on like mainframe computersand in fact they i think they very much
 understood the mind uh through the metaphor of the mainframecomputer because that was the tool they
 they were working with right and so you had the static programs thiscollection of very different static
 programs operating over a database like memory and in thispicture learning was not very important
 learning was considered to be just memorization and in factlearning is basically not featured in ai
 textbooks until the 1980s with the rise of machinelearning


0:38:17
Speaker 0 :it's kind of fun to think about that
 learning was the outcast like the the weird people were learninglike the mainstream
 ai world was um i mean i don't know what the best termis but it's non-learning
 it was seen as like reasoning yes would not be learning based

0:38:37
Speaker 1 :yes it was seen it was considered that
 the mind was a collection of programs that were primarilylogical in nature and that's all you
 needed to do to create a mind was to write down these programs and they wouldoperate over your knowledge
 which would be stored in some kind of database and as long as your databasewould encompass you know
 everything about the world and your logical rules were uhcomprehensive then you would have in
 mind so the other view of the mind is the brain as a sort of blank slateright this is a very old idea you find
 it in john locke's writings this is thetabulata
 and this is this idea that the mind is some kind of like information spongethat starts empty it starts
 blank and that absorbs uh knowledge and skills from experienceright so it's uh it's a sponge that
 reflects the complexity of the world thecomplexity of your life experience
 essentially that everything you know and everythingyou can do is
 a reflection of something you found in the outside world essentiallyso this is an idea that's very old uh
 that was not very popular for instance in the in the 1970sbut that had gained a lot of vitality
 recently with the rise of connectionism in particular deeplearning and so today deep learning is
 the dominant paradigm in ai and i feel like lots ofai researchers are conceptualizing the
 mind via a deep learning metaphor like theysee the mind as a kind of
 randomly initialized neural network that starts blankwhen you're born and then that gets
 trained yeah exposure to training data that acquiresknowledge and skills exposure to
 training data

0:40:31
Speaker 0 :by the way it's a small tangent
 i feel like people who are thinking about intelligenceare not conceptualizing it that way i
 actually haven't met too many people who believethat a neural network
 will be able to reason who seriously think that rigorously becausei think it's actually interesting world
 view and and we'll talk about it more but itit's been impressive
 what the uh what neural networks have been able to accomplishand it's i to me i don't know you might
 disagree but it's an open question whetherlike like scaling size
 eventually might lead to incredible results to us mere humans will appear asif it's general


0:41:16
Speaker 1 :i mean if you if you ask people who are
 seriously thinking about intelligence they willdefinitely not say that all you need to
 do is is like the mind is just in your network uhhowever
 it's actually you that's that's very popular i think in the deep learningcommunity that
 many people are kind of uh conceptually you know intellectually lazy about it

0:41:37
Speaker 0 :right but what i guess what i'm saying
 exactly right it's uh i i me i haven't met many people andi think it would be interesting
 uh to meet a person who is not intellectualized about this particulartopic and still believes
 that neural networks will go all the way i think januaryis probably closest to that there are


0:41:56
Speaker 1 :definitely people
 who argue that uh current deep learning techniques arealready the way
 to general artificial intelligence and that all you need to dois to scale it up to all the available
 training data and that's if you look at the the wavesthat
 open ai's gpt stream model has made you seeechoes of this idea so on that topic


0:42:23
Speaker 0 :gpt-3 similar to gpt-2
 actually have captivated some part of the imagination of the publicthere's just a bunch of hype of
 different kind that's i would say it's emergent it's notartificially manufactured it's just like
 people just get excited for some strange reason in in the case of gpt3 which isfunny
 that there's i believe a couple months delay from release tohype maybe i'm not
 historically correct on that but it feels like there was a little bit of alack of hype and then there's a phase
 shift into into hype but nevertheless there's a bunch ofcool applications
 that seem to captivate the imagination of the public about what thislanguage model that's trained in
 unsupervised way without any fine tuning is able toachieve
 so what do you make of that what are your thoughts about gbt3

0:43:23
Speaker 1 :yeah so i think what's interesting about
 gpg3 is the idea that it may be able to learn new tasks inafter just being shown a few examples so
 i think if it's actually capable of doing thatthat's novel and that's very interesting
 and that's something we should investigatethat said i must say i'm not entirely
 convinced that we have shown it's it's capable ofdoing that
 it's very likely given the amount of data that the model is trained onthat what it's actually doing
 is pattern matching uh a new task you give itwith the task that it's been exposed to
 in its training data it's just recognizing the taskinstead of just developing a model of
 the task

0:44:05
Speaker 0 :right but there's a side to interrupt
 there's there's a parallels to what you said beforewhich is it's possible to see gpt3
 as like the prompts that's given as a kind ofsql query into this thing that it's
 learned similar to what you said before which is language is usedto query the memory yes so is it
 possible that neural network is a giant memorizationthing
 but then if it gets sufficiently giant it'll memorize sufficiently largeamounts of thing in the world
 where it becomes more intelligence becomes a querying machine

0:44:40
Speaker 1 :i think it's possible that uh a
 significant chunk of intelligence is this giant associative memory uhi definitely don't believe that
 intelligence is just a giant issue of memory but it may wellbe a big component


0:44:57
Speaker 0 :so do you think gpt 3
 4 5 gpt 10 will eventually like what do you think where's theceiling do you think you'll be able to
 reason um no that's a bad question uh like what is the ceiling is the better

0:45:17
Speaker 1 :question how well is it going to scale
 how good is gptn going to be yeah so i believe gptn is going tochiptn is going to improve on the
 strength of gpt2 and 3 which is it will be ableto generate you know
 ever more plausible text in context just

0:45:37
Speaker 0 :monitoring


0:45:39
Speaker 1 :the process performance um yes
 if you train if you're training bigger more on more data thenyour text will be increasingly more
 context aware and increasingly more plausible in thesame way that gpd3
 it is much better at generating clausable text compared to gpd2but that said i don't think just getting
 up uh the model to more transformer layersand more train data is going to address
 the flaws lgbt3 which is that it can generateplausible text but that text is
 not constrained by anything else other than plausibilityso in particular it's not constrained by
 factualness uh or even consistency which is why it'svery easy to get gpt3 to generate
 statements that are factually untrue uh or to generalstatements that are even
 self-contradictory right uh because it's uh it's it'sonly goal is plausibility and it has no
 other constraints it's not constrained to beself-consistent for instance right
 and so for this reason one thing that i thought was very interesting with gpd3is that
 you can present mind the answer it will give youby asking the question in specific way
 because it's very responsive to the way you ask the question since it hasno understanding of the content of the
 question right and if you if you ask the same questionin two different ways that are
 basically adversarially engineered to produce certain answers you will gettwo different answers to contractor


0:47:15
Speaker 0 :answers it's very susceptible to
 adversarial

0:47:17
Speaker 1 :attacks essentially potentially yes so
 in in general the problem with these models isgenerative models is that
 they are very good at generating plausible text but that's justthat's just not enough right um
 you need uh i think one one avenue that would be veryinteresting to make progress is to make
 it possible to write programs over the latent spacethat these models operate on that you
 would rely on these self-supervised models togenerate a sort of flag
 pool of knowledge and concepts and common sense and then you will be ableto write
 explicit uh reasoning programs over it uh because the current problem with gptstream is that you
 it's it can be quite difficult to get it todo what you want to do if you want to
 turn gpd3 into products you need to put constraints on ityou need to um force it to
 obey certain rules so you need a way to program it explicitly

0:48:22
Speaker 0 :yeah so if you look at its ability to do
 program synthesis it generates like you said somethingthat's plausible yeah so


0:48:28
Speaker 1 :if you if you try to make it generate
 programs it will perform well for any program that it has seen it inits training data
 but because uh program space is not interpretiveright um it's not going to be able to
 generalize to problems it hasn't seen before

0:48:48
Speaker 0 :now that's currently do you think
 sort of an absurd but i think useful um i guess intuition builder is uhyou know the gpt-3 has 175 billion
 parameters a human brain has a hundred has about athousand times that or
 or more in terms of number of synapses do you think obviouslyvery different kinds of things but there
 is some degree of similaritydo you think what do you think gpt will
 look like when it has a hundred trillionparameters
 you think our conversation might be so in nature differentlike because you've criticized gbt3 very
 effectively now do you think no i don't think so

0:49:45
Speaker 1 :so the the to begin with the bottleneck
 with scaling upgrades gbt models uh alternative pre-trainedtransformer models
 is not going to be the size of the model or how longit takes to train it the bottleneck is
 going to be the trained data because openui is already training gpt3on a crore of basically the entire web
 right and that's a lot of data so you could imagine training on more data thanthat like google could try on more data
 than that but it would still be only incrementallymore data
 and i i don't recall exactly how much more data gpd3 was trained on comparedto gpt2 but it's probably at least like
 100 or maybe even a thousand x don't have the exact numberuh you're not going to be able to train
 the model on 100 more data than with what you already with what you'realready doing


0:50:34
Speaker 0 :so that's that's brilliant so it's not
 you know it's easier to think of compute as a bottleneckand then arguing that we can remove that


0:50:41
Speaker 1 :bottleneck but we can remove the compute
 bottleneck i don't think it's a big problemif you look at the at the base at which
 we've uh improved the efficiency of deep learningmodels
 in the past a few years i'm not worried aboutuh trying time bottlenecks or model size
 bottlenecks the the bottleneck in the case of thesegenerative transformer models is
 absolutely the trained data

0:51:05
Speaker 0 :what about the quality of the data so so


0:51:07
Speaker 1 :yeah so the quality of the data is an
 interesting point the thing is if you're going to want to use thesemodels in real
 products um then you you want to feed them data that's ashigh quality as
 factual i would say as unbiased as possiblebut you know there's there's not really
 such a thing as unbiased data in the first place but you probablydon't want to
 to train it uh on reddit for instance it soundssounds like a bad plan so from my
 personal experience working with a large scale deep learning modelsso at some point i was working on a
 model at google that's trained on extra 150 millionlabeled images it's image classification
 model that's a lot of images that's like probably most publicly available imageson the web at the time
 and it was a very noisy data set because the labelswere not originally annotated by hand by
 humans they were automatically derived from like tags onsocial media
 or just keywords in in the same page as the image was fun and so on so it wasvery noisy and
 it turned out that you could uh easily geta better model uh not just by training
 like if you train on more of the noisy data you get anincrementally better model but you
 you you very quickly hit diminishing returns on the other handif you try on smaller data set with
 higher quality annotations quality that areannotations that are actually made by
 humans you get a better model and it also takes you know lesstime to train it


0:52:49
Speaker 0 :uh yeah that's fascinating it's the
 self-supervised learnings there's a way to get betterdoing the automated


0:52:58
Speaker 1 :labeling yeah so you can
 enrich or refine your labels in an automated way that's correct do

0:53:06
Speaker 0 :you have a hope for um
 i don't know if you're familiar with the idea of a semantic webis this a semantic web just for people
 who are not familiar and is uh is the idea of being able toconvert
 the internet or be able to attach like semanticmeaning to
 the words on the internet this the sentences the paragraphsto be able to contr convert information
 on the internet or some fraction of the internet into something that'sinterpretable by machines
 that was kind of a dream for um i think the the semantic whitepapers in the 90s
 it's kind of the dream that you know the internet is full of rich excitinginformation even
 just looking at wikipedia we should be able to use thatas data for machines and so information


0:53:58
Speaker 1 :is not it's not really in a format
 that's available to machines so no i don't think the semantic web willever work simply because it would be a
 lot of work right to make to provide thatinformation in structured form
 and there is not really any incentive for anyone to provide that workuh so i think the the way forward to
 make the knowledge on the web available tomachines is actually
 something closer to unsupervised deep learningyeah the gpg 3 is actually a bigger step
 in the direction of making the knowledge of the web available to machinesthan the semantic web was yeah perhaps


0:54:36
Speaker 0 :in a human-centric sense it it feels
 like gpt-3 hasn't learnedanything that could be used
 to reason but that might be just the early days

0:54:53
Speaker 1 :yeah i think that's correct i think the
 forms of reasoning that you that you see it perform are basicallyjust reproducing
 patterns that it has seen in string data so of course if you're trained onuh the entire web then you
 can produce an illusion of reasoning in many different situations but it willbreak down
 if it's presented with a novel uh situation

0:55:15
Speaker 0 :that's the opening question between the
 illusion of reasoning and actual reasoning

0:55:18
Speaker 1 :yes the power to adapt to something that
 is genuinely new because the thing is even imagine youhad
 uh you could train on every bit of data ever generatedin history of humanity uh it remains
 so that model would be capable of of anticipatinguh many different possible situations
 but it remains that the future is going to be somethingdifferent like
 for instance if you train a gpt stream model onon data from the year 2002 for instance
 and then use it today it's going to be missing many things it's going to bemissing many
 common sense facts about the world it's even going to be missing vocabularyand so on


0:56:05
Speaker 0 :yeah it's interesting that uh gbt3 even
 doesn't have i think any information about thecoronavirus


0:56:14
Speaker 1 :yes which is why you know uh
 a system that's uh you you tell that the system is intelligent when it's capableto adapt
 so intelligence is gonna require uh some amount of continuous learningbut it's also gonna require some amount
 of improvisation like it's not enough to assume that whatyou're going to be
 asked to do is something that you've seen beforeor something that is a simple
 interpolation of things you've seen beforeyeah in fact that model breaks down for
 uh even even very tasks that look relatively simple from adistance
 like l5 self-driving for instance google had a paper couple of years backshowing that something like 30 million
 different road situations were actually completely insufficient to traina driving model it wasn't even l2 right
 and that's a lot of data that's a lot more data than thethe 20 or 30 hours of driving that a
 human needs to learn to drive given the knowledgethey've already accumulated


0:57:22
Speaker 0 :well let me ask you on that topic
 elon musk tesla autopilot one of the only companies i believe isreally pushing for a learning based
 approach are you you're skeptical that that kindof network can achieve level four


0:57:38
Speaker 1 :l4 is probably achievable
 l5 is probably not what's the

0:57:44
Speaker 0 :distinction there
 this l5 is completely you can just fall

0:57:48
Speaker 1 :asleep
 yeah alpha is basically human level well

0:57:51
Speaker 0 :it will drive you have to be careful
 saying human level because like

0:57:54
Speaker 1 :that's yeah most of the drivers yeah


0:57:57
Speaker 0 :that's the clearest example of like
 you know cars will most likely be much safer than humans in situin many situations where humans fail
 it's the vice versa so i'll tell you you know

0:58:09
Speaker 1 :the thing is the the amounts of training
 data you would need to anticipate for pretty much everypossible situation
 you'll encounter in the real world uh is such thatit's not entirely unrealistic to think
 that at some point in the future we'll develop a system that's running onenough data especially uh
 provided that we can uh simulate a lot of that datawe don't necessarily need actual uh
 actual cars on the road for everything but it's a massiveeffort and it turns out you can create a
 system that's much more adaptative that can generalizemuch better
 if you just add explicit models of the surroundings ofthe car
 and if you use deep learning for what it's good at which is to provideperceptive information so in general
 deep learning is is a way to encode perception and a way toencode intuition
 but it is not a good medium for any sort ofexplicit reasoning and
 uh in ai systems today uh strong generalization tends tocome from um explicit
 models tend to come from abstractions in the human mind that are encodedin program form by a human engineer
 right yeah these are the abstractions you can actually generalize not the sortof
 weak abstraction that is learned by a neural network yeah and the question is

0:59:35
Speaker 0 :how much
 how much reasoning how much strong abstractions are required to solveparticular tasks like driving
 that's that's the question or human life existence how much how much strong obsabstractions does existence
 require but more specifically on driving that's that seems to be that seems to bea coupled
 question about intelligence is like uh how muchintelligence like how do you build an
 intelligent system and uh the coupled problem how hard isthis problem how much intelligence does
 this problem actually require so we're um we get to cheat rightbecause we get to look at the problem
 like it's not like you get to close our eyes and completely new to drivingwe get to do what we do as
 human beings which is uh for the majority of our lifebefore we ever learn quote unquote to
 drive we get to watch other cars and other people drive we get to bein cars we get to
 watch we get to get to see movies about cars we get toyou know get to observe all this stuff
 and that's similar to what neural networks are doingit's getting a lot of data and
 the the the question is yeah how much is uhhow many leaps of reasoning genius is
 required to be able to actually effectively drive

1:00:59
Speaker 1 :i think it's an example of driving
 i mean sure you've seen a lot of cars in your life before you learn to drivebut let's say you've learned to drive in
 silicon valley and now you rent a car in tokyowell now everyone is driving on the
 other side of the road and the signs are differentand the roads are more narrow and so on
 so it's a very very different environmentuh a smart human even an average human
 should be able to just zero shot it to justbe operational in this in this very
 different environment yeah right away despite having addnew contacts with the novel complexity
 that is contained in this environment right and that is another complexity isnot just
 interpolation over the situations that you've encountered previouslylike learning to drive in the u.s right
 i would say

1:01:55
Speaker 0 :the reason i ask this one of the most
 interesting tests of intelligence we havetoday actively which is driving
 in terms of having an impact on the world like when do you think we'll passthat test of intelligence


1:02:09
Speaker 1 :so i i don't think driving is that much
 of a test institutions because again there is no task for which skid at thattask
 demonstrates intelligence unless it's a kind of meta task that involvesacquiring
 new skills so i don't think i think you can actually solve drivingwithout having
 any any real amount of intelligence for instance if you really did have infinitetrained data
 um you could just literally train an end-to-end deep learning model that'sdriving
 provided infinite training data the only problemwith the whole idea is um
 collecting a data sets that's sufficiently comprehensive that coversthe very long tail of possible
 situations you might encounter and it's really just a scale problem soi think the
 there's nothing fundamentally wrong uh uh with this plan with this idea it'sjust that
 um it strikes me as a fairly inefficient thing to do because you runinto this uh this uh scanning issue with
 diminishing returns whereas if instead you took a more manualengineering approach
 where you use deep learning modules in combinationwith um engineering an explicit model
 of the surrounding of the cars and you and you bridge the two in a clever wayyour model will actually start
 generalizing much earlier and more effectively than theend-to-end depleting model so why would
 you not go with the more manually engineeringoriented approach
 like even if you created that system either the end-to-end deep learningmodel system that's infinite data or
 the slightly more human system i i don't think achieving alpha woulddemonstrate
 uh general intelligence or intelligence of any generality at all again the onlypossible test
 of generality in ai would be a test that looks at skillacquisition over unknown tasks but for
 instance you could take your l5 driver and ask it to to learn to topilot a
 a commercial airplane for instance and then you would look at how much humaninvolvement
 is required and how much training data is required uh for the system to learnto pirate an airplane and
 that that gives you a measure of how intelligent that system

1:04:36
Speaker 0 :is yeah well i mean that's a big leap i
 get you but i'm more interested as a problem i wouldsee
 to me driving is a black box that can generate novel situations atsome rate
 that what people call edge cases like so it does havenewness that keeps being like we're
 confronted let's say once a month it is a very long

1:04:59
Speaker 1 :time yes
 long term that doesn't mean you cannot solve ituh just by by training a statistical
 model a lot of data huge amount of data it's it's really amatter of scale


1:05:11
Speaker 0 :but i guess what i'm saying is if you
 have a vehicle that achieves level five it isgoing to be
 able to deal with new situations or i mean the data is so largethat the rate of new situations is
 very low yes that's not intelligent so if we go back to your kind of definitionof intelligence it's the efficiency


1:05:39
Speaker 1 :with which you can adapt to new
 situations to truly new situations not situations you've seen beforeright not situations that could be
 anticipated by your creators by the creators of the system but three newsituations
 the efficiency with which you acquire new skillsif you require if in order to pick up a
 new skill you require a very extensive training data setsof most possible situations that can
 that can occur in the practice of that skill then thesystem is not intelligent it is mostly
 just a lookup table yeah

1:06:14
Speaker 0 :

1:06:15
Speaker 1 :well likewise if uh in order to acquire
 a skill you need a human engineer to write down a bunchof rules that cover
 most or every possible situation likewise the system isis not intelligent the system is merely
 the output artifact of a process that that depends thathappens in the minds
 of the engineers that are creating it right it isincluding uh an abstraction that's
 produced by the human mind and intelligence that would actually bethe process of producing of autonomously
 producing this abstraction yeah not like if you take an abstractionyou encode it
 on a piece of paper or in a computer program the abstraction itselfis not intelligent what's intelligent is
 the the agent that's capable of producing these abstractionsright yeah it feels like there's a


1:07:12
Speaker 0 :little bit of a gray area
 like because you're basically saying that deep learning forms abstractionstoo but those abstractions
 do not seem to be effective for generalizing far outsideof the things that's already seen but
 generalize a little bit

1:07:31
Speaker 1 :yeah absolutely no depending does
 generalize a little bit like generalization is not it's not a binaryit's mark a spectrum


1:07:38
Speaker 0 :yeah and there's a certain point it's a
 gray area but there's a certain point where there's an impressive degree ofgeneralization
 that happens no like i guess exactly what you were saying isuh intelligence is um
 how efficiently you're able to generalizefar outside of the distribution of
 things you've seen already yes so it's both like the the distanceof how far you can
 like how new how radically new something isand how efficiently yes absolutely so


1:08:13
Speaker 1 :you you can think of
 uh intelligence as a measure of an information conversion ratiolike imagine uh a space of possible
 situations and you've covered some of themso you have some amount of information
 about your space of possible situations that's provided by the situations youalready know
 and that's on the other hand also provided bythe prior knowledge that the system
 brings to the table the prior knowledge that's embeddedin the system so the system starts with
 some information right about the problem but the task andit's about going from that information
 to a program what you would call a skillprogram a behavioral program
 that can cover a large area of possible situation spaceand essentially the ratio between that
 area and the amount of information you start withis intelligence
 so a very smart agent uh can make efficient usesof very little information about a new
 problem and very little prior knowledge as wellto cover a very large area of potential
 situations in that problem without knowing what these future newsituations are going to be


1:09:31
Speaker 0 :so one of the other big things you talk
 about in in the paper we've talked about a little bit alreadybut let's talk about it some more is uh
 actual tests of intelligence so if we look at like human and machineintelligence
 do you think tests of intelligence should be differentfor humans and machines or how we think
 about testing of intelligence are these fundamentally the same kind ofintelligences that we're after and
 therefore the test should be

1:10:03
Speaker 1 :similar so if your goal is to create
 ais that are more human-like then it will be super variable obviouslyto have a test
 that's that's universal at a price to both uh aisuh and humans so that you can you could
 establish a comparison uh between the two that you could tellexactly
 how uh intelligent in terms of human intelligencea given system is so that said the
 constraints that apply to artificial intelligenceand to human intelligence
 are very different and your tests should account for this differencebecause if you look at artificial
 systems it's always possible for an experimenter to buy arbitrarylevels of skill
 at arbitrary tasks either by injecting a hard-coded prior knowledgeinto the system via rules
 and so on that come from the human mind from the minds of the programmersand also buying uh higher levels of
 skill just by training on more data for instance you could generate aninfinity of different goal games
 and you could train a good playing systemthat way but you could not directly
 compare it to human goal playing skills becausea human that plays go had to develop
 that skill in a very constrained environment theyhad a limited amount of time
 their limited amount of energy and of coursethis started from a different set of
 priors to solids from uh um you know innate uh human priorsum so i think if you want to compare the
 intelligence of two systems like the intentions of an aiand the intelligence of a human you have
 to um control for priors you have tostart from the the same set of knowledge
 priors about the task and you have to control for forexperience and that is to say for
 training data

1:12:11
Speaker 0 :so prior what's priors


1:12:15
Speaker 1 :so prior is whatever information
 you have about a given task before you start learning about this task

1:12:23
Speaker 0 :and how's the difference from experience


1:12:25
Speaker 1 :well experience is acquired
 right so for instance if you're if you're trying to play goalyour experience with goal is all the
 goal games you've played or you've seen or you've simulated inyour mind let's say
 and uh your priors are things like well go go is a game on on a 2d gridand we have lots of hard-coded priors
 about the organization of 2d space and the

1:12:53
Speaker 0 :rules of how
 the the dynamics of the physics of this game in this 2d spaceyes and the idea that you have what
 winning is

1:13:04
Speaker 1 :yes exactly so like and all other board
 games can also share some similarities withschool and if you've played these board
 games then uh with respect to the game of go thatwould be part of your priors about the
 game

1:13:16
Speaker 0 :well it's interesting to think about the
 game of goes how many priors are actually brought to the tablewhen you look at uh self-play
 reinforcement learning based mechanisms that do learning it seems like thenumber of prizes pretty low yes but
 you're saying you should be exp

1:13:32
Speaker 1 :there's a 2d special priority in the
 covenant

1:13:36
Speaker 0 :right but you should be clear at making
 those priors explicit

1:13:39
Speaker 1 :yes uh so in particular i think if your
 if your goal is to measure a human-like form ofintelligence
 then you should clearly establish that you wantthe ai your testing to start from
 the same set of priors that humans start with right

1:13:58
Speaker 0 :so i mean to me personally but i think
 to a lot of people the human side of things is veryinteresting so testing intelligence for
 humans what um what do you think is a good testof human intelligence


1:14:14
Speaker 1 :well that's the question that
 psychometrics is is interested in what is there's anentire subfield of psychology
 that deals with this question so what's

1:14:24
Speaker 0 :psychometrics the psychometrics


1:14:25
Speaker 1 :is the sub-field of psychology that that
 tries to measure quantify aspects of the humanmind so in particular community
 abilities intelligence and personality threats as well so

1:14:39
Speaker 0 :uh like what are might be a weird
 question but what are like the first principlesof the of psychometrics that
 operates on the you know what what are the priors it brings to the table

1:14:55
Speaker 1 :so it's a filled with a with a fairly
 long history um it's so you know psychology sometimesgets a bad reputation
 for not having very reproducible uh results and somepsychometrics as actually some fairly
 solidly or producible results so the ideal goals of the field is youknow tests should be
 be reliable which is a an ocean type reproducibilityit should be valid uh meaning that it
 should actually measure what you say but you say it measures um so forinstance if you're if you're saying that
 you're measuring intelligence then your test results should be created withthings that you expect to be correlated
 with intelligence like success in school or success in theworkplace and so on
 should be standardized meaning that you canadminister your tests to many different
 people in the same conditions and it should be free from bias meaningthat for instance uh if you're if if
 your test involves uh the english language then you have tobe aware that
 this creates a bias against people who have english as their second language orpeople who can't speak english at all
 so of course these these principles for creating psychometric tests arevery much nighty old i don't think every
 psychometric test is is really either reliablevalid or offer from bias but at least
 the field is aware of these weaknesses and is trying toaddress them so


1:16:27
Speaker 0 :it's kind of interesting um ultimately
 you're only able to measure like you said previouslythe skill
 but you're trying to do a bunch of measures of different skills thatcorrelate as you mentioned strongly with
 some general concept of cognitive ability yes yes so what's theg
 factor so right there are many different

1:16:47
Speaker 1 :kinds of
 tests tests of intelligence and uh each of them is interested in in uhdifferent aspects of intelligence you
 know some of them will deal with language some of themwe deal with a special vision maybe
 mental rotations numbers and so on when you run these very different testsat scale what you start seeing is that
 there are clusters of correlations among test results so for instance ifyou look at uh
 homework at school um you will see that peoplewho do well at math are also likely
 statistically to do well in physics and what's more uh there there alsopeople do well at math and physics
 are also statistically likely to do well in things thatsound completely unrelated like writing
 in english essay for instance and so when you see clusters ofcorrelations
 uh in in statical statistical terms you would explain them with a latentvariable
 and the latent variable that would for instance explain uhthe relationship between being good at
 math and being good at physics would be cognitive ability right and the g factoris the the latent variable that explains
 uh the fact that every test of intelligence that you cancome up with
 results on that on on this test end up being correlated so there is some asingle uh a unique variable
 uh that that explains this correlations that's the g factorso it's a statistical construct it's not
 really something you can directly measure for instance in a person um butit's there
 but it's there it's there it's the art scale and that's also one thing i wantto
 mention about psychometrics like you know when you talk aboutmeasuring intelligence in in humans for
 instance some people get a little bit worried they will say youknow that sounds dangerous maybe that's
 not potentially discriminatory and so on andthey're not wrong and the thing is so
 personally i'm not interested in psychometricsas a way to characterize one individual
 person like if if i get your psychometric personality assessmentor your iq i don't think that actually
 tells me much about you as a person i thinkpsychometrics is most useful
 as a statistical tool so it's most useful at scaleit's most useful when you start getting
 test results for a large number of people and you startcross-correlating these test results
 because that gives you information about thestructure
 of the human mind particularly about the structure of human cognitive abilitiesso
 at scale psychometrics paints a certain picture of the human mind andthat's interesting
 and that's what's relevant to ai the structure of human currency abilities

1:19:41
Speaker 0 :yeah it gives you an insight into it i
 mean to me i remember when i learned about gfactor it seemed
 it it seemed like it would be impossible for it evenit to be real even as a statistical
 variable like it felt uh kind of like astrology likeit's like wishful thinking among
 psychologists but uh the more i learned i realizedthat there's some
 i mean i'm not sure what to make about human beings the fact that the jigfactor is a thing
 that there's a commonality across all of human speciesis there destiny to be a strong
 correlation between cognitive abilities that's kind of fascinating yeah actually

1:20:18
Speaker 1 :so human connectivities have
 uh a structure like the the most mainstream theory of the structure ofcancer abilities
 it's called a chc theory it's a cattle horn carolit's name of the industry psychologist
 who contributed key pieces of it and it describes uh cognitive abilitiesas a hierarchy with three levels and at
 the top you have the g-factor then you have broad cognitive abilitiesfor instance fluid intelligence right
 that that encompass um a broad set of possible kinds of tasksthat are all
 related and then you have narrow cognitivity is at the last levelwhich is uh closer to task specific
 skill and there are actually differenttheories
 of the structure of clinical abilities that just emerge from differentstatistical analysis of
 iq test results but they all describe a hierarchy with a kind of g factorat the top and you're right that the g
 factor is it's not quite real in the sense thatit's not
 something you can observe and measure like your height for instance but it'sreally in the sense that
 you you see it in in a statistical analysis of the dataright one thing i want to mention is
 that the fact that there is a g-factor does not really mean thathuman intelligence is a general in a
 strong sense does not mean human intentions can canbe applied to any problem
 at all and that someone who has a high iq is going to be able to solve anyproblem at
 all that's not quite what it means i think umone one popular analogy to understand it
 is the sports analogy if you consider the concept ofphysical fitness it's a concept that's
 very similar to intelligence because it's a useful concept it's something youcan intuitively
 understand some people are fit uh maybe like yousome people are not as fit maybe like me


1:22:21
Speaker 0 :um but none of us can fly


1:22:22
Speaker 1 :absolutely it's so constrained even if
 you're very fit that doesn't mean you can do uh anythingat
 all in any environment you you obviously cannot fly you cannot uh survive at thebottom of the ocean and so on
 and if you were a scientist say you want you wanted to preciselydefine and measure physical fitness in
 humans then you would come up with a batteryuh of tests uh like you would you know
 have running android meter uh playing soccer playingtable tennis swimming and so on
 and uh if you run these tests over many different people you will start seeingcorrelations and test results for
 instance people who are good at soccer are so goodat sprinting right and
 you will explain these correlations with physical abilities that arestrictly analogous to cognitive
 abilities right and then you would start also observingcorrelations between biological uh
 characteristics like maybe lung volume is correlated with beinga a fast runner for instance uh in the
 same way that there are neurophysical uh correlatesof cognitive abilities right and at the
 top of the hierarchy of physical abilitiesthat you would be able to observe you
 would have a g-factor a physical g-factor whichwould map to physical fitness right
 and as you just said that doesn't mean thatpeople with a with high physical fitness
 can fly doesn't mean uh human morphology and human physiologyis universal
 it's actually super specialized we can only do the thingsand that we were evolved to do
 right like we are not appropriate to to to you you could not exist on venus ormars or in the void of space
 but on the ocean so that said one thing that's really strikingand remarkable is that
 our morphology generalizes far beyond the environments that weevolved for
 like in a way you could say we evolved to runafter prey in the seminar right that's
 very much where our human morphology comes fromand that said
 we can we can do a lot of things that are that arecompletely unrelated to that we can
 climb mountains we can we can swim across lakes uh we can playa table tennis i mean table tennis is
 very different from what we were evolved to do rightso our morphology our bodies or our
 sense of motor affordances are of a degree of generality that isabsolutely remarkable
 right and i think cognition is very similar to thatour cognitive abilities have a degree of
 generality that goes far beyond what the mind was initially supposed todo which is why we can you know play
 music and write novels and and go to mass and do all kinds of crazythings
 but it's not universal in the same way that human morphology and our bodyis not appropriate for actually most of
 the universe by volume in the same way you could say that thehuman mind is naturally appropriate for
 most of problem space potential problem space uhby volume so we have very strong
 cognitive biases actually that mean that there are certain types of problems thatwe handle very well and certain
 certain types of problem that we are completely adapted forso that's really how we interpret
 the g-factor it's not a sign of strong generalityit's it's really just a broader the
 broadest cognitive ability but our abilities whether we are talkingabout sensory motor abilities
 or cognitive abilities they still they remain very specializedin the human condition right


1:26:13
Speaker 0 :within the constraints of the human
 cognition they're general yes absolutely so but

1:26:18
Speaker 1 :

1:26:19
Speaker 0 :the constraints as you're saying are
 very limited what i think what's yeah limiting so we

1:26:23
Speaker 1 :we evolved
 our cognition and our body evolved in in very specific environmentsbecause our environment was so viable
 fast changing and so unpredictable part of the constraints that that droveour evolution
 is generality itself so we were in a way evolved toto be able to improvise in all kinds of
 physical or cognitive environments right yeah umand for this reason it turns out that
 uh the the minds and bodies that we ended up withuh can be applied to much much broader
 scope than what they were evolved for rightand that's truly remarkable
 and that goes that's the degree of generalization that is far beyondanything you can see in artificial
 systems today right um that's it it does not mean that thatuh human intelligence is anywhere
 universal yes yeah it's not general

1:27:16
Speaker 0 :you know it's a kind of exciting topic
 for people even you know outside of artificialintelligence iq tests


1:27:25
Speaker 1 :

1:27:27
Speaker 0 :there i think it's mensa whatever
 there's different degrees of difficulty for questionswe talked about this offline a little
 bit too about sort of difficult questionsyou know what makes a question on an iq
 test more difficult or less difficult do youthink so


1:27:43
Speaker 1 :the the thing to keep in mind is that
 there's no such thing as a question that's intrinsicallydifficult
 it has to be difficult to respect to the things you already knowand the things you can already do right
 so in in terms of an iq test questiontypically you would have it will be
 structured for instance as a set of demonstrationinput and output pairs right and then
 you would be given a test input a prompt and you youyou would need to recognize or produce
 the corresponding output and in that narrow context you could saya difficult
 question is a question where um the input prompt isvery surprising and unexpected given the
 the training examples just even the

1:28:37
Speaker 0 :nature of the patterns that you're
 observing in the input problem for instance let's say you have a

1:28:40
Speaker 1 :rotation problem
 you must rotate the shape by 90 degrees if i give you two examples and then i'llgive you one one
 prompt which is actually one of the two training examplesthen there is zero generalization
 difficulty for the task it's actually triggered taskyou just recognize that it's one one of
 the training examples and you produce the same answernow if it's uh if it's a more complex
 shape there is you know a little bit moregeneralization but it remains that
 you are still doing the same thing at this timeas you were being demonstrated at
 training time a difficult task starts to requiresome amount of uh test time adaptation
 some amount of improvisation right so uhconsider i don't know you're teaching a
 class on like quantum physics or somethingum if
 uh if you wanted to kind of test the understanding that students have ofthe material you would come up with
 an exam that's very different from anything they've seen like on theinternet
 when they were cramming uh on the other hand if you wanted to make it easyyou would just give them something
 that's very similar to the the mock exams that that thatthey've taken
 something that's just a simple interpolation of questions that they'vethey've already seen
 and so that would be an easy exam it's very similar to what you've been trainedon
 and a difficult exam is one that really probes your understanding because itforces you
 to improvise it forces you to do things uh that are different from what you wereexposed to before
 so that said it doesn't mean that the exam that requires improvisation isintrinsically hard right because maybe
 you're you're a quantum physics expert so when you take the exam this isactually stuff that despite being you
 new to the students it's not new to you right so it can only be difficultwith respect to what the test taker
 already knows and with respect to the informationthat the test taker has about the task
 so that's what i mean by controlling forpriors what you
 the information you bring to the table and the exp and experience which isthe training data so in in the case of
 the the quantum physics exam that would beuh all the the the course material
 itself and all the mock exams that students might have taken online

1:31:13
Speaker 0 :yeah it's interesting because um i've
 also i i sent you an email and i asked you likei've been
 this just this curious question of um you know what's a really hard iq testquestion
 and i've been talking to also people who have designed iq teststhere's a few folks on the internet it's
 like a thing people are really curious about it first of all most ofthe iq tests they designed
 they like religiously protect against the correct answers likeyou can't find the correct answers
 anywhere in fact the question is ruined once youknow even like
 the approach you're supposed to take so

1:31:54
Speaker 1 :they're very
 the approach is implicit in in the training examples so here it is thetraining examples it's over
 well which is why in arc for instance there is a test set that is private andno one has seen it


1:32:09
Speaker 0 :no for really tough iq questions it's
 not obvious it's not because the ambiguitylike it's uh and you have to
 look to them but like some number sequences and so on it's notcompletely clear so like you can get a
 sense but there's like some you know when you lookat a number sequence i don't know
 uh like your fibonacci number sequence if you look at the first few numbersthat sequence could be completed in a
 lot of different ways and you know some are if you thinkdeeply or more correct than others
 like there's a kind of intuitive simplicity and elegance to the correctsolution yes


1:32:53
Speaker 1 :i am personally not a fan of ambiguity
 in in test questions actually but i thinkyou can have difficulty
 uh without requiring ambiguity simply by making the testuh require a lot of extrapolation over
 the training examples

1:33:10
Speaker 0 :but the beautiful question
 is difficult but gives away everything when you give the training example

1:33:17
Speaker 1 :basically yes meaning that so
 the the tests i'm interested in in creatingare not necessarily difficult uh for
 humans because uh human intelligence is thebenchmark
 uh they're supposed to be difficult uh for machinesin ways that are easy for humans like i
 think an ideal uh test of human and machineintelligence is a test that is
 uh actionable uh that highlights uh the need for progressand that highlights the direction in
 which you should be making progress i i think

1:33:52
Speaker 0 :we'll talk about the arc challenge and
 the test you've constructed you have these elegant examplesi think that highlight like this is
 really easy for us humans but it's really hard for machines buton the you know the designing an iq test
 for iqs of like a higher than 160 and so onyou have to say you have to take that
 and put on steroids right you have to think like what is hard forhumans and that's a fascinating exercise
 in in itself i think and it was an interesting question ofwhat it takes to create a really hard
 question for humans because um you again have to do the same process asyou mentioned which is
 uh you know something basically where the experience that youhave likely to have encountered
 throughout your whole life even if you've preparedfor iq
 tests which is a big challenge that this will still be novel for you

1:34:55
Speaker 1 :yeah i mean novelty is a requirement
 you should not be able to practice for the questions that you're gonna betested on that's important because
 otherwise what you're doing is not exhibiting intelligence whatyou're doing is just retrieving
 uh what you've been exposed before it's it's the same thing as deep learningmodel if you train a deep learning model
 on uh all the possible answers then it willace your test in the same way that
 uh um you know uh as a stupid student uh can still ace thetest
 if they cram for it they memorize you know 100 different possible mockexams and then they hope that
 the actual exam will be a very simple interpolation of the mock exams and thatstudent could just be a deep learning
 model at that point but you can actually do that without anyunderstanding of the material and in
 fact many students pass the exams in exactly this way andif you want to avoid that you need an
 exam that's unlike anything they've seen that reallyprobes
 their understanding so how do we

1:36:00
Speaker 0 :design an iq test for machines
 and intelligent tests for machines all

1:36:08
Speaker 1 :right so
 in the paper i outline a number of requirementsthat you expect of such a test and in
 particular we should start by acknowledging the priorsthat we expect to be required in order
 to perform the test so we should be explicit about thepriors right uh
 and if the goal is to compare machine intelligence and human intelligence thenwe should assume
 uh human cognitive bias right and secondly we should make sure that we aretesting
 for skilled acquisition ability uh skill acquisition efficiency in particular andnot for skill itself
 meaning that every task featured in your test should benovel and should not be something that
 you can anticipate so for instance it should not bepossible to
 brute force the space of possible questions rightto pre-generate every possible question
 and the answer so it should be tasks that cannot beanticipated
 not just by the system itself but by the creatorsof the system right yeah you know what's


1:37:16
Speaker 0 :fascinating i mean one of my favorite
 aspects of the paper and the work you do with thearc challenge is
 the the process of making priors explicitjust even that act alone is a really
 powerful one of like what are it's ait's a really powerful question ask of
 us humans what are the priors that we bring to the tableso the the next step is like once you
 have those priors how do you use them to solve a novel task but like just evenmaking the prize explicit
 is a really difficult and really powerful stepand that's like visually beautiful and
 conceptually philosophically beautiful part of the work you didwith uh and i guess continue to do uh
 probably with the with the paper and the arc challengecan you talk about some of the priors
 that we're talking about here

1:38:12
Speaker 1 :yes so a researcher has done a lot of
 work on what exactly uh um are the knowledgepriors that
 that are innate to humans is elizabeth spelkie from harvard soshe developed the core knowledge uh
 theory which uh outlines four differentuh core knowledge systems uh so systems
 of knowledge that we are basically either born with or that weare
 hardwired to acquire very early on in our development and there's no uhthere's no strong
 um distinction between the two like if you areum primed to acquire as a
 certain type of knowledge uh in just a few weeks you might as welljust be born with it it's just it's just
 part of who you are and so there are there are fourdifferent core knowledge systems like
 the first one is the notion of objectness anda basic physics like you recognize that
 um something that moves uh currently for instance is an objectso we intuitively naturally innately
 divide the world into objects based on this notion ofcoherence physical currents and in terms
 of elementary physics there's the the fact that uh you know objectscan bump against each other
 and the fact that they can occlude each other so these arethings that we are essentially born with
 or at least that we are going to be acquiring extremely earlybecause really
 hard wire to acquire them so a bunch of

1:39:56
Speaker 0 :points
 pixels that move together on objects are partly the same object yes i meani mean that like i don't i don't smoke
 weed but if i did that's something i could sitlike all night and just like think about
 i remember right in your paper just object-ness i wasn'tself-aware i guess of how that
 particular prior that that's such a fascinating priorthat like and that's that's the most


1:40:28
Speaker 1 :basic one but


1:40:31
Speaker 0 :yes just identity just yeah object yes
 it's it's very basic i suppose but it's so fundamental is this phenomenal

1:40:39
Speaker 1 :team and cognition
 yeah and uh the second prior that's also fundamental isagent-ness which is not a real world a
 real world but so agentness the fact that some ofthese objects
 uh that you that you segment your environment intosome of these objects are agents so
 what's an agent it's uh basically it's an object thathas
 goals um so that has what that has goals this this capable of person goals so forinstance if you see
 two dots uh moving in in a roughly synchronized fashion you willintuitively
 infer that one of the dots is pursuing the otherso that one of the dots is
 uh and and one of the dots is an agent and its goal is to avoid the other dotand one of the dots the other dot
 is also an asian and its goal is to catchthe first start pelkey has shown that
 babies you know as young as three months identifyuh agentness and goal directedness
 in their environment another prior is basic you know geometry and topologylike the notion of distance the ability
 to navigate in your environment and so on this issomething that is fundamentally
 hardwired into our brain it's in fact backed by very specificneural mechanisms
 like for instance grid cells and plate cellsso it's it's something that's literally
 hard coded at the at the new level uh you know you know hypocampus and thelast prior
 would be the notion of numbers like numbers are not actually culturalconstructs
 we are intuitively innately able to do some basic counting and to comparequantities
 uh so it doesn't mean we can do arbitrary arithmeticuh uh counting the actual accounting


1:42:39
Speaker 0 :

1:42:40
Speaker 1 :scanning like counting one two three ish
 then maybe more than three uh you can also comparequantities if i give you
 uh uh three dots and five dots you can tell the thethe side with five dots there's more
 dots uh so this is actually an innate uh prior um sothat said the list may not be exhaustive
 uh so spelke is still you know pursuingthe potential existence of new knowledge
 systems for instance uh knowledge systems that would dealwith social
 uh relationships yeah yeah i mean

1:43:17
Speaker 0 :which is which is much much less


1:43:19
Speaker 1 :relevant uh uh
 to something like arc or iq testing

1:43:25
Speaker 0 :right so there could be stuff
 that's uh like like you said rotation symmetry is really interesting it's very

1:43:31
Speaker 1 :likely that there is
 uh speaking about rotation that there is uh in the braina hard-coded system that is capable of
 performing rotations uh one one famous experiment uh thatpeople did in the
 uh i don't remember who it was exactly but in the inthe 70s was that
 people found that if you asked people if you give themuh two different shapes and one of the
 shapes is a rotated version of the first shapeand you ask them
 is is that shape a related version of first step or notwhat you see is that the time it takes
 people to answer is linearly proportional rightto the angle of rotation so it's almost
 like you have in somewhere in your brain like a turntable um with a fixed speedand if you want to know if two two
 objects uh uh are rotated version of each other youput the object on the turntable
 you let it move around a little bit and then you and then you stop when youhave a match and and that that's really
 interesting

1:44:41
Speaker 0 :so what's the arc challenge so


1:44:42
Speaker 1 :in in the paper outline you know all
 these principles that a good test of machine intelligenceand humanitarian should follow
 and the arc challenge is one attempt to embody as many of these principles aspossible
 so i don't think it's it's anywhere near a perfect attemptright it does not actually follow every
 principle but it is what i was able to do given thegiven the constraints
 so the format of arc is very similar to classic iq tests in particularravens progressive mattresses ravens
 yeah ravens privacy mattresses i mean if you've done like you test in the pastyou know where that is probably
 at least you've seen it even if you don't know what it's called andso um you have a set of uh tasks
 that's what they're called and for each task you haveum training data which is a set of
 input and output pairs so i uh an input or output pair is a grid of colorsbasically the grid the size of the
 grades these variables is the size of the grid is variableand um you're given an input
 and you must transform it into the proper outputsright and so you're shown a few
 demonstrations of a task in the form of existing inputoutput pairs and then you're given a new
 input and you must provide you must producethe correct output and
 the assumptions in arc is that every task shouldonly require
 cool knowledge priors should not require anyoutside knowledge so for instance uh no
 language uh no english nothing like this uh newconcepts
 uh taken from uh our human experience liketrees dogs cats and so on so only
 uh tasks that are reasoning tasks that are built on top ofa core knowledge priors and some of the
 tasks are um actually explicitly trying to probe uhspecific forms of abstraction right
 uh part of the reason why i wanted to create arcis i'm a big believer in
 you know when you're faced with uh a problem as murkyas understanding how to autonomously
 generate abstraction in a machine you have to co-evolve thesolution
 and the problem and so part of the reason why i design act was toclarify my ideas about the nature of
 abstraction right and some of the tasks are actuallydesigned to
 to probe uh bits of that theory and there are things that areturned out to be very easy for humans to
 perform including young kids right but turn out to benear impossible informations so whatever


1:47:51
Speaker 0 :you learn from the nature of abstraction
 uh from from designing that like what can you clarify what you meanone of the things you wanted to try to
 understand was this uh idea of abstraction

1:48:06
Speaker 1 :yes so clarifying uh my own ideas about
 abstraction by forcing myself to produce tasks thatwould require
 uh the ability to produce that form of abstraction in order to solve them

1:48:20
Speaker 0 :got it okay so and by the way just uh i
 mean people should check out i'll probably overlay if you're watching thevideo part but the
 the grid input output with the different colors on the gridand that's it that's i mean it's a very
 simple world but it's kind of beautiful it's it's

1:48:37
Speaker 1 :very similar to classic acutes like it's
 not very original in that sense the main difference with iq tests is thatwe make the priors explicit which is not
 usually the case in iq test so you make it explicit that everythingshould only be built
 out of core knowledge priors i also think it's generallymore more diverse than iq tests in
 general and it's it perhaps requires a bit moremanual work to produce solutions because
 you have to to click around on a grid for a while sometimes the grades can beas large as 30 by 30 cells


1:49:13
Speaker 0 :so how did you come up um if you can
 reveal uh with the questions like what's the process of the questions was itmostly you
 yeah that came up with the questions what uh how difficult is it to come upwith a question
 like is this um scalable to a much larger number if you think youknow with iq tests you might
 not necessarily want to or need it to be scalablewith machines it's possible you
 could argue that it needs to be scalable

1:49:42
Speaker 1 :so there are a thousand questions
 a thousand tasks yes wow including the test and the private test seti think it's fairly difficult in the
 sense that a big requirement is that every task should be noveland unique and unpredictable right like
 you don't want to create your your own little world that isuh simple enough that it would be
 possible for a human to reverse and generate and write downan algorithm that could generate every
 possible arc task and their solution for instance that we completely invalidatedthe test so
 you're constantly coming up on new stuff

1:50:20
Speaker 0 :

1:50:21
Speaker 1 :you need yeah you need a source
 of novelty of unthinkable novelty and one thing ifound is that
 as a human uh you are not a very good sourceof uh unthinkable novelty and so you
 have to pace the creation of these tasks quite abit there are only so many
 unique tasks that you can do in a given day

1:50:45
Speaker 0 :so that means coming up with truly
 original new ideas um did psychedelics help you at all i'mjust gonna
 but i mean that's fascinating to think about like so you would be likewalking or something like that are you
 constantly thinking of something totally new

1:51:03
Speaker 1 :yes i mean this is hard


1:51:05
Speaker 0 :

1:51:07
Speaker 1 :this is yeah i i i mean i i'm not saying
 i've done anywhere near a perfect job at it uh there is someamount of redundancy and there are many
 imperfections in arc so that said you should you shouldconsider arc as a work in progress
 it is not uh the definitive state uh where where the the arc tasks todayare not
 definitive states of the test i want to keep refining itum in the future i also think it should
 be possible to open up the creation of tasksto a broad audience to do crowdsourcing
 um that would involve several levels offiltering obviously
 but i think it's possible to apply crowdsourcing to to develop a muchbigger and much more diverse arc data
 set that would also be free of potentiallyyou know some of
 my own personal biases but is there always need to be

1:51:57
Speaker 0 :a part of arc that's the test like
 is hidden yes absolutely it is

1:52:03
Speaker 1 :impressive that uh the
 test that you're using to actually benchmarkalgorithms is not accessible to the
 people developing these algorithms because otherwise what's going to happenis that the human engineers are just
 going to solve the tasks themselves and andencode their solution in program form
 but that again what you're seeing here isthe process of intelligence happening in
 the mind of the human and and then you're just uh capturing itscrystallized output but that
 crystallized output is not the same thing as the processgenerated that's right it's not
 intelligent in itself so what uh

1:52:41
Speaker 0 :by the way the idea of crowdsourcing it
 is fascinating i think i think the creation ofquestions
 is really exciting for people i think i think there's a lot of really brilliantpeople out there that love to create
 these kinds of stuff

1:52:56
Speaker 1 :yeah one thing that uh that kind of
 surprised me that i wasn't expecting is thatlots of people seem to actually enjoy
 ark as a as a kind of game and i was really seeing it as as a testas a benchmark
 uh of uh a fluid uh general intelligence and lots of people just including kidsjust started you know enjoying it as a
 game so i think that's that's encouragingyeah i'm fascinated by there's a world


1:53:21
Speaker 0 :of people who create iq
 questions i think i think that's a cool uh it's a coolactivity for machines that for humans
 and people humans are themselves fascinated bytaking the questions like
 you know measuring their own intelligencei mean that's just really compelling
 it's really interesting to me too it helpsone of the cool things about arc you
 said it's kind of uh inspired by iq tests or whatever follows a similarprocess but because of its nature
 because of the context in which it lives it immediately forces you to think aboutthe nature of intelligence as opposed to
 just a test of your own like it forces you to really think there's i don't knowif it's if it's within the question
 inherent in the question or just the fact that it livesin the test that's supposed to be a test
 of machine intelligence absolutely as you

1:54:16
Speaker 1 :as you solve arc tasks as a human
 you will uh be forced to basically introspectyeah higher how you come up with
 solutions and that forces you to reflect on uh the human problem solving processand the way your own mind uh generates
 uh abstract representations of the problems uh it's exposed toi i think it's due to the fact that the
 set of core knowledge priors that arc is built upon is so small it'sall
 a recombination of a very very small set of assumptions

1:55:01
Speaker 0 :okay so what's the future of ark so you
 you held arc as a challenge as part of like a kegel competitionyes calgary competition and
 uh what do you think do you think that's something that continues forfive years ten years like just continues
 growing yes absolutely

1:55:18
Speaker 1 :so arc itself will keep evolving so i've
 talked about crowdsourcing i think that's a that's agood avenue another thing i'm starting
 is i'll be collaborating with folks fromthe psychology department at nyu
 to do human testing on arc and i think there are lots of interesting questionsyou can start asking especially as you
 start correlating machine solutions to arc tasks and andthe human characteristics of solutions
 like for instance you can try to see if there's a relationshipbetween the
 human perceived difficulty of a task and the machine person yes and andexactly some measure of machine
 perceived difficulties yeah it's a nice big playground in which to

1:56:04
Speaker 0 :explore this very difference
 it's the same thing as we talked about the autonomous vehicles the things thatcould be difficult for humans might be
 very different than the things that yes absolutely and uh formalizing or makingexplicit
 that difference in difficulty will teach us something may teach us somethingfundamental about intelligence


1:56:22
Speaker 1 :so one thing i think we did well uh with
 arc is that it's proving to be a veryuh actionable test in the sense that
 uh machine performance and arcs started at very muchzero initially while you know
 humans found actually the tasks very easyand that that alone was like a big red
 flashing light saying that something is going onand that we are missing something and at
 the same time uh machine performance did not stay atzero for very long actually within two
 weeks of the carol competition we started havinga non-zero number and now the state of
 the art is around uh twenty percent of the test set uhsolved
 um and so arc is actually a challenge whereour capabilities start at zero which
 indicates the need for progress but it's also not an impossible changeit's not accessible you can start making
 progress basically right away at the same timewe are still very far from having solved
 it and that's actually a very positive outcome of thecompetition is that the competition has
 has proven that there was no obvious shortcut to solve these tasksright yeah so the test held up yeah


1:57:43
Speaker 0 :

1:57:43
Speaker 1 :exactly that was the primary reason to
 do the cargo competition is to check if some some you know clever person wasgoing to
 hack the benchmark and that did not happenright like people who are solving the
 tasks are essentially doing it uh uh well in a way they're they'rethey're actually exploiting some flaws
 of art that we will need to address in the future especially they'reessentially anticipating what sort of uh
 tasks may be contained in the test sets

1:58:14
Speaker 0 :right right um which is kind of
 yeah that's the kind of hacking it's it's human hacking of the town yes

1:58:20
Speaker 1 :that that said you know uh uh with the
 state of the art it's like uh 20 percent we're still very very faruh from even level which is closer to
 100 and so and i i do believe that you knowit will
 it will take a while uh until we reach a human parityon ark and that by the time we have
 human party we will have ai systems that areprobably pretty close to human level
 in terms of general fluid intelligence which is i mean it'sthey're not going to be necessarily
 human-like they're not necessarily uh you would not necessarily recognizethem as you know being an egi
 but they would be capable of a degree of generalization that matches thegeneralization
 performed by human food intelligence sure i mean this is a good point in

1:59:12
Speaker 0 :terms of
 general flu intelligence to mention in your paper you describe different kindsof generalizations
 uh local broad extreme and there's kind of a hierarchy that you formso when we say generalizations
 what are we talking about what kinds are there right

1:59:33
Speaker 1 :so uh generalization is is very old idea
 i mean it's even older than machine learning inthe context of machine learning you say
 a system generalizes if it can uh make sense of an input it has it has notyet seen
 and that's what i would call a system-centricuh generalization you is generalization
 with respect to novelty uh for the specific system you'reconsidering so i think a good test of
 intelligence should actually uh deal with uh developer awaregeneralization which is slightly
 stronger than system-centric transition so developer generalization developeraware generalization would be
 the ability to generalize to novelty or uncertainty thatnot only the system itself has not
 accessed to but the developer of the systemcould not have access to either that
 that's a fascinating that's a

2:00:30
Speaker 0 :fascinating meta definition
 so like the system is uh it's basically the edge case thing we're talking aboutwith autonomous vehicles
 yes neither the developer nor the system know about the edge casesso it's up to they get the system should
 be able to generalize the thing that that uh nobody expected neither thedesigner of the training data
 nor obviously the contents of the trainingthat's a fascinating definition so you


2:01:00
Speaker 1 :can see generalization degrees of
 generalization as a spectrum and the lowest level is what machinelearning
 is trying to do is the assumption that any new situation is going to be sampledfrom a static distribution of possible
 situations and that you already have arepresentative sample of that
 distribution that's your training data and so in machine learning yougeneralize to a new sample from a known
 distribution and the ways in which your new samplewill be
 new or different are ways that are already understood by the developers ofthe system
 so you are generalizing to known unknownsfor one specific task that's what you
 would call robustness you are robust to things like noisesmall variations and so on
 um for one a fixed known distribution that that you know throughyour training data
 and a higher degree would be flexibility in machine intelligence soflexibility would be
 something like an l5 cell driving car or maybe a robot that canyou know pass the the coffee cup test
 which is the notion that you would be given arandom kitchen
 uh somewhere in the country and you would have to you knowgo make a cup of coffee in that kitchen
 right so flexibility would be the ability to deal withunknown unknowns so things that could
 not uh dimensions of viability that couldnot have been possibly foreseen
 by the creators of the system within one specific taskso generalizing to the long tail of
 situations in self-driving for instance would beflexibility so you have robustness
 flexibility and finally you would have extreme generalizationwhich is basically flexibility but
 instead of just considering one specific domain like driving or domestic roboticsyou're considering an open-ended range
 of possible domains so a robot would be capable ofextreme generalization if let's say it's
 designed and trained uh to to for cooking for instanceum and if i if i buy the robot
 and if i'm able uh if it's able uh to teach itselfgardening in in a couple weeks it would
 be capable of extreme generalization for instanceso the ultimate goal is extreme


2:03:33
Speaker 0 :generalization yes


2:03:34
Speaker 1 :so be uh creating a system that is
 so general that it could essentially achieve a human skill parity overarbitrary tasks and arbitrary domains
 with the same level of you know improvisation and adaptation power ashumans when
 when it encounters new situations and it would do souh over basically the same range of
 possible domains and tasks uh as humans and using this essentiallythe same amount of training experience
 of practice as humans would require that will be human level extremegeneralization
 so i i don't actually think humans are anywhere near the uhoptimal intelligence bound if there is
 such a thing so i think for humans or in general in

2:04:23
Speaker 0 :

2:04:24
Speaker 1 :general
 i think it's quite likely you know that there is ana hard limit to how intelligent
 any system can be but at the same time i don't think humans are anywhere nearthat limit


2:04:39
Speaker 0 :yeah last time i think we talked i think
 you had this idea that uh we're only as intelligent as theproblems we face
 sort of uh yes we are upper bounded by the problem soin a way yes we are we are bounded by on


2:04:52
Speaker 1 :our environments
 and we are bounded by the problems we try to solve

2:04:58
Speaker 0 :yeah yeah what do you make of neuralink
 and uh outsourcing some of thebrain power like bring computer
 interfaces do you think we can expand our augment our intelligence

2:05:14
Speaker 1 :i am fairly skeptical
 of neural interfaces because they are tryingto fix one specific bottleneck
 in in human machine cognition which is the bandwidth bottleneck input andoutput of information
 in the brain and my perception of the problem is that bandwidth is notat this time a bottleneck at all
 meaning that we already have sensors that enable us toto take in far more information than
 what we can actually process well to push back on

2:05:52
Speaker 0 :that a little bit
 uh to sort of play dell's advocate a little bit isif you look at the internet wikipedia
 let's say wikipedia i would say that humans after the adventof wikipedia
 are much more intelligent yes

2:06:07
Speaker 1 :i think that's a good one but that's
 also not about that's about um externalizing our intelligencevia uh uh information processing systems
 the accidental function processing system which is very different fromuh brain computer interfaces right but
 the question is

2:06:25
Speaker 0 :whether if we have direct access if our
 brain has direct access to wikipedia with our brain already has

2:06:33
Speaker 1 :direct access to wikipedia
 it's on your phone and you have your hands and your eyesand your ears and so on uh to access
 that information and the speed at which you can access itis bottlenecked by the customer i think


2:06:45
Speaker 0 :

2:06:46
Speaker 1 :it's already closed
 fairly close to optimal which is why speed reading for instancedoes not work yeah the faster you read
 the less you understand but maybe it's because it uses the eyes

2:06:57
Speaker 0 :so maybe
 um so i don't believe so i think you

2:07:01
Speaker 1 :know the brain is very slow
 um it typically operates you know the fastestthings that happen in the brain at the
 level of 50 milliseconds uh forming a conscious out canpotentially take
 entire seconds right and you can already read pretty fastso i think the speed at which you can
 take information in and even the speed at which you canadd with information
 can only be very incrementally improved maybe i think if you're a very fasttyper if you're a very trained typer
 the speed at which you can express your thoughts is already a speedat which you can form your thoughts


2:07:41
Speaker 0 :right so that's kind of an idea that
 there are fundamental bottlenecks to the human mind but it's possiblethat the everything we have in the human
 mind is just to be able to survive in theenvironment and
 there's a lot more to expand maybe you know you said this the speed of thethought so yeah i i think


2:08:03
Speaker 1 :augmenting human intelligence is a very
 valid and very powerful avenue right andthat's what computers
 are about in fact that's what you know all of cultureand civilization is about they are
 culture is externalized cognition and we rely onculture
 to think constantly yeah yeah i mean

2:08:25
Speaker 0 :that's that's another
 yeah that's not just not just computers

2:08:27
Speaker 1 :not just phones and the internet i mean
 all of culture like language for instance is a form of externalrecognition books are obviously
 external recognition yeah that's right and you you can scalethat external exclamation you know far
 beyond the capability of the human brain and you could see youknow civ
 civilization itself is um it has capabilities that are far beyondany individual brain
 and will keep scaling it because it's not rebound by individual brainsit's a different kind of system yeah and


2:09:02
Speaker 0 :and that system includes non-human
 non-humans first of all includes all the other biological systems which areprobably contributing to the overall
 intelligence of the organism and then yeah computers are part of it

2:09:14
Speaker 1 :no non-human systems probably not
 contributing much but ais are definitely contributing to thatlike google search for instance
 big part of it yeah yeah a huge part

2:09:27
Speaker 0 :a part we can probably introspect like
 how the world has changed in the past 20 yearsit's probably very difficult for us to
 be able to understand until of course whoever created thesimulation we're in is
 probably doing metrics measuring the progressthere was probably a big spike in
 performance uh they're enjoying they're enjoyingthis
 so what are your thoughts on um the touring test and the lobner prizewhich is the
 you know one of the most famous attempts at the test of human intelligenceuh sorry of artificial intelligence
 by uh doing a natural language open dialoguetest that's test that's uh
 judged by humans as far as how well the machine did

2:10:19
Speaker 1 :so i'm not a fan of the chewing test
 itself or any of its variants for two reasonsso first of all it's um
 it's really copping out of trying to define and measureintelligence because it's entirely
 outsourcing that to a panel of human judges and these human judgesthey may not themselves have any proper
 methodology they may not themselves have any properdefinition of intelligence
 they may not be reliable so the joint is already failingone of the core psychometrics principles
 which is reliability because you have biased human judges uh it's alsoviolating the
 the standardization requirement and the freedom from bias requirementand so it's really a coop out because
 you are outsourcing everything that matters which isprecisely describing
 intelligence and finding a standalone testuh um to measure it you're outsourcing
 everything to uh to people so it's really cool and bythe way
 uh we should keep in mind that uh when turingproposed uh the imitation game it was
 not meaning for the imitation game to be anactual
 uh goal for the field of ai an actual test of intelligence he was usinguh it was using the imitation game as a
 thought experiment in a philosophical discussionin his uh 1950 paper he was
 trying to argue that theoretically it should be possiblefor something very much like the human
 mind indistinguishable from the human mindto be encoded in ensuring machine and at
 the time that was that was you know uma very daring idea it was stretching
 credibility but uh nowadays i think it's it's fairlywell accepted that the
 the mind is an information processing system and that you could probablyencode it
 into a computer so another reason why i'm not a fan of this type of test isthat
 it the incentives that it creates are incentives that are not conduciveto proper scientific research
 if your goal is to trick to convince a panel of human judges that they'retalking to a human
 then you have an incentive to rely on on tricks and press the digitizationin the same way that let's say you're
 doing physics and you want to solve teleportationand what if the test that you set out to
 pass is you need to convince a panel of judges that teleportationtook place
 and and they're just sitting there and watching what you're doingand that is something that you can
 achieve with you know david copperfield could couldachieve it in his in his show at vegas
 right but is it and what he's doing is veryelaborate
 but it's not actually it's not physics it's not making any progress youknow understanding of the universe right
 to push back on that it's possible

2:13:34
Speaker 0 :that's the hope with these kinds of
 subjective evaluations is that it's easier to solve itgenerally than it is to
 come up with tricks that convince a large number of judgments that's thewhole


2:13:47
Speaker 1 :in practice when it turns out that it's
 very easy to deceive people in the same way that you know you canyou can do magic in vegas you can
 actually very easily convince people that they'retalking to human when they're actually
 talking to liberalism i just disagree i disagree with that i

2:14:01
Speaker 0 :think it's easy i i would i would push
 it's not easy it's uh uh it's doable

2:14:08
Speaker 1 :it's very easy because i wouldn't say
 it's very easy though we are biased like we have theory of mind we areconstantly projecting
 emotions intentions yes uh uh agentness agentness is one of our coreinnate priors right we are projecting
 these things on everything around us likeif you if you paint a smiley on a rock
 the rock becomes happy you know eyes and because we have thisextreme bias that permeates
 everything everything we see around this it's actually pretty easy to trickpeople
 like this it is very very short i so

2:14:44
Speaker 0 :totally disagree with that
 you brilliantly put there's a huge it's athe anthropomorphization that we
 naturally do the agentness of that word is that real word but no

2:14:54
Speaker 1 :it's not a real word i like it but it's
 exactly why it's useful well it's a useful word let's

2:14:58
Speaker 0 :make it real it's a huge help
 but i still think it's really difficult to convince uhif you do like the alexa prize
 formulation where you know you talk for an hourlike there's formulations of the test
 you can create where it's very difficult

2:15:13
Speaker 1 :so i like i like the extra price better
 because it's more pragmatic it's more practicalit's
 actually incentivizing developers to create something that's usefulyeah as a as as a a human
 machine interface uh so that's slightly betterthan just the imitation so i like your
 your

2:15:33
Speaker 0 :your ideas like a test which hopefully
 help us in creating intelligent systems as a result like if you create a systemthat passes it
 it'll be useful for creating further intelligence systems

2:15:45
Speaker 1 :yes at least yeah i mean i'm just to


2:15:47
Speaker 0 :kind of
 comment i'm a little bit surprised how little inspiration people draw fromthe touring test today you know
 the media and the popular press might write about it every once in a whilethe philosophers might talk about it but
 like most engineers are not really inspiredby it and
 i know i know you don't like the touring testbut uh we'll have this argument another
 time you know i there's something inspiring about it ithink that


2:16:18
Speaker 1 :as as a philosophical device in a
 physical discussion i think there is something very interesting about it idon't think it is
 in practical terms i don't think it's it's conducive to to progressand one of the reasons why is that you
 know i think being very human-like beingindistinguishable from a human
 is actually the very last step in the creation of machine intelligence thatthe first
 ais that will show strong generalization uh uh in in uh that that will actuallyuh implement human like broad cognitive
 abilities they will not actually be able to lookanything
 uh like humans human likeness is the very last step in that processand so a good test is a test that points
 you towards the first step uh on the ladder not towards the top ofthe ladder right yeah so to push back on


2:17:10
Speaker 0 :that so i guess
 i usually agree with you on most things i remember you i think at some pointtweeting
 something about the turing test not being being counterproductive orsomething like that
 and i think a lot of very smart people agree with that iuh uh a uh you know uh
 computation speaking not very smart person uh disagree with that because ithink there's some magic to the
 interactivity interactivity with other humans so topush to play devil's advocate on your
 statement it's possible that in order todemonstrate the
 the generalization abilities of a system you have toshow your ability in conversation show
 your ability to adjust adapt to the conversationthrough not just like as a standalone
 system but through the process of like theinteraction like game theoretic
 where you're you really are changing the environment by your actionsso in the arc challenge for example
 you're an observer you can't you can't scarethe test into into changing you can't
 talk to the test you can't play with it so there's someaspect of that interactivity
 that becomes highly subjective but it feels like it could be conduciveto yeah generalization you make a great


2:18:29
Speaker 1 :point the interactivity
 is a very good setting to force the system to showadaptation to shoot generalization uh
 that that said you at the same time uh it's not something very scalable becauseyou rely on human judges
 it's not something reliable because the images may not may not so you don't likehuman judges


2:18:50
Speaker 0 :basically yes and i think so i i love


2:18:52
Speaker 1 :the idea of interactivity
 um i initially wanted an arc test that had some amount of interactivitywhere your score on a task would not be
 one or zero if you can solve it or not but would be thenumber of attempts
 that you can make before you hit the right solution whichmeans that now you can start applying
 the scientific method as you solve our tasks that you canstart formulating hypothesis
 and and and probing the system to see whether the hypothesis isthe observation will match the buddhists
 or not it would be amazing if you could also

2:19:30
Speaker 0 :even higher level than that measure the
 quality of your attempts which of course is impossible but againthat's gets subjective yes like how good
 was your thinking like it's yeah how efficient

2:19:42
Speaker 1 :was so one thing that's interesting
 about this notion of scoring you as how many attempts youneed is that you can start producing
 tasks that are way more ambiguous right right because

2:19:56
Speaker 0 :

2:19:56
Speaker 1 :you can with the problem with the with
 the different attempts you can actually probe that ambiguity right right

2:20:04
Speaker 0 :so that's in a sense which yeah so
 it's how good can you adapt to the uncertaintyand reduce the uncertainty yes


2:20:16
Speaker 1 :it's half fast with is the efficiency
 with which to reduce uncertainty in in program space exactly verydifficult to come up with that kind of
 test though yeah so uh i would love to be able to createsomething like this in practice
 it would be it would be very very difficult but yes but uh

2:20:33
Speaker 0 :i mean what you're doing what you've
 done with the arc challenge is is uh brilliant i'm also not i'msurprised that it's not more popular
 but i think it's picking up what does it

2:20:43
Speaker 1 :snitch it does
 yeah what are your thoughts about

2:20:45
Speaker 0 :another test that
 talks with marcus hutter he has the harder prize forcompression of human knowledge and the
 idea is really sort of quantify like reduce the test ofintelligence purely to just
 ability to compress what's your thoughts about this intelligence that'scompression


2:21:05
Speaker 1 :i mean it's a it's a very uh fun test
 because it's it's such a simple idea like you're given wikipedia basicallyenglish wikipedia
 and you must compress it and so it stems fromthe idea that cognition is compression
 that the brain is basically a compression algorithm this is a very oldidea
 it's a very i think striking and beautiful idea i used to believe ituh i eventually had to realize that it
 was it was very much a flawed idea so i no longerbelieve that compression
 is recognition is compression so but i can tell youwhat's the difference so it's very easy
 to believe that cognition and compression are thesame thing because
 uh so jeff hawkins for instance says that cognitionis prediction and of course prediction
 is basically the same thing as compression right it'sjust
 including the temporal axis and it's very easy to believe this becausecompression is something that we do
 all the time very naturally we are constantly you knowcompressing information we are um
 uh constantly trying we have this bias towards simplicity wewe're constantly trying to organize
 things in our mind and around us to be more regular right souh it's it's a beautiful idea it's very
 easy to believe uh there is a big difference between uhwhat we do with our brains
 and and compression so compression is actually kind ofa tool in the human cognitive toolkits
 that is is used in many ways but it's just atool it is not
 it is a tool for cognition it is not cognition itselfand the big fundamental difference is
 that cognition is about being ableto operate in future situations
 that include fundamental uncertainty and novelty so for instance consider achild
 at age 10 and so they have 10 years of life experience they've gotten youknow pain pleasure
 rewards and and punishment in a period of timeif you were to generate the shortest
 behavioral program that would have basicallyrun that child over this 10 years in an
 optimal way right the shortest optimal behavioralprogram given the
 experience of that child so far well that programthat that compress program this is what
 you would get if the mind of the child was a compression algorithm essentiallyum would be utterly
 enable inappropriate to process the next 70 years in the in the life of the childso in the models with
 we build of the world we are not trying to make them actuallyoptimally compressed we are we are using
 compression as a tool to promote simplicity andefficiency in our models
 but they are not perfectly compressed because they need to includethings that are seemingly useless today
 that have seemingly been useless so far but that may turn out to be usefulin the future because you just don't
 know the future unless that's the fundamental principle uh thatcognition
 that intelligence arises from is that you need to be able to run appropriatebehavioral programs except you have
 absolutely no idea what sort of context environmentsituation
 are going to be running in and you have to deal with that with thatuncertainty with that future normality
 so an analogy an analogy that you can make iswith investing for instance um
 if i look at the past uh uh you know 20 years of stock market dataand i use a compression algorithm to
 figure out the best trading strategy it's going to be youknow you buy apple stock then maybe the
 past few years you buy tesla stock or somethingbut is that strategy still going to be
 true for the next 20 years well actually probably not which is whyif you're a smart investor you're not
 you're not just going to be following the strategy thatcorresponds to compression of the past
 uh you're going to be following uh uh you're going to have a balancedportfolio
 yeah right because you just don't know what's going to run

2:25:37
Speaker 0 :i mean i guess in that same sense the
 compression is analogous to what you talked about which is likelocal or robust generalization
 versus extreme generalization it's much closer to thatside of being able to generalize in
 in a local sense that's why you know as

2:25:54
Speaker 1 :humans as uh when we are when we are
 children um in our education so a lot of it isdriven by place
 even by curiosity uh we we are not efficiently compressing things we'reactually exploring
 we are um retaining all kinds of uh uh things from our environment that thatseem to be completely useless because
 they might turn out to be eventually useful rightand it's it's that's what cognition is
 really about and that what makes it antagonistic to compression is thatit is about hedging for future
 uncertainty and that's efficient into compression yesespecially hedging so
 uh cognition leverages compression as a tool to promote uhuh to promote efficiency right and so
 in that sense in our models it's like

2:26:48
Speaker 0 :einstein said
 make it simpler but not however that quote goes but nottoo simple so you want to compression
 simplifies things but you don't want to make it too simple

2:27:00
Speaker 1 :yes so a good model of the world is
 going to include all kinds of things that are completelyuseless actually just because just in
 case yes because you need diversity in thesame way that in your portfolio you need
 all kinds of stocks that that may not have performed well so farbut you need diversity and the reason
 you need diversity because fundamentally you don't know what you'redoing and the same is true of the human
 mind is that it needs to to behaveappropriately
 in the future and it has no idea what the future is going to be likeit's a bit it's not going to be like the
 past so compressing the past is not appropriate because the pastis not uh it's not proactive in the
 future

2:27:41
Speaker 0 :yeah history repeats itself but not
 perfectly i don't think i asked you last time themost inappropriately absurd question
 we've talked a lot about intelligence but you know the bigger question fromintelligence is of meaning you know
 intelligence systems are kind of goal-orientedthere's throws optimizing for goal if
 you look at the harder prize actually i mean there'salways there's always a clean
 formulation of a goal but the natural questions for us humanssince we don't know our objective
 function is what is the meaning of it allso the absurd question is what
 francois chole do you think is the meaning of lifewhat's the meaning of life yeah that's a


2:28:26
Speaker 1 :that's a big question
 um and i think i can i can you know give you my answer at leastone of my answers and
 so you know the one thing that's uh very importantuh in understanding who we are is that
 everything that makes up uh that makes up ourselves it makes up we areeven even your most personal thoughts
 is not actually your own right like even your most personal thoughtsare expressed in words that you did not
 invent and are built on concepts and images that you did notinvent
 we are very much uh cultural beings right well we are made of culture we arenot that what makes us different from
 animals for instance right so we are everything aboutourselves
 is an echo of the past an echo of people who lived uh before usright that's who we are and
 in the same way if we manage to contributesomething to the collective edifice of
 culture a new idea maybe a beautiful piece ofmusic a work of art
 a grand theory a new word maybe um that somethingis is going to become a part
 of the minds of future humans essentiallyforever so everything we do
 creates ripples right that propagates into the futureand i i and that that's in a way this is
 this is our path to immortality is thatas we contribute things to culture
 culture in turn in turn becomes future humansand we keep influencing people you know
 thousands of years from now so our actions todaycreate reports and these reports i think
 basically sum up the meaning of life like in the same way that we are the thesum
 um of the interactions between many different reports that came from ourpast
 we are ourselves creating reports that will propagate into the futureand that's why you know we should be
 this seems like perhaps anything to say but we should bekind to others during our time
 on earth because every act of kindness creates reports andand in reverse every act of violence
 also creates reports and you want you want to carefully choose which kindof reports you want to create
 and you want to propagate into the future and in your case

2:31:17
Speaker 0 :first of all beautifully put but in your
 case creating ripples into the future human and future agi systems

2:31:27
Speaker 1 :yes it's fascinating all success


2:31:33
Speaker 0 :i don't think there's a better way to
 end it francois as always for second time and i'm sure many timesin the future it's been a huge honor
 you know one of the most brilliant people in the machine learning computerscience
 science world again that's a huge honor thanks for talking today it's been a

2:31:50
Speaker 1 :pleasure thanks a lot for having me
 i really appreciate it thanks for

2:31:54
Speaker 0 :listening to this conversation with
 friend squash chole and thank you to our sponsors babblemaster class
 and cash app click the sponsor links in the description to get a discountand to support this podcast if you enjoy
 this thing subscribe on youtube review five stars on apple podcastfollow on spotify
 support on patreon or connect with me on twitter at lex friedmanand now let me leave you with some words
 from rene descartes in 1668 an except of which francois includes inis on the measure of intelligence paper
 if there were machines which bore a resemblance to our bodiesand imitated our actions as closely as
 possible for all practical purposes we should still have two very certainmeans of recognizing
 that they were not real men the first is that they could never usewords or put together signs as we do in
 order to declare our thoughts to others for we can certainly conceive of amachine so constructed
 that it utters words and even utters words that correspond to bodily actionscausing a change in its organs
 but it is not conceivable that such a machine should produce differentarrangements of words
 so as to give it an appropriately meaningful answer to whatever is saidin his presence as the dullest of men
 can do here descartes is anticipating theturing test and the argument still
 continues to this day secondly he continues even though somemachines might do
 some things as well as we do them or perhaps even betterthey would inevitably fail in others
 which would reveal that they're acting not fromunderstanding but only from the
 disposition of their organs this is incredible quote forwhereas reason is a universal instrument
 which can be used in all kinds of situationsthese organs need some particular action
 hence it is for all practical purposesimpossible for machine to have enough
 different organs to make it act in all the contingencies of life inthe way
 in which our reason makes us act that's the debatebetween mimicry memorization versus
 understanding so thank you for listening and hope tosee you


