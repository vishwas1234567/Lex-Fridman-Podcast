0:00:00
Speaker 1 :you've studied the human mind cognition
 language vision evolution psychology from child to adult from the level ofindividual to the level of our entire
 civilization so I feel like I can start with a simple multiple-choice questionwhat is the meaning of life is it a to
 attain knowledge as Plato said B to attain power as Nietzsche said C toescape death as Ernest Becker said d to
 propagate our genes as Darwin and others have said e there is no meaning as thenihilists have said F knowing the
 meaning of life is beyond our cognitive capabilities as Steven Pinker said basedon my interpretation twenty years ago
 and G none of the above

0:00:47
Speaker 0 :I'd say aid comes closest but I would
 amend that to attaining not only knowledge but fulfillment more generallythat is life health stimulation access
 to the living cultural and social world now this is our meaning of life it's notthe meaning of life if you were to ask
 our genes their meaning is to propagate copies of themselves but that isdistinct from the meaning that the brain
 that they lead to sets for itself so to

0:01:21
Speaker 1 :you knowledge is a small subset or a


0:01:27
Speaker 0 :large subset it's a large subset but
 it's not the entirety of human striding because we also want to interact withpeople we want to experience beauty we
 want to experience the the richness of the natural world but understanding thewhat makes the universe tick is his way
 up there for some of us more than others certainly for me that's that's one of

0:01:54
Speaker 1 :the top five so is that a fundamental
 aspect are you just describing your own preference or is this a fundamentalaspect of human nature is to seek
 knowledge just in your latest book you talk about the the the power theusefulness of rationality and reason so
 on is that a fundamental nature human beings or is it something we

0:02:16
Speaker 0 :should just strive for it's both it is
 we're capable of striving for it because it is one of the things that make uswhat we are Homo sapiens wise men we are
 unusual among animals in the degree to which we acquire knowledge and use it tosurvive we we make tools we strike
 agreements via language we extract poisons we predict the behavior ofanimals we try to get at the workings of
 plants and when I say we I don't just mean we in the modern West but we as aspecies everywhere which is how we've
 managed to occupy every niche on the planet and how we've managed to driveother animals to extinction and the
 refinement of Reason in pursuit of human well-being of health happiness socialrichness cultural richness is our our
 main challenge in the present that is using our intellect using our knowledgeto figure out how the world works how we
 work in order to make discoveries and strike agreements that make us all

0:03:24
Speaker 1 :better off in the long run right and you
 do that almost undeniably and in a data-driven way in a recent book but I'dlike to focus on the artificial
 intelligence aspect of things and not just artificial intelligence but naturalintelligence too so twenty years ago in
 the book you've written on how the mind worksyou conjecture again my right to
 interpret things you could you can correct me if I'm wrong but youconjecture that human thought in the
 brain may be a result of and now we're a massive network of highly interconnectedneurons so from this interconnectivity
 emerges thought compared to artificial neural networks we use for machinelearning today is there something
 fundamentally more complex mysterious even magical about the biological neuralnetworks versus the ones we've been
 starting to use over the past 60 years and it becomes a success in the past 10

0:04:21
Speaker 0 :there is something
 a little bit mysterious about the human neural networks which is that each oneof us who is a neural network knows that
 we ourselves are conscious conscious not of a sense of registering oursurroundings or even registering our
 internal state but in having subjective first-person present-tense experiencethat is when I see red it's not just
 different from green but it just there's there's a redness to it I feel whetheran artificial system would experience
 that or not I don't know and I don't think I can know that's why it'smysterious if we had a perfectly
 lifelike robot that was behaviorally indistinguishable from a human would weattribute consciousness to it or ought
 we to attribute consciousness to it and that's something that it's very hard toknow but putting that aside put inside
 that that largely philosophical question the question is is there some differencebetween the human neural network and the
 ones that we were building in artificial intelligence will mean that we're on thecurrent trajectory not going to reach
 the point where we've got a lifelike robot indistinguishable from a humanbecause the way their neural so-called
 neural networks were organized are different from the way ours areorganized having there's overlap but I
 think there are some some big differences that they're the currentneural networks current so called deep
 learning systems are in reality not all that deep that is they are very good atextracting high order statistical
 regularities but most of the systems don't have a semantic level a level ofactual understanding of who did what to
 who why where how things work what causes what else do you think that kind

0:06:06
Speaker 1 :of thing can emerge as it does so
 artificial you know so much smaller the number of connections and so on in thecurrent human biological networks but do
 you think sort of go to go to consciousness or to go to this higherlevel semantic reasoning about things do
 you think that can emerge with just a larger network with a more richlyweirdly interconnected network


0:06:29
Speaker 0 :separating consciousness because
 consciousness is even a matter of complex a really good oneyeah you could have you could sensibly
 ask the question of whether shrimp are conscious for example they're notterribly complex but maybe they feel
 pain so let's just put that one that part of it aside yet but I think sheersize of a neural network is not enough
 to give it structure and knowledge but if it's suitably engineered then thenwhy not
 that is where neural networks natural selection did a kind of equivalent ofengineering of our brains so I don't
 know there's anything mysterious in the sense that no no system made out ofsilicon could ever do what a human brain
 can do I think it's possible in principle whether it'll ever happendepends not only on how clever we are in
 engineering these systems but whether even we even want to whether that's evena sensible goal that is you can ask the
 question is there any locomotion system that is as as good as a human well wekind of want to do better than a human
 ultimately in terms of legged locomotion there's no reason that humans should beour benchmark they're their tools that
 might be better in some ways it may just be not as maybe that we can't duplicatea natural system because at some point
 it's so much cheaper to use a natural system that we're not going to investmore brainpower and resources so for
 example we don't really have a subsidy and exact substitute for wood we stillbuild houses out of would we still go
 furniture out of wood we like the look we like the feel it's wood has certainproperties that synthetics don't there's
 not that there's any magical or mysterious about wood it's just that theextra steps of duplicating everything
 about wood is something we just haven't bothered because we have wood likewise acotton I mean I'm wearing cotton
 clothing now feels much better than the polyester it's not that cotton hassomething magic in it and it's not that
 if there was that we couldn't ever synthesize something exactly like cottonbut at some point it just it's just not
 worth it we've got cotton and likewise in the case of human intelligence thegoal of making an artificial system that
 is exactly like the human brain is a goal that weno one's gonna pursue to the bitter end
 I suspect because if you want tools that do things better than humans you're notgoing to care whether it does something
 like humans so for example you're diagnosing cancer or particularlywhether why set humans as your benchmark


0:09:00
Speaker 1 :but in in general I suspect you also
 believe that even if the human should not be a benchmark on women's don't wantto imitate humans in their system
 there's a lot to be learned about how to create an artificial intelligence system

0:09:16
Speaker 0 :by studying the human yeah III think
 that's right there in in the same way that to buildflying machines we want understand the
 laws of aerodynamics and including birds but not mimic the birds right but the

0:09:29
Speaker 1 :same laws you have a view on AI
 artificial intelligence and safety that from my perspective is refreshinglyrational or perhaps more importantly has
 elements of positivity to it which I think can be inspiring and empowering asopposed to paralyzing for many people
 including AI researchers the eventual existential threat of AI is obvious notonly possible but obvious and for many
 others including a researchers the threat is not obvious so Elon Musk is isfamously in the highly concerned about
 AI camp saying things like AI is far more dangerous and nuclear weapons andthat AI will likely destroy human
 civilization so in February you said that if Elon was really serious about AIthey the threat of AI he would stop
 building self-driving cars that he's doing very successfully as part of Teslathen he said Wow if even Pinker doesn't
 understand the difference between arrow AI like a car in general AI when thelatter literally has a million times
 more compute power and an open-ended utility function humanity is in deeptrouble so first what did you mean by
 the statement about Elon Musk should stop Bill ourselves driving cars if he'sdeeply concerned


0:10:59
Speaker 0 :not last time that Elon Musk has fired
 off an intemperate tweet well we live in

0:11:04
Speaker 1 :a world where Twitter has power yes yeah


0:11:07
Speaker 0 :I think the the that there are two kinds
 of existential threat that have been discussed in connection with artificialintelligence and I think that they're
 both incoherent one of them is vague fear of AI takeover that it just as wesubjugated animals and less
 technologically advanced people's so if we build something that's more advancedthan us it will inevitably turn us into
 pets or slaves or or domesticated animal equivalentsI think this confuses intelligence with
 a will to power that it so happens that in the intelligence system we are mostfamiliar with namely Homo sapiens we are
 products of natural selection which is a competitive process and so bundledtogether with our problem-solving
 capacity are a number of nasty traits like dominance and exploitation andmaximization of power and glory and
 resources and influence there's no reason to think that sheerproblem-solving capability will set that
 as one of its goals its goals will be whatever we set it its goals as and aslong as someone isn't building a
 megalomaniacal artificial intelligence and there's no reason to think that itwould naturally evolve in that direction
 now you might say well what if we gave it the goal of maximizing its own powersource well that's a pretty stupid goal
 to give a an autonomous system you don't give it that goal I mean that's justself-evident we idiotic so if you look


0:12:39
Speaker 1 :at the history of the world there's been
 a lot of opportunities where engineers could instill in a system destructivepower and they choose not to because
 that's the natural process of

0:12:49
Speaker 0 :Engineering well weapons I mean if
 you're building a weapon its goal is to destroy people and so I think they'regood reasons to not not build certain
 kinds of weapons I think the building nuclear weapons was a massive mistake

0:13:02
Speaker 1 :but probably do you think so
 maybe pause on that because that is one of the serious threats do you think thatit was a mistake in a sense that it was
 should have been stopped early on or do you think it's just anunfortunate event of invention that this
 was invented we think it's possible to stop I guess is the question it's hard

0:13:22
Speaker 0 :to rewind the clock because of course it
 was invented in the context of World War two and the fear that the Nazis mightdevelop one first then once was
 initiated for that reason it was it it was hard to turn off especially sincewinning the war against the Japanese and
 the Nazis was such an overwhelming goal of every responsible person that there'sjust nothing that people wouldn't have
 done then to ensure victory it's quite possible if World War two hadn'thappened that nuclear weapons wouldn't
 have been invented we can't know but I don't think it was by any means anecessity any more than some of the
 other weapon systems that were envisioned but never implemented likeplanes that would disperse poison gas
 over cities like crop dusters or systems to try to do to create earthquakes andtsunamis in enemy countries to weaponize
 the weather weaponize solar flares all kinds of crazy schemes that that wethought the better off I think analogies
 between nuclear weapons and artificial intelligence are fundamentally misguidedbecause the whole point of nuclear
 weapons is to destroy things the point of artificial intelligence is not todestroy things so the analogy is is
 misleading so there's two artificial

0:14:36
Speaker 1 :intelligence you mentioned the first one
 was the intelligence all know hungry

0:14:41
Speaker 0 :yeah the system that we design ourselves
 where we give it the goals goals are external to the means to attain thegoals I if we don't design an artificial
 intelligence system to maximize dominance then it won't maximizedominance it just that we're so familiar
 with Homo sapiens when these two traits come bundled together particularly inmen that we are apt to confuse high
 intelligence with a will to power but that's just an error the other fear isthat we'll be collateral damage that
 will give artificial intelligence a goal like make paperclips and it will pursuethat goal so brilliantly that
 before we can stop it it turns us into paperclips we'll give it the goal ofcuring cancer and it will turn us into
 guinea pigs for lethal experiments or give it the goal of world peace and itsconception of world pieces no people
 therefore no fighting and so it'll kill us all now I think these are utterlyfanciful in fact I think they're
 actually self-defeating they first of all assume that we're going to be sobrilliant that we can design an
 artificial intelligence that can cure cancer but so stupid that we don'tspecify what we mean by curing cancer in
 enough detail that it won't kill us in the process and it assumes that thesystem will be so smart that it can cure
 cancer but so idiotic that it doesn't can't figure out that what we mean bycuring cancer is not killing everyone so
 I think that the the collateral damage scenario the value alignment problem isis also based on a misconception so one


0:16:20
Speaker 1 :of the challenges of course we don't
 know how to build either system currently or are we even close toknowing of course those things can
 change overnight but at this time theorizing about it is very challengingin either direction so that that's
 probably at the core the problem is without that ability to reason about thereal engineering things here at hand is
 your imagination runs away with things exactly but let me sort of ask what doyou think was the motivation the thought
 process of elam Wasco i build autonomous vehicles I study autonomous vehicles Istudied Tesla autopilot I think it is
 one of the greatest currently application large scale application ofartificial intelligence in the world it
 has a potentially a very positive impact on society so how does a person who'screating this very good quote/unquote
 narrow AI system also seem to be so concerned about this other general AIwhat do you think is the motivation
 there what do you think is the thing

0:17:21
Speaker 0 :really you probably have to ask him but
 there and and he is notoriously flamboyant impulsive to the as we havejust seen to the detriment of his own
 goals of the health of a company so I don't know what's going onon his mind you probably have to ask him
 but I don't think the and I don't think the distinction between special-purposea and so-called general is relevant that
 in the same way that special-purpose AI is not going to do anything conceivablein order to attain a goal all
 engineering systems have to are designed to trade off across multiple goalswell we build cars in the first place we
 didn't forget to install brakes because the goal of a car is to go fast itoccurred to people yes you want to go
 fast but not always so you build an brakes too likewise if a car is going tobe autonomous that doesn't and program
 it to take the shortest route to the airport it's not going to take thediagonal and mow down people and trees
 and fences because that's the shortest route that's not what we mean by theshortest route when we program it and
 that's just what and an intelligent system is by definition it takes intoaccount multiple constraints the same is
 true in fact even more true of so-called general intelligence that is if it'sgenuinely intelligent it's not going to
 pursue some goal single-mindedly omitting every other consideration andcollateral effect that's not artificial
 in general intelligence that's that's artificial stupidity I agree with you bythe way on the promise of autonomous
 vehicles for improving human welfare I think it's spectacular and I'msurprised at how little press coverage
 notes that in the United States alone something like 40,000 people die everyyear on the highways vastly more than
 are killed by terrorists and we spend we spent a trillion dollars on a war tocombat deaths by terrorism but half a
 dozen a year whereas if you're an year out 40,000 people are massacred on thehighways which could be brought down to
 very close to zero so I'm with you on the humanitarian benefit let me just

0:19:32
Speaker 1 :mention that it's as a person who's
 building these cars it is it a little bit offensive to me to say thatengineers would be clueless enough not
 to engineer safety into systems I often stay up at night thinking about those40,000 people that are dying and
 everything I tried to engineer is to save those people's lives so every newinvention that I'm super
 excited about every new and the in all the deep learning literature and cvprconferences and nips everything I'm
 super excited about is all grounded in making it safe and help people so I justdon't see how that trajectory can all a
 sudden slip into a situation where intelligence will be highly negative you

0:20:14
Speaker 0 :know you and I certainly agree on that
 and I think that's only the beginning of the potential humanitarian benefits ofartificial intelligence there's been
 enormous attention to what are we going to do with the people whose jobs aremade obsolete by artificial intelligence
 but very little attention given to the fact that the jobs that hooni madeobsolete are horrible jobs the fact that
 people aren't going to be picking crops and making beds and driving trucks andmining coal these are you know soul
 deadening jobs and we have a whole literature sympathizing with the peoplestuck in these menial mind deadening
 dangerous jobs if we can eliminate them this is a fantastic boon to humanity nowgranted we you solve one problem and
 there's another one namely how do we get these people a a decent income but ifwe're smart enough to invent machines
 that can make beds and put away dishes and and handle hospital patients well Ithink we're smart enough to figure out
 how to redistribute income to apportion some of the vast economic savings to thehuman beings who will no longer be
 needed to to make beds okay Sam Harris

0:21:23
Speaker 1 :says that it's obvious that eventually
 AI will be in existential risk he's one of the people says it's obvious we don'tknow when the claim goes but eventually
 it's obvious and because we don't know when we should worry about it now thisis a very interesting argument in my
 eyes so how do you how do we think about time scale how do we think aboutexistential threats when we don't really
 know so little about the threat unlike nuclear weapons perhaps about thisparticular threat that it could happen
 tomorrow right so but very likely won't yeahthey're likely to be a hundred years
 away so how do do we ignore it do how do we talk aboutit do we worry about it what how do we


0:22:12
Speaker 0 :think about those what is it a threat


0:22:14
Speaker 1 :that we can imagine it's within the
 limits of our imagination but not within our limits of understanding - sufficientto accurately predict it but but what


0:22:23
Speaker 0 :what is what is the ether asre AI xai


0:22:27
Speaker 1 :being the existential threat AI can


0:22:31
Speaker 0 :always know like enslaving us or turning
 us into paperclips I think the most

0:22:35
Speaker 1 :compelling from the Sam Harris was fact
 it would be the paperclip situation yeah

0:22:39
Speaker 0 :I mean I just think it's totally
 fanciful I just don't build a system don't give it a don't first of all thecode of engineering is you don't
 implement a system with massive control before testing it now perhaps theculture of engineering will radically
 change then I would worry I don't see any signs that engineers will suddenlydo idiotic things like put a electrical
 power plant in control of a system that they haven't tested first or all ofthese scenarios not only imagine a
 almost a magically powered intelligence you know including things like curecancer which is probably an incoherent
 goal because there's so many different kinds of cancer or bring about worldpeace I mean how do you even specify
 that as a goal but the scenarios also imagine some degree of control of everymolecule in the universe which not only
 is itself unlikely but we would not start to connect these systems toinfrastructure without without testing
 as we would any kind of engineering system now maybe some engineers will beirresponsible and we need legal and
 regulatory and legal responsibilities implemented so that engineers don't dothings that are stupid by their own
 standards but the ii-i've never seen enough of a plausible scenario ofexistential threat to devote large
 amounts of brain power to to forestall it so you believe in the sort of the

0:24:12
Speaker 1 :power and mass of the engineering of
 reason as the argue this book of Reason science and sort ofbe the very thing that puts the
 development of new technology so it's safe and also keeps us safe it's the

0:24:27
Speaker 0 :same and you know granted the same
 culture of safety that currently is part of the engineering mindset for airplanesfor example so yeah I don't think that
 that that should be thrown out the window and that untested all-powerfulsystem should be suddenly implemented
 but there's no reason to think they are and in fact if you look at the progressof artificial intelligence it's been you
 know it's been impressive especially in the last ten years or so but the ideathat suddenly there'll be a step
 function that all of a sudden before we know it it will be all powerful thatthere'll be some kind of recursive
 self-improvement some kind of Foom is also fanciful we certainly by thetechnology that we that were now
 impresses us such as deep learning when you train something on hundreds ofthousands or millions of examples
 they're not hundreds of thousands of problems of which curing cancer is atypical example and so the kind of
 techniques that have allowed AI to increase in the last five years are notthe claim that are going to lead to this
 fantasy of of exponential sudden self-improvement so it's may I thinkit's it's kind of a magical thinking
 it's not based on our understanding of how AI actually works now give me a

0:25:45
Speaker 1 :chance here so you said fanciful magical
 thinking in his TED talk Sam Harris says that thinking about AI killing all humancivilization is somehow fun
 intellectually now I have to say as a scientist engineer I don't find it funbut when I'm having beer with my non-ai
 friends there is indeed something fun and appealing about it like talkingabout an episode of black mirror
 considering if a large meteor is headed towards Earth we were just told a largemeteors headed towards Earth something
 like this and can you relate to this sense of funand do you understand the psychology of


0:26:25
Speaker 0 :it yeah that's a good question
 III personally don't find it fun I find it kind of actually a waste oftime because there are genuine threats
 that we ought to be thinking about like like pandemics like like a cybersecurity vulnerabilities like the
 possibility of nuclear war and certainly climate change this is enough to film itmany conversations without and I think
 there I think Sam did put his finger on something namely that there is acommunity us sometimes called the
 rationality community that delights in using its brain power to come up withscenarios that would not occur to mere
 mortals to less cerebral people so there is a kind of intellectual thrill infinding new things to worry about that
 no one has worried about yet I actually think though that it's notonly is it is a kind of fun that doesn't
 give me particular pleasure but I think there is there can be a pernicious sideto it namely that you overcome people
 with such dread such fatalism that there's so many ways to die toannihilate our civilization that we may
 as well enjoy life while we can there's nothing we can do about it if climatechange doesn't do us in then runaway
 robots will so let's enjoy ourselves now we've got to prioritize we have to lookat threats that are close to certainty
 such as climate change and distinguish those from ones that are merelyimaginable but with infinitesimal
 probabilities and we have to take into account people's worry budget you can'tworry about everything and if you so
 dread and fear and terror and numb and fatalism it can lead to a kind ofnumbness well they're just these
 problems are overwhelming and the engineers are just gonna kill us all solet's either destroy the entire
 infrastructure of science technology or let's just enjoy life while we can so

0:28:30
Speaker 1 :there's a certain line of worry which
 I'm worried about a lot of things engineering there's a certain line ofworry when you cross a lot across
 that it becomes paralyzing fear as opposed to productive fear and that'skind of what they're highlighting there


0:28:45
Speaker 0 :exactly right and we've seen some we
 know that human effort is not well calibrated against risk in that becausea basic tenet of cognitive psychology is
 that perception of risk and hence perception of fear is driven by imaginedability not by data and so we miss
 allocate vast amounts of resources to avoiding terrorism which kills onaverage about six Americans a year with
 a one exception of 9/11 we invade countries we invent entire newdepartments of government with massive
 massive expenditure of resources and lives to defend ourselves against atrivial risk whereas guaranteed risks
 and you mentioned as one of them you mentioned traffic fatalities and evenrisks that are not here but are
 plausible enough to worry about like pandemics like nuclear war receivefar too little attention the in
 presidential debates there's no discussion of how to minimize the riskof nuclear war lots of discussion of
 terrorism for example and and so we I think it's essential to calibrate ourbudget of fear worry concern planning to
 the actual probability of harm yep so

0:30:10
Speaker 1 :let me ask this then this question
 so speaking of imagined ability you said it's important to think about reason andone of my favorite people who who likes
 to dip into the outskirts of reason through fascinating exploration of hisimagination is Joe Rogan oh yes you so
 who has through reason used to believe a lot of conspiracies and through a reasonhas stripped away a lot of his beliefs
 in that way so it's fascinating actually to watch him through rationality kind ofthrow away that ideas of Bigfoot and
 9/11 I'm not sure exactly trails I don't

0:30:49
Speaker 0 :know what the leaves in yet
 but you no longer know believed in

0:30:52
Speaker 1 :that's right no either he's become a


0:30:53
Speaker 0 :real force for for good yeah so you were


0:30:56
Speaker 1 :on the Joe Rogan podcast in February and
 had a fascinating conversation but as far as I remember didn't talk much aboutartificial intelligence I will be on his
 podcast in a couple weeks Joe is very much concerned aboutexistential threat away I am not sure if
 you're this is why I was I was hoping that you would get into that topic andin this way he represents quite a lot of
 people who look at the topic of AI from 10,000 foot level so as an exercise ofcommunication he said it's important to
 be rational and reason about these things let me ask if you were to coachme as AI researcher about how to speak
 to Joe and the general public about AI what would you advise well I'd the short

0:31:38
Speaker 0 :answer would be to read the sections
 that I wrote an Enlightenment I know about AI but a longer reason would be Ithink to emphasize and I think you're
 very well positioned as an engineer to remind people about the culture ofengineering that it really is safety
 oriented that another discussion in enlightenment now I plot rates anaccidental death from various causes
 plane crashes car crashes Occupational accidents even death by lightningstrikes and they all plummet because the
 culture of engineering is how do you squeeze out the the lethal risks deathby fire death by drowning death by
 asphyxiation all of them drastically declined because of advances inengineering then I gotta say I did not
 appreciate until I saw those graphs and it is because exactly people like youwho stamp at night thing oh my god it is
 what a mime is what I mean what I'm inventing likely to hurt people and todeploy ingenuity to prevent that from
 happening now I'm not an engineer although I spent 22 years at MIT so Iknow something about the culture of
 engineering my understanding is that this is the way this is what you thinkif you're an engineer
 and it's essential that that culture not be suddenly switched off when come startofficial intelligence so I mean fact
 that could be a problem but is there any reason to think it would be switched off

0:33:03
Speaker 1 :I don't think so and one there's not
 enough engineers speaking up for this way for this the excitement for thepositive view of human nature what
 you're trying to create is the positivity like everything we try toinvent is trying to do good for the
 world but let me ask you about the psychology of negativity it seems justobjectively not considering the topic it
 seems that being negative about the future makes you sound smarter than mepositive about the future irregardless
 of topic am I correct in the observation and if you if so why do you think thatis yeah I think that I think there is


0:33:37
Speaker 0 :that that phenomenon that as Tom Lehrer
 the satirist said always predict the worst and you'll be hailed as a prophetit may be part of our overall negativity
 bias we are as a species more attuned to their negative than the positive wedread losses more than we enjoy gains
 and that mate might open up a space for prophets to remind us of harms and risksand losses that we may have overlooked
 so I think there there there is that asymmetry so you've written some of my

0:34:12
Speaker 1 :favorite books all over the place so
 starting from enlightenment now to the better angels of our natureblank slate how the mind works the the
 one about language language instinct bill gates big fan to set of your mostrecent book that it's my new favorite
 book of all time so for you as an author what was the book early on in your lifethat had a profound impact on the way
 you saw the world certainly this book

0:34:45
Speaker 0 :enlightenment now is influenced by David
 Deutsch as the beginning of infinity a rather deep reflection on knowledge andthe power of knowledge to improve the
 human condition the and with bits of wisdom such as that problems areinevitable but problems are solvable
 given the knowledge and that solutions create newproblems have to be solved in their turn
 that's I think a kind of wisdom about the human condition that influenced thewriting of this book there's some books
 that are excellent but obscure some of which I have on my page of my website Iread a book called the history of force
 self-published by a political scientist named James Payne on the historicaldecline of violence and that was one of
 the inspirations for the better angels of our naturethe what about early on if we look back


0:35:35
Speaker 1 :when you're maybe a teenager loved a


0:35:39
Speaker 0 :book called one two three infinity when
 I was a young adult I read that book by George gamma the physicist veryaccessible in humorous explanations of
 relativity of number theory of dimensionality high multiple dimensionalspaces in a way that I think is still
 delightful seventy years after it was published I like that the time lifescience series these were books that
 would arrive every month my mother subscribed to each one on a differenttopic one would be on electricity what
 would be on forests want to be learned may evolution and then one was on themind and I was just intrigued that there
 could be a science of mind and that that book I would cite as an influence aswell then later on you fell in love with


0:36:28
Speaker 1 :the idea of studying the mind that's one
 thing that grabbed you it was one of the

0:36:32
Speaker 0 :things I would say the I read as a
 college student the book reflections on language by Noam Chomsky spent most ofhis career here at MIT Richard Dawkins
 two books the blind watchmaker and The Selfish Gene or enormous Li influentialpartly for mainly for the content but
 also for the writing style the ability to explain abstract concepts in livelyprose Stephen Jay Gould first collection
 ever since Darwin also excellent example of lively writing George Millerpsychologist that most psychologists are
 familiar with came up with the idea that human memory has a capacity of sevenplus or minus two chunks and then
 Sophia's biggest claim to fame but he wrote a couple of books on language andcommunication that I've read it's an
 undergraduate again beautifully written and intellectually deep wonderful Steven

0:37:29
Speaker 1 :thank you so much for taking the time


