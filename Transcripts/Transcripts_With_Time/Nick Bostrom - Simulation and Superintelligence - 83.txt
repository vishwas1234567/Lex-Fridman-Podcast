0:00:00
Speaker 0 :the following is a conversation with
 Nick Bostrom a philosopher at University of Oxford and the director of the futureof humanity Institute he has worked on
 fascinating and important ideas in existential risk simulation hypothesishuman enhancement ethics and the risks
 of super intelligent AI systems including in his book super intelligenceI can see talking to Nick multiple times
 in this podcast many hours each time because he has done some incredible workin artificial intelligence in technology
 space science and really philosophy in general but we have to start somewhereconversation was recorded before the
 outbreak of the corona virus pandemic that both Nick and I I'm sure will havea lot to say about next time we speak
 and perhaps that is for the best because the deepest lessons can be learned onlyin retrospect on the storm has passed I
 do recommend you read many of his papers on the topic of existential riskincluding the technical report titled
 global catastrophic risks survey that he co-authored with Anders Sandberg foreveryone feeling the medical
 psychological and financial burden of this crisisI'm sending love your way stay strong
 we're in this together we'll beat this thing this is the artificialintelligence podcast you can enjoy it
 subscribe on YouTube review it with five stars on a podcast supported on patreonor simply connect with me on Twitter
 Alex Friedman spelled Fri D ma n as usual I'll do one or two minutes of adsnow and never any ads in the middle that
 can break the flow of the conversation I hope that works for you and doesn't hurtthe listening experience this show is
 presented by cash app the number-one finance app in the App Store when youget it
 use code lex podcast cash Apple s you said mind your friends buy Bitcoin andinvest in the stock market with as
 little as one dollar since cash app does fractional share trading let me mentionthat the order execution algorithm that
 works behind the scenes to create the abstraction of fractional orders is analgorithmic marvel so big props to the
 cash app engineers for solving a hard problem that in the end provides an easyinterface that takes a step up to the
 next layer of abstraction over the stock market making trading more accessiblefor new investors and diversification
 much easier so again you get cash out from the App StoreGoogle Play and use the collects podcast
 you get $10 and cash Apple also donate $10 the first an organization that ishelping to advance robotics and STEM
 education for young people around the world and now here's my conversationwith Nick Bostrom at the risk of asking
 the Beatles to play yesterday or the Rolling Stones to play satisfaction letme ask you the basics what is the


0:02:57
Speaker 1 :simulation hypothesis that we are living
 in a computer simulation

0:03:01
Speaker 0 :what is the computer simulation how
 we're supposed to even think about that

0:03:06
Speaker 1 :well so the hypothesis is meant to be
 understood in a literal sense not that we can kind of metaphorically view theuniverse as an information processing
 physical system but that there is some advanced civilization who built a lot ofcomputers and that what we experience is
 an effect of what's going on inside one of those computers so that the the worldaround us our own brains everything we
 see in perceive and think and feel would exist because this computer is runningcertain programs do you think of this


0:03:48
Speaker 0 :computer as something similar to the
 computers of today these deterministic sub touring machine type things is thatwhat we're supposed to imagine or we're
 supposed to think of something more like a like a like a quantum mechanicalsystem something much bigger something
 much more complicated something much more mysterious from our current

0:04:12
Speaker 1 :perspective so the ones we have today
 would you find them in bigger certainly you'd need more memory and moreprocessing power I don't think anything
 else would be required now it might well be that they do have addition maybe theyhave quantum computers and other things
 that would give them even more implausible but I don't think it's anecessary assumption in order to get to
 the conclusion that a technology mature civilization would be able to createthese kinds of computer simulations with
 conscious beings inside them so do you

0:04:45
Speaker 0 :think the simulation hypothesis is an
 idea that's most useful in philosophy computer science physics sort of wheredo you see it having valuable kind of
 start a starting point in terms of a

0:05:04
Speaker 1 :thought experiment of it is it useful I
 guess it's more in in informative and interesting and maybe important it's notdesigned to be useful for something else


0:05:15
Speaker 0 :okay interesting
 sure but is it philosophically interesting or is there some kind ofimplications of computer science and


0:05:24
Speaker 1 :physics I think not so much for computer
 science or physics per se certainly it would be of interest in philosophy Ithink also to say cosmology or physics
 in as much as you're interested in the fundamental building blocks of the worldand the rules that govern it and if we
 are in a simulation there is then the possibility that say physics at thelevel were the computer running the
 simulation could could be different from the physics governing phenomena in thesimulation so I think might be
 interesting from point of view of religion or just from for a kind oftrying to figure out what what the heck
 is going on so we mentioned the simulation hypothesis so far there isalso the simulation argument which I
 tend to make a distinction so simulation hypothesis we are living in a computersimulation simulation argument this
 argument that tries to show that one of three propositions is true one of whichis the simulation hypothesis but there
 are two alternatives in the original simulation argument which which we can

0:06:36
Speaker 0 :get to yeah let's go there by the way
 confusing terms Picasa people will I think probably naturally thinkssimulation argument equals simulation
 hypothesis just terminology wise but let's go there so simulation hypothesismeans that we are living in simulations
 the hypothesis that we're living in simulation simulation argument has thethree complete possibilities that cover
 all possibilities so what yeah so it's

0:07:00
Speaker 1 :like a disjunction it says at least one
 of these three is true yeah although it doesn't on its own tell us which one sothe first one is that almost all
 civilizations at our current stage of technological development go extinctbefore they reach technological maturity
 so there is some great filter that makes it so that basically none of thecivilizations throughout you know maybe
 vast cosmos will ever get to realize the full potential of technological develop

0:07:42
Speaker 0 :and this could be theoretically speaking
 this could be because most civilizations kill themselves too eagerly or destroythemselves early or it might be super
 difficult to build a simulation so the

0:07:55
Speaker 1 :the span of time theoretically it could
 be both now I think it looks like we would technically be able to get therein a time span that is short compared to
 say the lifetime of planets and other sort of astronomical processes so your

0:08:13
Speaker 0 :intuition is the build simulation is not


0:08:15
Speaker 1 :well so this is interesting concept of
 technological maturity it's kind of an interesting concept to have otherpurposes as well we can see even based
 on our current limited understanding what some lower bound would be on thecapabilities that you could realize by
 just developing technologies that we already see are possible so for exampleone one of my research fellows here eric
 drexler back in india teas studied molecular manufacturing that is youcould analyze using theoretical tools
 and computer modeling the performance of various molecularly precise structuresthat we didn't then and still don't did
 I have the ability to actually fabricate but you could say that well if we couldput these atoms together in this way
 then the system would be stay and it would you know rotate with atthis speed and have what these
 computational characteristics and he also outlined some pathways that wouldenable us to get to this kind of
 molecularly manufacturing in the fullness of timeyou could do other other studies we have
 done you can look at the speed at which say it would be possible to colonize thegalaxy if you had mature technology we
 have an upper limit which is the speed of light we have sort of a lower currentlimit which is how fast current Rockets
 go we know we can go faster than that by just you know making them bigger andhave more fuel and stuff and and you can
 then start to describe the technological affordances that would exist once acivilization has had enough time to
 develop Eva at least those technologies we're already not possible then maybethey would discover other new physical
 phenomena as well that we haven't realized that would enable them to doeven more but but at least there is this
 kind of basic set of capabilities in

0:10:12
Speaker 0 :Jilin garnett well how do we jump from
 molecular manufacturing to deep-space exploration to mature technology likewhat's the connection well so these


0:10:23
Speaker 1 :would be two examples of technological
 capability sets that we can have a high degree of confidence or physicallypossible in our universe under that a
 civilization that was allowed to continue to develop its science andtechnology would eventually attain you


0:10:43
Speaker 0 :can Intuit like we can kind of see the
 set of breakthroughs they're likely to happen so you can see like what did youcall the technological set with


0:10:52
Speaker 1 :computers maybe at easiest I mean the
 one is we could just imagine bigger computers using exactly the same partsthat we have so you can kind of scale
 things that way right but you could also make processors bit faster if you hadthis molecular nanotechnology that
 director x2 described he characterized a kind of crude computer built with theseparts that that would perform you know
 at a million times the human brain while beingwe can be smaller the size of a sugar
 cube and he made no claim that that's the optimum computing structure likefraud you know we could build a faster
 computers that would be more efficient but at least you could do that if youhad the ability to do things that were
 atomically precise yes means you can combine these two youcould have this kind of nanomolecular
 ability to build things at the bottom and then say at this as a spatial scalethat would be attainable through space
 colonizing technology you could then start for example to characterize alower bound on the amount of computing
 power that technology material civilization would have if it could grabresources you know planets and so forth
 and then use this molecular nanotechnology to optimize them forcomputing you'd get a very very high
 lower bound on the amount of compute so

0:12:16
Speaker 0 :sorry define some terms so
 technologically mature civilization is one that took that piece of technologyto its to its lower bound
 what is it technological matures well

0:12:27
Speaker 1 :yeah so that mean it's a strong concept
 and we really need for the simulation hypothesis I just think it's interestingin its own right so it would be the idea
 that there is some stage of technological development for youbasically maxed out that you developed
 all those general-purpose widely useful technologies that could be developed orat least kind of come very close to the
 my you know 99.9 percent there or something so that's that's that's anindependent question you can think
 either that there is such a ceiling or you might think it just goes thetechnology tree just goes on forever


0:13:02
Speaker 0 :where where is your sense for I would


0:13:03
Speaker 1 :guess that there is I I'm a maximum that
 you would start to asymptotes towards so

0:13:09
Speaker 0 :new things won't keep springing up new


0:13:13
Speaker 1 :ceilings in terms of basic technological
 capabilities I think that yeah there's like a finite set of those that canexist in this universe more of our I
 mean I wouldn't be that surprised if we actually reached close to that levelfairly shortly after we have say machine
 super intelligence so I don't think it would take millionof years for a human originating
 civilization to begin to do this it think it's like more more likely tohappen on historical timescales but that
 that's that's an independent speculation from the simulation argument I mean forthe purpose of the simulation argument
 it doesn't really matter whether it goes indefinitely far up or whether there isa ceiling as long as we know we could at
 least get to a certain level and it also doesn't matter whether that's gonnahappen in a hundred years or five
 thousand years or 50 million years like the timescales really don't make any

0:14:11
Speaker 0 :difference for the ceilin garna a little
 bit like there's a big difference between a hundred years and ten millionyears you know so it doesn't really not
 matter because you just said this is a matter if we jump scales to beyondhistorical skills so we described that
 so for the simulation argument sort of doesn't it matter that we if it takesten million years it gives us a lot more
 opportunity to destroy civilization in

0:14:44
Speaker 1 :the mean time yeah well so it would
 shift around the probabilities between these three alternatives that is if weare very very far away from being able
 to create these simulations if it's like say the billions of years into thefuture then it's more likely that we
 will fail ever to get there they're more time for us to kind of you know give goextinct along the way and similarly for
 other civilizations so it's important to

0:15:06
Speaker 0 :think about how hard it is to build


0:15:09
Speaker 1 :simulation from in terms of yeah
 figuring out which of the disk jockeys but for the simulation argument itselfwhich is agnostic as to which of these
 three alternatives is true okay it's like you don't have to sit like thisimmolation argument would be true
 whether or not we thought this could be done in five hundred years or it wouldtake five hundred million years so for


0:15:29
Speaker 0 :sure the simulation argument stands I'm
 sure there might be some people who oppose it but it doesn't matter I meanit's it's very nice those three cases
 covered but the fun part is at least not saying what the probabilities are butkind of thinking about kind of intuitive
 reasoning about what's more likely what whatthe kind of things that would make some
 of the arguments less and more so like but let's actually I don't think we wentthrough them so number one is we destroy
 ourselves before we ever create simulate

0:16:00
Speaker 1 :right so that's kind of sad but we have
 to think not just what what might destroy us I mean the day there could besome whatever disastrous for me crowd
 slamming the earth a few years from now that that could destroy us right butyou'd have to postulate in order for
 this first disjunct to be true that almost all civilizations throughout thecosmos also failed to reach


0:16:31
Speaker 0 :technological maturity and the
 underlying assumption there is that there is likely a very large number ofother intelligent civilizations well if


0:16:39
Speaker 1 :there are yeah then they would virtually
 all have to succumb in the same way I mean then that that leads off another Iguess there are a lot of little
 digressions that you know there so there yeah give me dragging us back there arethese there is a set of basic questions
 that always come up in conversations with interesting people yeah like theFermi paradox like there's like you
 could almost define whether person is interesting whether they're at somepoint because there was a Fermi paradox
 comes up like well so forward it's worse it looks to me that the universe is verybig I mean in fact according to the most
 popular current cosmological theory is infinitely big and so then it wouldfollow pretty trivially that that it
 would contain a lot of other civilizations in fact infinitely many ifyou have some locals stochasticity and
 infinitely many is like you know infinitely many lumps of matter one nextto another there's a kind of random
 stuff in each one then you're going to get all possible outcomes withprobability one infinitely repeated so
 so then then certainly that would be a lot of extraterrestrials out there I'dmaybe short of that if the universe is
 very big there might be a finite but large number if we literallyone yet and then of course if we went
 extinct then all of civilizations at our current stage would have gone extinctbefore becoming technological material
 so then it kind of becomes trivially true that a very high fraction of thoseQuantic things but if we think there are
 many I mean it's interesting because there are certain things that plausiblycould kill us like a certain if you look
 at existential risks and it might be a different like that that the best answerto what would be most likely to kill us
 might be a different answer than the best answer to the question if there issomething that kills almost everyone
 what would that be because that would have to be some risk factor that waskind of uniform over all possible


0:18:53
Speaker 0 :civilizations yeah so in this for the
 for the seekers argument you have to think about not just us but like everycivilization dies out before they create
 this simulation yeah or something very

0:19:03
Speaker 1 :close to everybody okay so what's number


0:19:06
Speaker 0 :

0:19:09
Speaker 1 :two in well so number two is the
 convergence hypothesis that is that maybe like a lot of some of thesecivilizations do make it through to
 technological maturity but out of those who do get there they all lose interestin creating these simulations so they
 just they have the capability of doing it but they choose not to yeah not justa few of them decide not to but you know
 you know out of a million you know maybe not even a single one of them would do

0:19:41
Speaker 0 :it and I think when you say lose
 interest that sounds like unlikely because it's like they get bored orwhatever but it could be so many
 possibility within that igniculus I mean losing interest could be

0:19:57
Speaker 1 :

0:19:58
Speaker 0 :it could be anything from it being
 exceptionally difficult to do to fundamentally changing the sort of thefabric of reality if you do it as
 ethical concerns all those kinds of things could be exceptionally strong

0:20:14
Speaker 1 :pressures well certainly I mean yeah
 ethical concerns I mean not really too difficult to do I mean in a sense that'sthe first adopter that you get to
 technical maturity where you would have the ability using only a tiny fractionof your resources to create many many
 simulations so it wouldn't be the case that they would need to spend half oftheir GDP forever in order to create one
 simulation and the head is like difficult debate about whether theyshould you know invest half of their GDP
 for this it would more be like well if any little fraction of the civilizationfeels like doing this at any point
 during maybe they're you know millions of years of existence then there wouldbe millions of simulations but but
 certainly that could be many conceivable reasons for why there would be thisconvert many possible reasons for not
 running ancestor simulations or other computer simulations even if you could

0:21:14
Speaker 0 :do so cheaply by the way what's an


0:21:16
Speaker 1 :ancestor simulation well that would be
 the type of computer simulation that would contain people all like those wethink have lived on our planet in the
 past and like ourselves in terms of the types of experiences to have and andwhere those simulated people are
 conscious so it's like not just simulated in the same sense that a anon-player character would be simulated
 in the current computer game where it's kind of has you can have at our body andthen a very simple mechanism that moves
 it forward or backwards or but but something where the the simulated beinghas a brain let's say that simulated at
 a sufficient level of granularity that that it would have the same subjectiveexperiences as we have so where does


0:22:03
Speaker 0 :consciousness fit into this do you think
 simulation like is there are different ways to think about how this can besimulated
 just like you're talking about now do we have to simulate each brain within thelarger simulation is it enough to
 simulate just the brain just the minds and not the simulation I'm not the bigin the universe itself like is there
 different ways to think about this yeah

0:22:29
Speaker 1 :I guess there is a kind of premise in
 the simulation argument rolled in from philosophy of mind that is that it wouldbe possible to create a conscious mind
 in a computer and that what determines whether some system is conscious or notis is not like whether it's built from
 our organic biological neurons but maybe something like what the structure of thecomputation is that it implements so we
 can discuss that if we want but I think it would be far worse worse might bethat it would be sufficient say if you
 had a computation that was identical to the computation in the human brain downto the level of neuron so if you had a
 simulation with 100 billion neurons connected in the same ways to humanbrain and you'd then roll that forward
 with the same kind of synaptic weights and so forth so you actually had thesame behavior coming out of this as a
 human without brain would have done then I think that would be conscious now it'spossible you could also generate
 consciousness without having that detailed simulation there I'm gettingmore uncertain exactly how much you
 could simplify or abstract away

0:23:50
Speaker 0 :canyonland garnett what do you mean I
 missed where your place in consciousness

0:23:56
Speaker 1 :in a second well so that so if you are a
 computational is do you think that what creates consciousness is theimplementation of a computation some


0:24:04
Speaker 0 :property emergent property in the


0:24:07
Speaker 1 :computation itself yes the idea yeah you
 could say that but then the question is which what what's the class ofcomputations such that when they are
 wrong consciousness emerges so if you just have like something that I adds 1plus 1 plus 1 plus 1 like a simple
 computation you think maybe that's not gonna have any consciousness if on theother hand the computation is one like
 our human brains are performing where as part of the computation there is likeyou know a global work space is
 sophisticated attention mechanism there is like self representations of othercognitive processes and a whole lot of
 other things that possibly would be conscious and in fact if it's exactlylike ours I think definitely it would
 but exactly how much less than the full computation that the human brain isperforming would be required is a little
 bit I think of an open question he asks another interesting question as wellwhich is would it be sufficient to just
 have say the brain or would you need the environment right that's a nice way inorder to generate the same kind of
 experiences that we have and there is a bunch of stuff we don't know I mean ifyou look at say current virtual reality
 environments one thing that's clear is that we don't have to simulate alldetails of them all the time in order
 for say that the human player to have the perception that there is a fullreality and that you can have say
 procedurally generated virtual might only render a scene when it's actuallywithin the view of the player character
 and so similarly if this if this if this environment that that we perceive issimulated it might be that all of the
 parts that come into our view are rendered at any given time and a lot ofaspects that never come into view say
 the details of this microphone I'm talking into exactly what each atom isdoing at any given point in time might
 not be part of the simulation only a more coarse-grained representation so

0:26:27
Speaker 0 :that to me is actually from an
 engineering perspective why the simulation hypothesis is reallyinteresting to think about is how much
 how difficult is it to sort of in a virtual reality context Idon't know fake is the right word but to
 construct a reality that is sufficiently real to us to be to be immersive in thatway that the physical world is I think
 that's just that's actually probably an answerable question of psychology ofcomputer science of how how where's the
 line where it becomes so immersive that you don't want to leave that world yeah

0:27:07
Speaker 1 :alright that you don't realize while
 you're in it that it is a virtual world

0:27:12
Speaker 0 :yeah those are two actually questions
 yours is the more sort of the good question about the realism but mine frommy perspective what's interesting is it
 doesn't have to be real but it how how can we construct the world that we

0:27:28
Speaker 1 :wouldn't want to leave oh yeah I mean I
 think that might be too low a bar I mean if you think say when people first hadthe pong or something like that like I'm
 sure there were people who wanted to keep playing it for a long time becauseit was fun and I wanted to be in this
 little world I'm not sure we would say it's immersive I mean I guess in somesense it is but like an absorbing
 activity it doesn't even have to be but

0:27:51
Speaker 0 :they left that world though that's the
 so like I think that bar is deceivingly high so they eventually look so they youcan play pong or Starcraft or would have
 more sophisticated games for hours for four months you know Wow well theWarcraft could be in a big addiction but
 eventually they escape that ah so you

0:28:13
Speaker 1 :mean when it's uh absorbing enough that
 you would spend your entire it would ya choose to spend your entire life in

0:28:20
Speaker 0 :there and then thereby changing the
 concept of what reality is but as your reality your reality becomes the gamenot because you're fooled but because
 you've made that choice yeah and it may

0:28:33
Speaker 1 :be different people might have different
 preferences regarding that some Saul might even even if you had any perfectvirtual reality might still prefer not
 to spend the rest of their lives there meaning philosopher there's thisexperience machine thought experiment
 have you come across this so Robert Nozick had this thought experiment whereyou imagine some crazy super-duper
 neuroscientist of the future have created a machine that could give youany experience you want if you step in
 there and for the rest of your life you can kind of pre-programmed it indifferent ways so you're you know
 fondest dreams could come true you could whatever you dream you want to be agreat artist a great lover like have a
 wonderful life all of these things mmm if you step into the experience machinewill be your experiences constantly
 happy and but we kind of disconnect from the rest of reality and it would floatthere in the tank and the Gnostic
 thought that most people would choose not to enter the experience machine Imean many might want to go there for a
 holiday but they wouldn't want to check out of existence permanently and so hethought that was an argument against
 certain views of value according to what we what we value is a function of whatwe experience because in the experience
 machine you can have any experience you want and yet many people would thinkthat would not be much value so
 therefore what we value depends on other things than what we experience so ok can

0:30:19
Speaker 0 :you can you take that argument further
 what about the fact that maybe what we values the up and down of life so you

0:30:25
Speaker 1 :could have up and downs in the
 experience machine right but what can't you have in the experience machine wellI mean that then becomes an interesting
 question to explore but for example real connection with other people if theexperience machine is the solar machine
 where it's only you like that's something you wouldn't have there youwould have this objective experience
 that would be like fake people yeah but when if you gave somebody flowers thatwouldn't be any bother they were
 actually got happy it would just be a little simulation of somebody smilingbut the simulation would not be the kind
 of simulation I'm talking about in the simulation argument wheresimulated creatures conscious it would
 just be a kind of smiley face that would look perfectly real to you so we're now

0:31:08
Speaker 0 :drawing a distinction between appear to
 be perfectly real and actually being

0:31:14
Speaker 1 :real yeah so that could be one thing I
 mean like a big impact on history maybe it's also something you won't have ifyou check into this experience machine
 so some people might actually feel the life I want to have for me is one whereI have a big positive impact on history
 unfolds so let's see if you could kind of explore these different possibleexplanations for why this you wouldn't
 want to go into the experience machine if that's if that's what you feel andwhat one interesting observation
 regarding this Nozick thought experiment and the conclusions he wanted to drawfrom it is how much is a kind of a
 status quo effect so a lot of people might not want to jettison card realityto plug in to this dream machine but if
 they instead we're told well what you've experienced up to this point was a dreamnow
 do you want to disconnect from this and enter the real world when you have noidea maybe what the real world is or
 maybe you could say well you're actually a farmer in Peru growing you knowpeanuts and you could live for the rest
 of your life in this well or or would you want tocontinue your your dream life as Alex
 Friedman gone around the world making podcasts and doing research so if thestatus quo was that the that they were
 actually in the experience machine howling a lot of people might prefer tolive the life that they are familiar
 with rather than sort of bail out into

0:32:57
Speaker 0 :something the change itself the leap


0:32:59
Speaker 1 :yeah it might not be so much the the
 reality itself that we're after but it's more that we are maybe involved incertain projects and relationships and
 we have you know a self-identity and these things that's our values are kindof connected with carrying that forward
 and then whether it's inside a tank or outside a tank inPeru or whether inside a computer
 outside a computer that's kind of less important to what what we ultimately

0:33:29
Speaker 0 :care about yeah but still so just linger
 on it it is interesting I find maybe people are different but I find myselfquite willing to take the leap to the
 farmer in Peru especially as the virtual reality system become more realistic II find that possibility and I think more


0:33:50
Speaker 1 :people would take that leap but so in
 this in this thought experiment just to make sure we are understand so in thiscase that the farmer in Peru would not
 be a virtual reality that would be the real the real that really real that yourlife like before this whole experience
 machine started well I kind of assumed

0:34:04
Speaker 0 :from that description
 you're being very specific but that kind of idea just like washes away theconcept of what's real I mean I'm still
 a little hesitant about your kind of distinction between real and illusionbecause when you can have an illusion
 that's feels I mean that looks real and you know what III don't know how you candefinitively say something is real or
 not like what's what's a good way to prove that something is real in that

0:34:37
Speaker 1 :context well so I guess in this case
 it's Morris depression in one case you're floating in a tank with thesewires by the super-duper neuroscientists
 plugging into your head giving you Lex Friedman experiences in the other you'reactually tilling the soil in Peru
 growing peanuts and then those peanuts are being eaten by other people allaround the world by the exports and this
 that's two different possible situations in the one and the same real world thatthat you could choose to occupy but just


0:35:10
Speaker 0 :to be clear when you're in a vat with
 wires and the neuroscientists you can still go farming in Peru right mmm but

0:35:18
Speaker 1 :like well you could you could if you
 wanted to you could have the experience of farming in Peru but what thatwouldn't actually be any peanuts grown


0:35:27
Speaker 0 :well but what makes a peanut so
 so peanut could be grown and you could feed things with that peanut and whycan't all of that be done in a
 simulation

0:35:40
Speaker 1 :I hope first of all that they actually
 have peanut farms in Peru I guess we'll get a lot of comments otherwise angry Iwas way up to the point you should know


0:35:54
Speaker 0 :you can't realize in that climate now I


0:35:57
Speaker 1 :mean I I think I mean I I in the
 simulation I think there's a sense the important sense in which it should allbe real nevertheless there is a
 distinction between inside the simulation and outside the simulation orin the case of no.6 thought experiment
 whether you're in the VAT or outside the VAT and some of those differences may ormay not be important I mean that that
 comes down to your values and preferences so if they if the experiencemachine only gives you the experience of
 growing peanuts but you're the only one in in the experience machines there's

0:36:36
Speaker 0 :other you can within the experience
 machine others can plug in well they're

0:36:40
Speaker 1 :versions of the experience machine so in
 fact you might want to have distinguish different thought experiments differentversions of it so in in like in the
 original thought experiment maybe it's only right just you so and you think Iwouldn't want to go in there well that
 tells you something interesting about what you value and what you care aboutthen you could say well what if you add
 the fact that there would be other people in there and you would interactwith them well it starts to make it more
 attractive right then you can add in well what if you could also haveimportant long-term effects on human
 history in the world and you could actually do something useful even thoughyou were in there that makes it maybe
 even more attractive like you could actually have a life that had a purposeand consequences and so as you sort of
 add more into it it becomes more similar to the the baseline reality that that

0:37:32
Speaker 0 :you were comparing it to yeah but I just
 think inside the experience machine and without taking those steps you justmentioned you you you still have an
 impact on long-term history of the creatures that live inside thatof the quote-unquote fake creatures that
 live inside that experience machine and that like at a certain point you know ifthere's a person waiting for you inside
 that experience machine maybe your newly found wife and she dies she has fearsshe has hopes and she exists in that
 machine when you plug out when you unplug yourself and plug back in she'sstill there going on about her life oh


0:38:15
Speaker 1 :well in that case yeah she starts to
 have more of an independent existence i independent existence but it depends Ithink on how she's implemented in the
 experience machine take one the mid case where all she is is a static picture onthe wall of photograph right so you
 think well I can look at her right but that's it there's no that then you thinkwell it doesn't really matter much what
 happens to that and any more than a normal photographs if you tear it upright it means you can't see it anymore
 but you haven't harmed the person whose picture you tore up to go home but butif she's actually implemented say at a
 neural level of details so that she's a fully realized digital mind with thesame behavioral repertoire as you have
 then very plausibly she would be a conscious person like you are and thenyou would what you do in in this
 experience machine would have real consequences for how this other mindfelt so you have to like specify which
 of these experience machines you're talking about I think it's not entirelyobvious that it will be possible to have
 an experience machine that gave you a normal set of human experiences whichinclude experiences of interacting with
 other people without that also generating consciousnesses correspondingto those other people that is if you
 create another entity that you perceive and interact with that to you looksentirely realistic not just when you say
 hello they say hello back but you have a rich interaction many days deepconversations like it might be that the
 only possible way of implementing that wouldbe one that also has a side effect
 instantiated this other person in enough detail that you would have a secondconsciousness there I think that's to
 some extent an open question so you

0:40:11
Speaker 0 :don't think it's possible to fake
 consciousness and say well it might be I

0:40:15
Speaker 1 :mean I think you can certainly fake if
 you have a very limited interaction with somebody you could certainly fake thatthat is if all you have to go on is
 somebody said hello to you that's not enough for you to tell whether that wasa real person there or a pre-recorded
 message or you know like a very superficial simulation that has noconscious Ness because that's something
 easy to fake we could already fake it now you can record a voice recording andyou know but but if you have a richer
 set of interactions where you're allowed to answer ask open-ended questions andprobe from different angles that
 couldn't sort of be you could give can't answer to all of the possible ways thatyou could probe it then it starts to
 become more plausible that the only way to realize this thing in such a way thatyou would get the right answer for many
 which angle you probe it would be a way of instance ating it we alsoinstantiated a conscious mind yeah movie


0:41:10
Speaker 0 :on the intelligence part but there's
 something about me that says consciousness is easier to fake like II've recently gotten my hands on a lot
 of rubas don't ask me why or how but and I've made them there's just a nicerobotic mobile platform for experiments
 and I made them scream and/or moan in pain so on just to see when they'reresponding to me and it's just a sort of
 psychological experiment myself and I think they appear conscious to me prettyquickly my guy to me at least my brain
 can be tricked quite easily right I said if I introspect and they it's harder forme to be tricked that something is
 intelligent so I just have this feeling that inside this experience machine justsaying that you're conscious and having
 certain qualities of the interaction like being able to suffer like beingable to hurt like being able to wander
 about the essence of your own existence not actually I mean you know thecreating the illusion that you're
 wandering about it is enough to create the fit of consciousness and be createthe illusion of consciousness and
 because of that create a really immersive experience to where you feel

0:42:27
Speaker 1 :like that is the real world so you think
 there's a big gap between appearing conscious and being conscious or is itnot just that gets very easy to be


0:42:35
Speaker 0 :conscious I'm not actually sure what it
 means to be conscious all I'm saying is the illusion of consciousness is enoughfor this to create a social interaction
 that's as good as if the thing was conscious meaning I'm making it about

0:42:52
Speaker 1 :myself right yeah I mean I guess there
 are a few differences one is how good the interaction is which might mean ifyou don't really care about like probing
 hard for whether the thing is conscious maybe maybe it would be a satisfactoryinteraction whether or not you really
 thought it was conscious now if you really care about it being contrastingin like inside this experience machine
 yes how easy would it be to fake it and you say it sounds easy easy yeah thenthe question is would that also mean
 it's very easy to instantiate consciousness like it's much more widelyspread in the world and we have thought
 it doesn't require a big human brain with a hundred billion neurons all youneed is some system that exhibits basic
 intentionality and can respond and you already have consciousness like in thatcase I guess you still have a close
 coupling they denied that did I guess that a case would be where they can comeapart where we could create the
 appearance of there being a conscious mind without actually not being anotherconscious mind I'm yeah I'm somewhat
 agnostic exactly where these lines go I think one one observation that makes itpossible that you could have very
 realistic appearances relatively simply which also is relevant for thesimulation argument and in terms of
 thinking about how realistic with the virtual reality model have to be inorder for the
 creature not to notice that anything was awry well just think of our own humblebrains during the wee hours of the night
 when we are dreaming many times well dreams are very mersive but often youalso don't realize that you're in a
 dream and that's produced by simple primitive three-pound lumps of neuralmatter effortlessly so if a simple brain
 like this can create a virtual reality that seems pretty real to us then howmuch easier would it be for a super
 intelligent civilization with planetary sized computers optimized over the eonsto create a realistic an environment for
 you to interact with yeah and by the way

0:45:11
Speaker 0 :behind that intuition is that our brain
 is not that impressive relative to the possibilities of what technology couldbring it's also possible that the brain
 is the epitome is the ceiling like just

0:45:26
Speaker 1 :because ceiling how it's not possible


0:45:30
Speaker 0 :meaning like this is the smartest
 possible thing that the universe could

0:45:35
Speaker 1 :create so that's seems unlikely unlikely
 to me yeah I mean for some of these reasons we alluded to earlier in termsof designs we already have four
 computers that would be faster by many orders of magnitude than the human brainyeah but it could be that the


0:45:55
Speaker 0 :constraints the cognitive constraints in
 themselves is what enables the intelligence so the more the morepowerful you make the computer the less
 likely is to become super intelligent this is where I say dumb things to pushback and uh yeah I'm not sure I father


0:46:12
Speaker 1 :we might you know I mean so there are
 different dimensions of intolerance yeah a simple one is just speed like if youcould solve the same challenge faster in
 some sense yes you're like smarter so there I think we have very strongevidence for thinking that you could
 have a computer in this universe that would be much faster than the humanbrain and therefore have speed super
 into it's like be completely superior maybe amillion times faster then maybe there
 are other ways in which you could be smarter as well maybe more qualitativeways right and there
 the concepts are a little bit less clear-cut so it's harder to make a verycrisp neat firmly logical argument for
 why that could be qualitative superintelligence as opposed to justthinks that we're faster although I
 still think it's very plausible and for various reasons that that are less thanwatertight arguments but when you can
 sort of for example if you look at animals and brains and even withinhumans like there seems to be like
 Einstein versus random person like it's not just that Einstein was a little bitfaster but like how long would it take a
 normal person to invent general relativity it's like it's not twentypercent longer than it took Einstein or
 something like that it's like I don't know whether that we do it at all or itwould take millions of years or some
 totally bizarre so well you put your

0:47:37
Speaker 0 :tuition is that the computer size will
 get you go the increasing the size of the computer and the speed of thecomputer might create some much more
 powerful levels of intelligence that would that enable some of the thingswe've been talking about would like the
 simulation being able to simulate an ultra realistic environment ultrarealistic yes ception of reality yeah I


0:48:00
Speaker 1 :mean it's like they're speaking it would
 not be necessary to have super intelligence in order to he'll say thetechnology to make these simulations
 ancestor simulations or other kinds of simulations and as a matter of fact thatthing if if there are if we are in a
 simulation it would most likely be one built by a civilization that had superintelligence it certainly would help a
 lot I mean it could build more efficient large-scale structures if you had superintelligence I also think that if you
 had the technology to build these simulations that's like a very advancedtechnology it seems kind of easier to
 get technology to super intelligence yeah so I'd expect by the time thatcould make these fully realistic
 simulations of human history with human brains in there like before that theygot to that stage I would have figured
 out how to create machines super tall or maybe biological enhancements oftheir own brains if there were
 biological creatures to start with so we

0:49:01
Speaker 0 :talked about the the three parts of the
 simulation argument one we destroy ourselves before we ever create thesimulation two we somehow everybody
 somehow loses interest in creating simulation three we're living in a

0:49:16
Speaker 1 :simulation so you've kind of I don't


0:49:17
Speaker 0 :know if your thinking has evolved on
 this point but you kind of said that we know so little that these three casesmight as well be equally probable
 so probabilistically speaking where do you stand on this yeah I know I mean I

0:49:31
Speaker 1 :don't think equal necessarily would be
 the most supported probability assignment so how would you without

0:49:41
Speaker 0 :assigning actual numbers wait wait
 what's more or less likely in your in

0:49:47
Speaker 1 :your well I mean historically tended to
 punt on the question of like has between these three so maybe you ask me another

0:49:55
Speaker 0 :way is which kind of things would make
 it each of these more or less likely

0:50:04
Speaker 1 :what cried VI certainly in general terms
 if you think anything that say increases or reduces the probability of one ofthese we tend to slosh probability
 around on the other so if if one becomes less probable like the other would haveto cuz gotta add up to one yes
 so if we consider the first hypothesis the first alternative that there's thisfilter that makes it so that virtually
 no civilization reaches technological maturity in particular our owncivilization if that's true then it's
 like very unlikely that we would reach technical maturity just because ifalmost no civilization at our stage does
 it then it's unlikely that we do it so

0:50:49
Speaker 0 :hang on sorry again longer than that for


0:50:51
Speaker 1 :a second well if it's the case that
 almost all civilizations at our current stage of technological maturity fails atfailed at our current stage of technical
 development failed to reach maturity that would give us very strong reasonfor thinking we will
 to reach technical material and also so

0:51:08
Speaker 0 :the flipside of that is the fact that
 we've reached it means that many other

0:51:13
Speaker 1 :civilizations yeah so that means if we
 get closer and closer to actually reaching technological maturity there'sless and less distance left where we
 could go extinct before we are there and therefore the probability that we willreach increases as we get closer and
 that would make it less likely to be true that almost all civilizations atour current stage failed to get there
 like we would have this what the one case we started ourselves would be veryclose to getting there that would be
 strong evidence it's not so hard to get too technical maturity so to the extentthat we you know feel we are moving
 nearer to technology maturity that that would tend to reduce the probability ofthe first alternative and increase the
 probability of the other - it doesn't need to be a monotonic change like ifevery once in a while some new threat
 comes into view some bad news thing you could do with some novel technology forexample you know that that could change
 our probabilities in the other direction

0:52:15
Speaker 0 :but that the technology again you have
 to think about as that technology has to be able to equally in an even way affectevery civilization out there yeah pretty


0:52:25
Speaker 1 :much I mean that strictly speaking is
 not real I mean that could that could be two different existential risk and everycivilization you know you know one or
 the other like but none of them kills more than 50% like yeah but thatincidentally so in some of my the work I
 mean on machine super intelligence like so I wanted some existential risks wherethey did sort of super intelligence AI
 and how we must make sure you know to handle that wisely and carefully it'snot the right kind of existential
 catastrophe to make first alternative true though like itmight be bad for us if the future lost a
 lot of value as a result of it being shaped by some process that optimizedfor some completely non human value but
 even if we got killed by machine superintendence is that machine superintelligence might still attain
 technical maturity so I see so you're

0:53:31
Speaker 0 :not very you're not human exclusive this
 could be any intelligent species that achieves like it's all about thetechnological maturity it's not that the
 humans have to attain it right like super intelligence replace us and that's

0:53:46
Speaker 1 :just as well fascination as well yeah
 yeah I mean it could interact with the second high pop foul turn ative like ifthe thing that replaced us was either
 more likely or less likely than we would be to have an interest in creatingancestor simulations you know that that
 could affect probabilities but yeah to a first-order like if we all just die thenyeah we won't produce any simulations
 because we are dead but if we all die and get replaced by some otherintelligent thing that then gets the
 technical maturity the question remains of course if my not that thing thatneeds some of its resources to to do


0:54:25
Speaker 0 :this stuff so can you reason about this
 stuff this is given how little we know about the universe is it reasonable toto reason about these probabilities so
 like how little well maybe you can disagree but to meit's not trivial to figure out how
 difficult it is to build a simulation we kind of talked about it a little bit wealso don't know like as we tried to
 start building it like start creating virtual worlds and so on how thatchanges the fabric of society like
 there's all these things along the way that can fundamentally change just somany aspects of our society about our
 existence that we don't know anything about like the kind of things we mightdiscover when we understand to a greater
 degree the fundamental the physics like the theory if we have abreak through have a theory and
 everything how that changes stuff how that changes deep space exploration andso on so like is it still possible to
 reason about probabilities given how

0:55:33
Speaker 1 :little we know yes I think though there
 will be a large residual of uncertainty that we'll just have to acknowledge andI think that's true for most of these
 big-picture questions that we might wonder about it's just we are smallshort-lived small brained cognitively
 very limited humans with little evidence and it's amazing we can figure out asmuch as we can really about the cosmos


0:56:04
Speaker 0 :but it okay so there's this cognitive
 trick that seems to happen where I look at the simulation argument which for meit seems like case one and to feel
 unlikely I want to say feel unlikely as opposed to sort of in like it's not likeI have too much scientific evidence to
 say that either one or two are not true it just seems unlikely that every singlecivilization destroys itself and it
 seems like feels unlikely that the civilizations lose interest so naturallythe without necessarily explicitly doing
 it but this illumination the simulation argument it basically says it's verylikely we're living in a simulation like
 to me my mind mm-hmm naturally goes there I think the mind goes there for alot of people is that the incorrect


0:56:56
Speaker 1 :place for it to go well not not not
 necessarily I think the second alternative which has to do with themotivations and interest of
 technologically mature civilizations I think there is much we don't understandabout that can you talk about that a


0:57:17
Speaker 0 :little bit what do you think I mean this
 question that pops up when you have when you build an AGI system or build thegeneral intelligence or how does that
 change our motivations do you think of fundamentally transform our motivations

0:57:30
Speaker 1 :well it doesn't seem that implausible
 that once you take this leap to the technologicalmaturity I mean I think like it involves
 creating machine superintelligence possibly that would be sort of on thepath for basically all civilizations
 maybe before they are able to create large numbers of ancestor simulationsthey would that possibly could be one of
 these things that quite radically changes the orientation of what acivilization is in fact optimizing for
 there are other things as well so at the moment we have not perfect control overour own being our own mental states our
 own experiences are not under our direct control so for example if if you want toexperience a pleasure and happiness you
 might have to do a whole host of things in the external world to try to get intothe stage into the mental state where
 you experience pleasure you look like some people get some pleasure fromeating great food well they can just
 turn that on they have to kind of actually go to a nice restaurant andthen they have to make money too so
 there's like all this kind of activity that maybe arises from the fact that weare trying to ultimately produce mental
 states but the only way to do that is by a whole host of complicated activitiesin the external world now at some level
 of technological development I think will become other potent in the sense ofgaining direct ability to choose our own
 internal configuration and enough knowledge and insight to be able toactually do that in a meaningful way so
 then it could turn out that there are a lot of instrumental goals that woulddrop out of the picture and be replaced
 by other instrumental goals because we could now serve some of these finalgoals in more direct ways and who knows
 how all of that shakes out after civilizations reflect on that andconverge and different attractors and so
 on and so forth and and that that could be new newinstrumental considerations that come
 into view as well that that we are just oblivious to that would maybe have astrong shaping effect on actions like
 very strong reasons to do something or not to do something and we just don'trealize they're there because we are so
 dumb tumbling through the universe but if if almost inevitably on on route toattaining the ability to create many
 other simulations you do have this cognitive enhancement or advice fromsuper intelligences or you yourself then
 maybe there's like this additional set of considerations coming into view andyesterday I it's obvious that the thing
 that makes sense is to do X whereas right now it seems so you could X Y or Zand different people will do different
 things and we're kind of random in that

1:00:38
Speaker 0 :sense yeah because at this time with our
 limited technology the impact of our decisions is minor I mean that'sstarting to change some in some ways but


1:00:49
Speaker 1 :well I'm not sure it follows that the
 impacts of our decisions is minor

1:00:54
Speaker 0 :well it's starting to change I mean I
 suppose 100 years ago was minor it's

1:01:00
Speaker 1 :starting to so it depends on how you
 viewed so what people did 100 years ago still have effects on the world today Oh

1:01:09
Speaker 0 :as a I see as a as a civilization or in


1:01:14
Speaker 1 :the together yeah so it might be that
 the greatest impact of individuals is not at technical maturity or very fardown it might be earlier on when there
 are different tracks civilization could go down I mean maybe the population issmaller things still haven't settled out
 if you count indirect effects that that that those could be bigger than thedirect effects that people have later on


1:01:43
Speaker 0 :so part 3 of the argument says that so
 that leads us to a place where eventually somebody creates a simulation

1:01:51
Speaker 1 :that I think you you had a conversation


1:01:54
Speaker 0 :Joe Rogan's I think there's some aspect
 here where you got stuck a little bit

1:02:00
Speaker 1 :

1:02:01
Speaker 0 :how does that lead to were likely living
 in a simulation so this kind of probability argument if somebodyeventually creates a simulation why does
 that mean that we're now in a simulation

1:02:15
Speaker 1 :but what you get to if you accept
 alternative three first is that would be more simulated people with our kinds ofexperiences than on simulated ones like
 if in n kind of if you look at the world as a whole by the end of time as it wereyou just count it up that would be more
 simulated once than on simulated ones then there is a an extra step to getfrom that if you assume that suppose for
 the sake of the argument that that's true how do you get from that to thisstatement we are probably in a
 simulation so here you are introducing an indexical statement like it's thatthis person right now is in a simulation
 they're all these other people you know that are in simulation so some that arenot in the simulation but what
 probability should you have that you yourself is one of the simulated ones ina setup so so yeah so I call it the
 bland principle of indifference which is that in in cases like this when you haveto I guess sets of observers one of
 which is much larger than the other and you can't from any internal evidence youhave tell which that you belong to you
 should design a probability that's proportional to the size of these setsso that if there are ten times more
 simulated people with your kinds of experiences you would be ten times morelikely to be one of those is that as


1:03:59
Speaker 0 :intuitive as it sounds in that that
 seems kind of if you don't have enough information you should rationally justassign the same probability as the yeah


1:04:10
Speaker 1 :kind of the size of the set it seems
 seems pretty plausible to me were the

1:04:15
Speaker 0 :holes in this is it at the at the very
 beginning the assumption that everything stretches sort of you have infinite timeessentially you don't need infinite time


1:04:25
Speaker 1 :

1:04:26
Speaker 0 :you need what how long this is the time


1:04:29
Speaker 1 :what however long it takes I guess for a
 universe to produce an intelligent civilization that has intense thetechnology to run some ancestor
 simulations gotcha

1:04:39
Speaker 0 :at some point when the first simulation
 is created that stretch of time just a little longer than they're all startcreating simulations kind of like yeah I


1:04:48
Speaker 1 :mean that might that different it might
 if you think of there being a lot of different planets and some subset ofthem have life and then some subset of
 those get to intelligent life and some of those maybe eventually start creatingsimulations they might get started at
 quite different times like maybe on some planet it takes a billion years longerbefore you get like monkeys or before
 you get even bacteria then on another planet so that like this might happenkind of at different cosmological epochs
 is there a connection here to the

1:05:25
Speaker 0 :Doomsday argument in that sampling there


1:05:29
Speaker 1 :if there is a connection in that they
 both involve an application of anthropic reasoning that is reasoning about thesekind of indexical propositions but the
 assumption you need in the case of the simulation argument it's much weakerthan the simulator the assumption you
 need to make the Doomsday argument go

1:05:53
Speaker 0 :through what is the Doomsday argument
 and maybe you can speak to the anthropic reasoning in more general yeah that's

1:05:59
Speaker 1 :that's a big an interesting topic in its
 own right and tropics but the Doomsday argument is this really first discoveredby Brandon Carter was a theoretical
 physicist and then developed by philosopher John Wesley I think it mighthave been discovered initially in the
 70s or 80s and Lester wrote this book I think in 96 and there are some otherversions as well
 God is a physicist but let's focus on the Carter Leslie version where it's anargument that we have systematically
 underestimated the probability that humanity will go extinct soon now Ishould say most people probably think at
 the end of the day there is something wrong with this doomsday argument thatit doesn't really hold it's like there's
 something wrong with it but it's proved hard to say exactly what is wrong withit
 and different people have different accounts my own view is it seemsinconclusive but and I can say what the
 argument is yeah yeah so maybe it's easiest to explain via an analogy tosampling from urns so imagine you have a
 big imagine you have two urns in front of you and they have balls in them thathave numbers so there's the tourist look
 the same but inside one there are ten balls ball number 1 2 3 up to ballnumber 10 and then in the other urn you
 have a million balls numbered one to a million and somebody puts one of theseurns in front of you and asked you to
 guess what what's the chance it's the 10 ball and you say 50/50 they you know Ican't tell which urn it is um but then
 you're allowed to reach in and pick a ball at random from the urn and that'ssuppose you find that it's ball number 7
 said that strong evidence for the 10 ball hypothesis like it's a lot morelikely that you would get such a lobe
 numbered ball if they're on the 10 balls in the urn like it's in fact 10 percentdone right then if there are a million
 balls it would be round likely you would get number 7so you perform a Bayesian update and if
 your prior was 50/50 that it was the temple urn you become virtually certainafter finding the random sample was 7
 that it's only has 10 balls in it so in the case of the urns this is oncontroversial just elementary
 probability theory the Doomsday argument says that you should recent in a similarway with respect to different hypotheses
 about how many many balls there will be in the urn of humanity I said for howmany humans that will have human being
 by the time we go extinct so to simplify let's suppose we only consider twohypotheses either maybe 200 billion
 humans in total or 200 trillion humans in total you could fill in morehypotheses but it doesn't change the
 principle here so it's easiest to see if we just consider these two so you startwith some prior based on ordinary
 empirical ideas about threats to civilization and so forth and maybe yousay it's a 5% chance that we will go
 extinct by the time there will have been 200 billion only you're kind ofoptimistic let's say you think probably
 will make it through colonize the universe in but then according to thisTuesday argument you should think of
 your own birth rank as a random sample so your birth is your sequence in theposition of all humans that have ever
 existed it turns out you're about a human number of 100 billion you knowgive or take that's talking roughly how
 many people have been born before you

1:09:55
Speaker 0 :that's fascinating because I probably
 yeah we each have a number wait wait

1:09:59
Speaker 1 :wait we would each have a number in this
 I mean obviously the exact number will depend on where you started countinglike witch ancestors start was human in
 hasta Carol is human but the does those are not really important - they'rerelatively few of those so yeah so
 you're roughly a hundred billion now if they're only gonna be 200 billion intotal that's a perfectly unremarkable
 number you're somewhere in the middle right run-of-the-mill human completelyunsurprising yes now if they're gonna be
 200 trillion you would be remarkably early like you it's like what are thechances out of these 200 trillion human
 that you should be human number one hundred billion that seems it would havea much lower conditional probability and
 so analogously taha in the urn case you thought after finding this low numberedrandom sample you updated in favor of
 having few balls similarly in this case you should update in favor of the humanspecies having a lower total number of
 members that is doom soon you said doom

1:11:04
Speaker 0 :soon that's yeah well that would be the


1:11:06
Speaker 1 :hypothesis in this case that it will end


1:11:11
Speaker 0 :just a hundred billion I just like that


1:11:14
Speaker 1 :term for the hypothec and of crucially
 relies on the Doomsday argument it's the idea that you should reason as if youwere a random sample from the set of all
 humans that will ever have existed if you have that assumption then I thinkthe rest kind of follows the question is
 why should you make that assumption in fact you know you're 100 billion so sowhere do you get this prior and then
 there is like a literature on that with different ways of supporting that orsomething and it that's just one example


1:11:45
Speaker 0 :of a topic reasoning right there yeah
 that seems to be kind of convenient when you think about humanity when you whenyou think about us of even like
 existential threats and so on as it seems that quite naturally that youshould assume that you're just an


1:12:03
Speaker 1 :average case yeah that you're a kind of
 a typical or randomly sampled now in the case of the Doomsday argument it seemsto lead to what intuitively we think is
 the wrong conclusion or at least many people have this reaction that there'sgot to be something fishy about this
 argument because from very very weak premises it gets this very strikingimplication that we have almost no
 chance of reaching size 200 trillion humans in the future and how can wepossibly get there just by reflecting on
 when we were born it seems you would need sophisticated arguments about theimpossibility of space colonization blah
 blah so what might be tempted to reject this key assumption I call it the selfsampling assumption the idea that you
 should reason as if you were a random sample from all observers or in yoursome reference class however it turns
 out that in other domains it looks like we need something like this selfsampling assumption to make sense of
 bona fide a scientific inferences in contemporary cosmology for example youhave
 these multiverse theories and according to a lot of those all possible humanobservations are made so I mean if you
 have a sufficiently large universe you will have a lot of people observing allkinds of different things so if you have
 two competing theories say about some the value of some constant it could betrue according to both of these theories
 that there will be some observers observing the value that corresponds tothe other theory because there will be
 some observers that have elucidation so there is a local fluctuation or anstatistically anomalous measurement
 these things will happen and if in us observers making us differentobservations that would be something
 that sort of by chance make these different ones and so what we would wantto say is well many more observers a
 larger proportion of the observers will observe as it were the true value and afew will observe the wrong value if we
 think of ourselves as a random sample we should expect with a very improperbility to observe the true value on that
 well then allow us to conclude that the evidence we actually have is evidencefor the theories we think are supported
 it kind of done is a way of making sense of these inferences that clearly seemcorrect that we can you know make
 various observations and infer what the temperature of the cosmic background isand and the the fine-structure constant
 and all of this but it seems that without rolling in some assumptionsimilar to the self sampling assumption
 this inference just doesn't go through and there are the examples so so thereare these scientific context so it looks
 like this kind of anthropic reasoning is needed and makes perfect sense and yetin the case of the dupes argument it has
 this weird consequence and people might think there is something wrong with itthere so there's done this project that
 would consistent try to figure out now what are the legitimate ways ofreasoning about these indexical facts
 when observer selection effects are in play in other wordswell being a theory of anthropic s-- and
 that different views of looking at that and it's a difficult methodological areabut to tie it back to the simulation
 argument the the key assumption there this land principle of indifference it'smuch weaker than the self sampling
 assumption so if you think about in the case of the Doomsday argument it saysyou should reason as if you're a random
 sample from All Humans that will never live even though in fact you know thatyou are about number one hundred billion
 human and you're alive in the year 2020 whereas in the case of the simulationargument it says that well if you
 actually have no way of telling which one you are then you should assign thiskind of uniform probability yeah yeah


1:16:11
Speaker 0 :your role is the observer in the
 simulation argument is different it seems like who is the observer I mean Ikeep assigning the individual


1:16:19
Speaker 1 :consciousness yeah I mean when I say you
 want a lot of observers in the simulation in the context of thesimulation argument but they're all
 irrelevant the server's would be a the people in original histories and be thepeople in simulations so this would be
 the class of observers that we need I mean there also may be the simulatorsbut we can set those aside for this so
 the question is given that class of observers a small set of originalhistory observers and a large class of
 simulated observers which one should you think is you where are you amongst thiswell observers I'm maybe having a little


1:16:54
Speaker 0 :bit trouble wrapping my head head around
 the intricacies of what it means to be an observer and this and this in thedifferent instantiations of the
 anthropic reasoning cases that we

1:17:09
Speaker 1 :mention right now it I mean it may be an
 easier way of putting it is just like are you simulated or you're notsimulated you've given this assumption
 that these two groups of people exist

1:17:21
Speaker 0 :yeah in the simulation case it seems
 pretty straightforward it's yeah so

1:17:23
Speaker 1 :that's right they think the key point is
 the methodological assumption you need to make to get the simulation argumentto where it wants to go is much weaker
 and less problematic then the methodological assumption you make toget the Doomsday argument to its
 conclusion maybe the dune star government is soundor unsound but you need to make a much
 stronger and more controversial assumption to make it go through in thecase of the Doomsday argument a sorry
 simulation argument I guess one maybe way intuition pub to like support thisbland principle of indifference is to
 consider a sequence of different cases where the fraction of people who areassimilated to non-simulated approaches
 one so in the limiting case where everybody assimilated I obviously candeduce with certainty that you are
 simulated right if everybody with your experience is assimilated and you knowyou're gotta be one of those you don't
 need the probability at all you just kind of logically conclude it rightright so then as we move from a case
 where say 90% of everybody simulated 99% 99.9% it's impossible that theprobability of sine should sort of
 approach one certainty as the fraction approaches the case where everybody isin a simulation yes exactly like you
 wouldn't like expect that to be a discrete well if there's onenon-simulated person then it's 50/50 but
 if we move that and it's hundred percent like it should kind of all right thereare other arguments as well one can use
 to support this blind principle of indifference but that might be enough to

1:19:20
Speaker 0 :but in general when you start from time
 equals zero and go into the future the fraction assimilated if it's possible tocreate simulated worlds the fraction
 similar worlds will go to one well I

1:19:32
Speaker 1 :mean it was a novelist kind of go all
 the way to one in in reality that would be some ratio although maybe a technicalmaterial civilization could run a lot of
 simulations using a small portion of its resources it probably wouldn't be ableto run infinite demand yeah I mean if we
 take say the observed the physics in the observed universe if we assume thatthat's also the physics at the level of
 the simulators that would be limits to the amount of information processingthat any one civilization could perform
 in its future trajectory right and there's like well first of all there'slimited amount of matter you can get
 your hands off because with the positive cosmological constant the universe isaccelerating there's like a finite
 sphere of stuff even if you've traveled with the speed of light that you couldever reach you have a finite amount of
 stuff and then if you think there is like a lower limit to the amount of lossyou get when you perform an eraser of a
 computation or if you think for example just matter gradually over cosmologicaltimescales decay
 you know maybe protons decay other things and they radiate outgravitational waves like there's all
 kinds of seemingly unavoidable losses that occur so eventually we'll havesomething like like a heat death of the
 universe or if it caused death or whatever but it's finite but of course

1:21:04
Speaker 0 :we don't know which if if there's many
 ancestral civil simulations we don't know which level we are so there couldbe couldn't there be like an arbitrary
 number of simulation that spawned ours and those had more resources there's aphysical universe to work with sorry I


1:21:26
Speaker 1 :mean that that could be sort of okay so


1:21:30
Speaker 0 :if simulations spawn other simulation
 tries it seems like each new spawn has fewer resources to work with yeah but we

1:21:42
Speaker 1 :

1:21:44
Speaker 0 :don't know at which love which step
 along the way we are at right any one observer doesn't know whether we're inlevel 42 or 100 or one or is that not
 matter for the resources I mean when it's true that they would

1:22:01
Speaker 1 :that would be all certainty asked you
 could have stacked simulations yes and that couldn't be a certainty as to whichlevel we are at as you remark tall so
 all the computations performed in a simulation within the simulation alsohave to be expended at the level of the
 simulation well today the computer in basement reality where all thesesimulations for the simulations with the
 simulations are taking place like that that computer ultimately it's it's itsCPU or whatever it is like that has to
 power this whole tower right so if there is a finite compute power in basementreality that would impose a limit to how
 tall this tower can be and if if each level kind of imposes a large extraoverhead you might think maybe the tower
 would not be very tall that most people would be lower down in the tower I love

1:23:00
Speaker 0 :the term basement reality let me ask one
 of the popularizers you said there's many through this when you look at sortof the last few years of the simulation
 hypothesis just like you said it comes up every once in a while some newcommunity discovers it and so on but I
 would say one of the biggest popular artists of this idea is Elon Musk do youhave any kind of intuition about what
 Elon thinks about when you think about simulation why is this of such interestis it all the things we've talked about
 or is there some special kind of intuition about simulation that he has I

1:23:35
Speaker 1 :mean you might have a better I think I
 mean why it's of interest I think it's it's like seems Fred Albus why if it tothe extent that one think the argument
 is credible why it would be of interest it would if it's correct tell ussomething very important about the world
 you know one way or the other whichever of the three alternatives for asimulation that seems like arguably one
 of the most fundamental discoveries right now interestingly in the case ofsomeone like Elon so there is like the
 standard arguments for why you might want to take the simulation hypothesisseriously the simulation argument right
 in the case that if you are actually Elon Musk let us say there's a kind ofan additional reason
 in that what are the chances you would be Elon Musk right it seems like maybethat would be more interested in
 simulating the lives of very unusual and remarkable people so if you consider notjust assimilations where all of human
 history or the whole of human civilization are simulated but alsoother kinds of simulations which only
 include some subset of people like in the industry in those simulations thatonly include a subset it might be more
 likely that that would include subsets of people with unusually interesting orconsequential like your Elon Musk
 you got a wonder right more like yeah or if you're like if you're Donald Trump orif you are Bill Gates or you're like
 some particularly yeah like distinctive character you might think that that ad Imean if you just think of yourself into
 the shoes right it's got to be like an extra reason to think that's kind of so

1:25:12
Speaker 0 :interesting so on a scale of like farmer
 in Peru to you a musk the more you get towards the almost the higher theprobability you're dividing that would


1:25:21
Speaker 1 :be some extra boost from that there's an


1:25:25
Speaker 0 :extra boost so he also asked the
 question of what he would ask an AGI saying the question being what's outsidethe simulation do you think about the
 answer to this question if we are living a simulation what is outside thesimulation so the programmer of the


1:25:44
Speaker 1 :simulation yeah I mean I think it
 connects to the question of what's inside the simulation in that if you hadviews about the Craters of the
 simulation it might help you make predictions about what kind ofsimulation it is what what might what
 might happen what you know happens after the simulation if there is some afterbut also like the kind of setup so these
 these two questions would be quite closely intertwined but do you think

1:26:12
Speaker 0 :you'll be very surprising to it like is
 the stuff inside the simulation is it possible for it to be fundamentallydifferent than the stuff outside yeah
 like I got another way to put it can the creatures inside the simulationand be smart enough to even understand
 or have the cognitive capabilities or any kind of information processingcapabilities enough to understand the
 mechanism that created them they might

1:26:39
Speaker 1 :understand some aspects of it I mean
 it's a love all of its kind of there are levels of explanation like degrees towhich you can understand so does your
 dog understand what it is to be human well it's got some idea like humans arethese physical objects that move around
 and do things and I a normal human would have a deeper understanding of what itis to be a human and maybe some very
 experienced psychic psychologist or great novelist might understand a littlebit more about what it is to be human
 and maybe super intelligence could see right through your soul so similarly I Ido think that that we are quite limited
 in our ability to understand all of the relevant aspects of the larger contextthat we exist in but there might be hope
 first I think we understand some aspects of it but you know how much good is thatif there's like one key aspect that
 changes the significance of all the other aspects so we understand maybeit's seven out of ten key insights that
 you need but but the answer actually like varies completely depending on whatlike number eight nine and ten insight
 is it's like whether you wanna suppose that the big tasks were to guess whethera certain number was odd or even like a
 ten digit number and if it's if it's even the best thing for you to do inlife is to go north and if it's odd the
 best thing for you to go south now we are in a situation where maybe throughour science and philosophy we figured
 out what the first seven digits are so we have a lot of information right mostof it we figured out but we are clueless
 about what the last three digits are so we are still completely clueless aboutwhether the number is odd or even and
 therefore whether we should go nor go south I feel that's that's an analogybut I feel we're somewhat in that
 predicament we know a lot about the universe we've come maybe more than halfof the way there to kind of fully
 understanding it but the parts were missing or plausibly ones that couldcompletely change the overall upshot of
 the thing and including change our overall view about what the scheme ofpriorities should be or which strategic
 direction would make sense to pursue it

1:29:08
Speaker 0 :yeah I think your analogy of us being
 the dog trying to understand human beings as a as an entertaining one andprobably correct
 the closer the understanding tends from the dog's viewpoint to us humanpsychologist viewpoint the steps along
 the way there will have completely transformative ideas of what it means tobe human so the dog has a very shallow
 understanding it's interesting to think that and analogize that a dog'sunderstanding of a human being is the
 same as our current understanding of the fundamental laws of physics in the

1:29:45
Speaker 1 :

1:29:46
Speaker 0 :universe man okay we spent an hour 40
 minutes talking about the simulation I like it let's talk about superintelligence at least for a little bit
 and let's start at the basics what tu is

1:30:00
Speaker 1 :intelligence yeah I didn't not to get
 too stuck with the definitional question I mean I the common sense understandinglike the ability to solve complex
 problems to learn from experience to plan to reason some combination ofthings like that it's got this mixed up


1:30:20
Speaker 0 :into that or no it's consciousness mixed
 up into that as well I don't think I

1:30:23
Speaker 1 :think it could be fairly intelligent at
 least without being conscious probably and so then what is super intelligence

1:30:31
Speaker 0 :

1:30:32
Speaker 1 :so yeah that would be like something
 that was much more had much more general cognitive capacity than we humans haveso if we talk about general super
 intelligence it would be much faster learner be able to recent much betterMIT plans that are more effective at
 achieving its goals say in a wide of complex challenging environments in

1:30:57
Speaker 0 :terms of as we turn our eye to the idea
 of sort of existential threats from super intelligence do you think superintelligence has to exist in the
 physical world or can it be digital only sort of we think of our generalintelligence as us humans as an
 intelligence that's associated with the body that's able to interact with theworld that's able to affect the world
 directly with physically I mean digital

1:31:23
Speaker 1 :always perfectly fine I think I mean you
 you could you it's physical in the sense that obviously the computers and thememories are physical but its capability


1:31:32
Speaker 0 :to affect the world sort of could be


1:31:34
Speaker 1 :very strong even if it has a limited set
 of actuators if it can types text on the screen or something like that that wouldbe I think ample so in terms of the


1:31:46
Speaker 0 :concerns of existential threat of AI how
 can any AI system that's in the digital world have existential risk sort of whatwhat are the attack vectors for a


1:32:01
Speaker 1 :digital system well I mean I guess maybe
 to take one step back so I should emphasize that I also think there's thishuge positive potential from machine
 intelligence including super intelligence and I want to stress thatbecause like some of my write writing
 has focused on what can go wrong and when I wrote the book super intelligenceat that point I felt that was a kind of
 neglect of what would happen if AI succeeds and in particular a need to geta more granular understanding of where
 the pitfalls are so we can avoid them I think that since since the book came outin 2014 there has been a much wider
 recognition of that and a number of research groups are not actually workingon developing say AI alignments
 techniques and so on and so forth so that's I'd I'd like yeah I think nowit's important to make sure we bring
 back onto the table the upside as well

1:33:02
Speaker 0 :and there's a little bit of a neglect
 now on the upside which is I mean if you look attalking to a friend if you look at the
 amount of information there's available or people talking and people beingexcited about the positive possibilities
 of general intelligence that's not it's far outnumbered by the negativepossibilities in in terms of our public


1:33:24
Speaker 1 :discourse possibly yeah it's hard to
 measure so but what are you kneeling on

1:33:29
Speaker 0 :that's a little bit what are some to you
 possible big positive impacts of general intelligence super intense me super

1:33:37
Speaker 1 :excite end to also want to distinguish
 these two different contexts of thinking about AI and high impacts they're kindof near term and long term if you want
 both of which I think are legitimate things to think about and people shouldyou know discuss both of them but but
 they are different and they often get mixed up and then then I get you getconfusion like I think you get
 simultaneously I've maybe been overhyping of the near term and andunder hyping of the long term and so I
 think as long as we keep them apart we can have like two good conversations butor we can mix them together and have one
 bad conversation can you clarify just oh

1:34:19
Speaker 0 :the two things we were talking about the
 near term and long term yeah and what

1:34:24
Speaker 1 :are the distinction well it's a blurry
 distinction but say the things I wrote about in this book super intelligencelong term things people are worrying
 about today with I don't know algorithmic discrimination or eventhings self-driving cars and drones and
 stuff more near term and then then of course you could you button some mediumterm where that kind of overlap and they
 want evolves into the other but I don't write I think both yeah the dishes lookkind of somewhat different depending on
 which of these contexts so I think I

1:35:02
Speaker 0 :think it'd be nice if we can talk about
 the long term mm-hm and think about a positive impact or a better worldbecause of the existence of the long
 term super intelligent now do you have

1:35:18
Speaker 1 :the use of such a war yeah I mean it I
 guess it's a little harder chicklet because it seems obvious thatthe world has a lot of problems as it
 currently stands and it's hard to think of any one of those which it wouldn't beuseful to have like a friendly aligned
 super intelligence working on so from health you know to the economic system

1:35:43
Speaker 0 :to be able to sort of improve the
 investment and trade and foreign policy decisions all that kind of stuff all

1:35:51
Speaker 1 :that kind of stuff and a lot more I mean


1:35:55
Speaker 0 :

1:35:57
Speaker 1 :what's the killer app well I don't think
 there is one I think AI I especially artificial general intelligence isreally the ultimate general purpose
 technology so it's not that there is this one problem this one area where itwill have a big impact but if and when
 it succeeds it will really apply across the board in all fields where humancreativity and intelligence and
 problem-solving is useful which is pretty much all fields right there thething that it would do is give us a lot
 more control over nature it wouldn't automatically solve the problems thatarise from conflict between humans
 fundamentally political problems some subset of those might go away if youjust had more resources and cooler tech
 but some subset would require coordination that is not automaticallyachieved just by having more technical
 capability but but anything that's not of that sort I think you just get likean enormous boost with this kind of
 cognitive technology what once it goes all the way not againthat doesn't mean I'm like thinking or
 people don't recognize what's possible with current technology and likesometimes things get over height but I
 mean those are perfectly consistent views to hold the ultimate potentialbeing enormous and then it's a very
 different question of how far are we from that or what can we do withnear-term technology so what's your


1:37:25
Speaker 0 :intuition about the idea of intelligence
 explosion so there's this

1:37:30
Speaker 1 :

1:37:32
Speaker 0 :you know when you start to think about
 that leap from the near term to the long term the natural inclination like for mesort of building machine learning
 systems today it seems like it's a lot of work to get the general intelligencebut there's some intuition of
 exponential growth of exponential improvement of intelligence explosioncan you maybe try to elucidate to try to
 talk about what's your intuition about the possibility of an intelligenceexplosion they won't be this gradual
 slow process there might be a phase

1:38:07
Speaker 1 :shift yeah I think it's we don't know
 how explosive it will be I think for what it's worth I've seems fairly likelyto me that at some point I will be some
 intelligence explosion like some period of time where progress in AI becomesextremely rapid roughly roughly in the
 area where you might say it's kind of human equivalent in coral cognitivefaculties that the concept of human
 equivalent like this starts to break down when you look too closely at it butand just how explosive does something
 have to be for it to be called an intelligence expulsion like does it haveto be like overnight literally or a few
 years or so but but overall I guess in on if you had if you plotted theopinions of different people in the
 world I I guess I would be somewhat more probability towards the intelligenceexpulsion scenario than probably the
 average you know AI researcher I guess so and then the other part of the

1:39:10
Speaker 0 :intelligence explosion or just forget
 explosion just progress is once you achieve that gray area of human levelintelligence is it obvious to you that
 we should be able to proceed beyond it to get the super intelligence yeah that

1:39:27
Speaker 1 :seems I mean as much as any of these
 things can be obvious given we've never had one people have different viewssmart people of different views is like
 that it's like some some some degree of uncertainty that always remains for anybig futuristic philosophical grand
 John that just we realize humans are fallible especially about these thingsbut it does him as far as I'm judging
 things based on my own impressions that it seems very unlikely that that wouldbe a ceiling at or near human cognitive


1:40:04
Speaker 0 :capacity but and this is a I don't know
 this is a special moment and it says both terrifying and exciting to create asystem that's beyond our intelligence so
 maybe you can step back and and say like how does that possibly make you feelthat we can create something it feels
 like there's a line beyond which it steps you'll be able to outsmart you andtherefore it feels like a step where we


1:40:35
Speaker 1 :lose control well I don't think that a
 lot of follows that is you could imagine and in fact this is what a number ofpeople are working towards making sure
 that we could ultimately the project higher levels of problem-solving abilitywhile still making sure that they are
 aligned like they're in the service of human values I mean so so it's losingcontrol I think is not enough even that
 would happen now I asked how it makes me feel I I mean to some extent I've livedwith this for so long since as this as
 long as I can remember being being an adult or even a teenager it seemed to meobvious that at some point I I will
 succeed and so I actually misspoke I

1:41:20
Speaker 0 :didn't mean control I meant because the
 control problem is an interesting thing and I think we the hope is at least weshould be able to maintain control over
 systems that are smarter than us but they're they we do lose our specialnessit's sort of we'll lose our place as the
 smartest coolest thing on earth and there's an ego involved that that humansare very good at dealing with I mean I I
 value my intelligence human being it seems like a bigtransformative step to realize you
 there's something out there that's more intelligent I mean you don't see that

1:42:09
Speaker 1 :today I think yes a lot I think it
 really small I mean I think there already a lot of things out there thatare I mean certainly if you think the
 universe is big there's going to be other civilizations that already havesuper intelligences or that just
 naturally have brains the size of beach balls and they're like completelyleaving us in the dust and we haven't
 our face to face we have some face to face but I mean that's not my questionwhat what would happen in in a kind of
 posthuman world like how much day-to-day would these super intelligences beinvolved in the lives of ordinary men
 I you could imagine some scenario where it would be more like a background thingthat would help protect against some
 things but you wouldn't like that there wouldn't be this intrusive kind of likemaking you feel bad by like making
 clever jokes on your ex but like there's all sorts of things that maybe in thehuman context would feel awkward about
 that you don't want to be the dumbest kid in your class everybody picks itlike a lot of those things maybe you
 need to abstract away from if you're thinking about this context where wehave infrastructure that is in some
 sense beyond any or all humans I mean it's a little bit like say thescientific community as a whole if you
 think of that as in a mind it's a little bit of metaphor but I mean obviouslyit's going to be like way more capacious
 than any individual so in some sense there is this mind like thing alreadyout there that's that just vastly more
 intolerant and than a new individual is and we think okay that's you just acceptthat as a fact that's the basic fabric


1:43:56
Speaker 0 :of our existence intelligent yeah you


1:43:59
Speaker 1 :get used to a lot of I mean there's


1:44:00
Speaker 0 :already Google and Twitter and Facebook
 these sister recommender systems that are the basic fabric of our and I could

1:44:09
Speaker 1 :see them becoming


1:44:11
Speaker 0 :I mean do you think of the collective
 intelligence of these systems as already perhaps reaching super intelligencelevel well means I hear it comes to this


1:44:20
Speaker 1 :the concept of intelligence and the
 scale and what human level means the the kind of vagueness and indeterminacy ofthose concepts starts to dominate how he
 would answer that question so the like say the Google search engine has a veryhigh capacity of a certain kind like
 retrieve it remember remembering and retrieving information particularly liketext or images that are you have a kind
 of string a word string key like obviously superhuman at that but a vastset of other things it can't even do at
 all not just not do well but so so you have these current AI systems that aresuperhuman in some limited domain and
 then like radically subhuman in all other domains so it's same way thatchess like are just a simple computer
 that can multiply really large numbers right it's gonna have this like onespike of super intelligence and then a
 kind of a zero level of capability across all other cognitive fields andyeah I don't necessarily think the


1:45:34
Speaker 0 :journalist I mean I'm not so attached
 with it but I could sort of it's a it's a gray area and it's a feeling but to mesort of alpha zero it's somehow much
 more intelligent much much more intelligent than deep blue hmm and justsay which tomato you could say well
 these are both just board game that they're both just able to play boardgames who cares if they're good do
 better or not but there's something about the learning the self playlearning yeah that makes it crosses over
 into that land of intelligence that doesn't necessarily need to be generalin the same way Google is much closer to
 deep blue currently in terms of its search engine now then it is to sort ofalpha zero and the moment it becomes the
 moment these recommender systems really become more like alpha zero but beingable to learn
 a lot without the constraints of being heavily constrained by human interactionthat seems like a special moment in time


1:46:34
Speaker 1 :certainly learning ability seems to be
 an important facet of general intelligence that you can take some newdomain that you haven't seen before and
 you weren't specifically pre-programmed for and then figure out what's going onthere and eventually become really good
 at it so that's something alpha 0 it has much more often than deep blue had andin fact I mean systems like alpha zero
 can learn not just go but other in fact probably beat deep blue in chess and soforth right so that you say you do just
 general and it matches the intuition we feel it's more intelligent and it alsohas more of this general purpose
 learning ability and if we get systems that have been more general-purposelearning ability it might also trigger
 an even stronger intuition that they are actually starting to get smart so if you

1:47:28
Speaker 0 :were to pick a future what would eating
 a utopia looks like with a GI systems sort of is it the neural link braincomputer interface world where we're
 kind of really closely interlinked with AI systems is it possibly where a GIsystems replace us completely while
 maintaining the the values and the the consciousness is it something like it'sa completely invisible fabric like you
 mentioned a society where just AIDS and a lot of stuff that we do like carryingdiseases and so on what does utopia if
 you get to pick yeah I mean it's a good

1:48:04
Speaker 1 :question and a deep and difficult one
 I'm quite interested in it I don't have all the answers yet but or might neverhave but I think there are some
 different observations one could make one one is if this if the scenarioactually did come to pass it would open
 up this vast space of possible modes of being on one and material and resourceconstraints would just be like expanded
 dramatically so you there would be a lot of a big pie let'sright also it would enable us to to do
 things including to ourselves or not like that do you eat it would just openup this much larger design space options
 based and and we have ever had access to in in human history so I think twothings follow from that what one is that
 we probably would need to make a fairly fundamental rethink of what ultimatelywe value like think things through more
 from first principles in the context would be so different from the familiarthat we could have just take what we've
 always been doing and then like oh well we have this cleaning robot that likecleans the dishes in the sink and a few
 other small things and like I think we would have to go back to firstprinciples and so from even from the


1:49:27
Speaker 0 :individual level go back to the first
 principles of what what is the meaning of life what is happiness how it is

1:49:34
Speaker 1 :fulfillment yeah and then also connected
 to this large space of of resources is that it would be possible and I thinksomething we should aim for is to do
 well by the lights of more than one value system that is we wouldn't have tochoose only one value criterion and say
 we're gonna do something that's course really high on the metric of say evenISM and then is like a zero by other
 criteria like kind of wire headed brains innovate and it's like a lot of pleasurethat's good but then like no no Beauty
 you know achievement like no III or or or pic and I think to some significantnot unlimited sense but the significant
 sense it would be possible to do very well by many criteria like maybe youcould get like 98% of the best according
 to several criteria at the same time given this this the secret expansion ofthe option space and so so have


1:50:51
Speaker 0 :competing value systems
 in criteria as a sort of firm just like our Democrat versus Republican thereseems to be this always multiple parties
 that are useful for our progress in society even though might seemdysfunctional inside the moment but
 having the multiple value systems used to be beneficial for I guess a balance

1:51:16
Speaker 1 :of power so that's yeah let's not not
 exactly what I have in mind that it's well although alchemy may be in anindirect way it is but that if you had
 the chance to do something that scored well in several different isometrics ourfirst instinct should be to do that
 rather than immediately leap to the thing ah which one's of these valuesystems are we gonna screw over like our
 first in let's first try to do very well by all of them yeah then it might bethat you can't get a hundred percent of
 all and you would have to then like have the hard conversation about which onewill only get ninety-seven particular


1:51:53
Speaker 0 :there's my cynicism that all of
 existence is always a trade-off but you say that maybe it's not such a bad tradeoffice first


1:51:59
Speaker 1 :he's right well this would be a
 distinctive context in which at least some of the constraints would be removedprobably stupid trade-offs in the end
 it's just that we should first make sure we at least take advantage of thisabundance so in terms of thinking about
 this like yeah what one should think I think in this kind of frame of mind ofgenerosity and a inclusiveness to
 different value systems and and see how far one can get there firstand I think one could do something that
 that would be very good according to many different criteria we kind of

1:52:43
Speaker 0 :talked about AGI fundamentally
 transforming the the value system of our existence the mean the meaning of lifebut today what do you think is the
 meaning of life what are you the serious or perhaps the biggest question what'sthe meaning of life what's the meaning
 of existence what makes what gives your life fulfillment purposehappiness meaning yeah I think these are


1:53:07
Speaker 1 :like I guess a bunch of different but
 related questions in there that one can ask happiness meaning yeah I mean it

1:53:17
Speaker 0 :

1:53:18
Speaker 1 :like he's pretty bad and somebody
 getting a lot of happiness for something that they didn't think was meaningfullike mindless like watching reruns of
 some television series avoiding junk food like maybe some people that givespleasure but they wouldn't think it had
 a lot of meaning whereas conversely something that might be quite loadedwith meaning might not be very fun
 always like some difficult achievement that really helps a lot of people mayberequires self-sacrifice and hard work
 and so so these things can I think come apart which is something to bear in mindalso when if you're thinking about these
 utopia questions that you might actually start to do some constructive thinkingabout that you might have to isolate and
 distinguish these different kinds of things that might be valuable indifferent ways make sure you can sort of
 clearly perceive each one of them and then you can think about how you cancombine them and just as you said


1:54:23
Speaker 0 :hopefully come up with a way to maximize


1:54:27
Speaker 1 :all of them together yeah maximize or or
 get like a very high score on on a wide range of them even if not literally allyou can always come up with values that
 are exactly opposed to one another right but I think for many values they're kindof a post with m'p lace them in in a
 certain dimensionality of your face like there are shapes that are kind of youcan't untangle like in a given
 dimensionality but if you start adding dimensions then it might in many casesjust be that they are easy to pull apart
 and you could so we'll see how much space there is for that but I think thatthere could be a lot in this context of
 radical abundance if ever we get to that I don't think there's a better way to

1:55:12
Speaker 0 :end it Nick you've influenced the huge
 number of people too work on what could very well be the mostimportant problems of our time so it's a
 huge honor and thank you so much for

1:55:24
Speaker 1 :talking for coming by likes that's fun
 thank you thanks for listening to this

1:55:28
Speaker 0 :conversation with Nick Bostrom and thank
 you to a presenting sponsor cash app please consider supporting the podcastby downloading cash app and using code
 lex podcast if you enjoy this podcast subscribe on youtube review it with fivestars a NAPA podcast supporter on
 patreon or simply connect with me on Twitter and lex

1:55:50
Speaker 1 :friedman and now let me leave you with


1:55:51
Speaker 0 :some words from nick bostrom
 our existential risks cannot be one oftrial-and-error there's no opportunity
 to learn from errors the reactive approach see what happens limit damagesand learn from experience is unworkable
 rather we must take a proactive approach this requires foresight to anticipatenew types of threats and a willingness
 to take decisive preventive action and to bear the costs moral and economic ofsuch actions thank you for listening and


1:56:24
Speaker 1 :

1:56:25
Speaker 0 :

