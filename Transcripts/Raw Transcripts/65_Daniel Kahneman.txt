 the following is a conversation with Daniel Kahneman winner of the Nobel Prize in Economics for his integration of economic science with a psychology of human behavior judgment and decision-making he's the author of the popular book Thinking Fast and Slow that summarizes in an accessible way his research of several decades often in collaboration with Amos Tversky a cognitive biases prospect theory and happiness the central thesis of this work is the dichotomy between two modes of thought what he calls system one is fast instinctive and emotional system two is slower more deliberative and more logical the book delineates cognitive biases associated with each of these two types of thinking his study of the human mind and his peculiar and fascinating limitations are both instructive and inspiring for those of us seeking to engineer intelligent systems this is the artificial intelligence podcast if you enjoy it subscribe on YouTube give it five stars an Apple podcast follow on Spotify supported on patreon or simply connect with me on Twitter Alex Friedman spelled Fri D ma a.m. I recently started doing ads at the end of the introduction I'll do one or two minutes after introducing the episode and never any ads in the middle that can break the flow of the conversation I hope that works for you and doesn't hurt the listening experience this show is presented by cash app the number one finance app in the App Store I personally use cash app to send money to friends but you can also use it to buy sell and deposit Bitcoin in just seconds cash app also has a new investing feature you can buy fractions of a stock say $1 worth no matter what the stock price is brokerage services are provided by cash app investing a subsidiary of square and member si PC I'm excited to be working with cash app to support one of my favorite organizations called first best known for their first robotics and Lego competitions they educate and inspire hundreds of thousands of students in over 110 countries and have a perfect rating a charity navigator which means that donated money is used to maximum effectiveness when you get cash app from the App Store Google Play and use code Lex podcast you'll get ten dollars in cash up will also donate ten dollars to the first which again is an organization that I've personally seen inspire girls and boys the dream of engineering a better world and now here's my conversation with Daniel Kahneman you tell a story of an SS soldier early in the war world war two in nazi-occupied France and Paris where you grew up he picked you up and hugged you and showed you a picture of a boy maybe not realizing that you were Jewish not maybe certainly not so I told you I'm from the Soviet Union that was significantly impacted by the words well and I'm Jewish as well what do you think World War two taught us about human psychology broadly well I think the the only big surprise is the extermination policy genocide by the German people that's when you look back on it and you know I think that's a major surprise it's a surprise because it's a surprise that they could do it it's a surprise that they that enough people willingly participated in that this is this is a surprise now it's no longer a surprise but it's changed many people's views I think about about human beings certainly for me the Ackman trial in a teaches you something because it's very clear that if it could happen in Germany it could happen anywhere it's not that the Germans were special this could happen anyway so what do you think that is do you think we're all capable of evil we're all capable of cruelty I don't think in those terms I think that what is certainly possible is you can dehumanize people so that there you treat them not as people anymore but as animals and and the same way that you can slaughter animals without feeling much of anything it can the same and when you feel that the I think the combination of dehumanizing the other side and and having uncontrolled power over other people I think that doesn't bring out our the most generous aspect of human nature so that Nazi soldier you know he he was a good man I mean you know and he was perfectly capable of killing a lot of people and I'm sure he did but what what did the Jewish people mean to Nazis so what the dismissal of Jewish as well worthy of again this is surprising that it was so extreme but it's not one thing in human nature I don't want to call it evil but the distinction between the in-group and the out-group that is very basic so that's built in the the loyalty and affection towards in-group and the willingness to dehumanize the out-group that's that is in human nature and that's that's what I think probably didn't need the Holocaust to teach us that but the Holocaust is a very sharp lesson of you know what can happen to people and when the people can do so the effect of the in-group and the out-group you know that it's clear that those were people you know you could you could shoot them you could you know they were not human they were not there was no empathy or very very little empathy left so occasionally you know they might have been and and very quickly by the way the empathy disappeared if there was initially and the fact that everybody around you was doing it that that completely the group doing it and everybody shooting Jews I think that that makes it permissible now how much you know whether it would it could happen or in every culture or whether the Germans were just particularly efficient and and disciplined so they could get away with it that is a question it's an interesting question are these artifacts of history or is it human nature I think that's really human nature you know you put some people in a position of power relative to other people and and then they become as human become different but in general and war outside of concentration camps in World War two it seems that war brings out darker sides of human nature but also the beautiful things about human nature well no I mean but it what it brings out is the loyalty among soldiers I mean it brings out the bonding male bonding I think is a very real thing that and that happens and so and and there is a student of thrill to friendship and there is certainly a certain thrill to friendship under risk and to shared risk and so people have very profound emotions up to the point where it gets so traumatic that that little is left but so let's talk about psychology a little bit in your book Thinking Fast and Slow you described two modes of thoughts as the one the fast instinctive an emotional one is system to the slower deliberate logical one at the risk of asking Darwin to discuss a theory of evolution can you describe distinguishing characteristics for people who have not read your book of the two systems well I mean the mood system is a bit misleading but it's at the same time it's misleading it's also very useful but what I call system one it's easier to think of it as as a family of activities and primarily the way I describe it is there are different ways for ideas to come to my mind and some ideas come to mind automatically and the example a standard example is two plus two and then something happens to you and and in other cases you've got to do something you got to work in order to produce the idea and my example I always give the same pair of numbers is 27 times 14 I think you have to perform some algorithm in your heads and yes and and it takes time it's a very difference nothing comes to mind except something comes to mind which is the algorithm I mean that you've got to perform and then it's work and it engages short-term memory and thing ages executive function and it makes you incapable of doing other things at the same time so the the main characteristic of system 2 is that there is mental effort involved and there is a limited capacity for mental effort where a system one is effortless essentially that's the major distinction so you talk about there you know it's really convenient to talk about two systems but you also mentioned just now and in general that there's no distinct two systems in the brain from a neurobiological even from psychology perspective but why does it seem to from the experiments you've conducted there does seem to be kind of emergent two modes of thinking so at some point these kinds of systems came into a brain architecture maybe ma'am will share it but the or do you not think of it at all in those terms that it's all on mush and these two things just emerge you know evolutionary theory saying about this is cheap and easier so it's the way I think about it is that it's very clear that animals have a perceptual system and that includes an ability to understand the world at least to the extent that they can predict they can't explain anything but they can anticipate what's going to happen and that's the key form of understanding the world and my crude idea is that we would I call system - well system - grew out of this and you know there is language and there is the capacity of manipulating our ideas and the capacity of imagining futures and of imagining counterfactuals thing that haven't happened and and to do conditional thinking and there are really a lot of abilities that without language and without the the very large brain that we have compared to others it would be impossible now system one is more like what the animals are but system one also can talk I mean it has language it understands language indeed it speaks for us I mean you know I'm not choosing every word you know as a deliberate process the words I have some idea and then the words come out and that's automatic and effortless and many of experiments you've done is to show that listen system won't exist and it does speak for us and we should be careful about it's the voice it provides well it's I mean you know we have to trust it because it's the speed at which it acts a system is usable if we if we depend on one system to for survival we wouldn't survive very long because it's very slow yeah crossing the street crossing a street I mean many things depend on there being automatic one very important aspect of system one is that it's not instinct you use the word instinct that it contains skills that clearly have been learned so that skilled behavior like driving a car or speaking in fact skilled behavior has to be learned and so it doesn't you know you don't come equipped with with driving you have to learn how to drive and and you have to go through a period where driving is not automatic before it becomes automatic so yeah you construct I mean this is where you talk about heuristic and biases you to make it automatic you create a pattern and then system one essentially matches a new experience against a previously seen pattern and when that match is not a good one that's when the cognate all of them all the mess happens but it's most of the time it works and so it's pretty most of the time the anticipation of what's going to happen next is correct and and most of the time the plan about what you have to do is correct and so most of the time everything works just fine what's interesting actually is that in some sense system one is much better at what it does and system tool is at what it does that is there is that quality of effortlessly solving enormous ly complicated problems which clearly exists so that the chess player a very good chess player all the moves that come to their mind are strong moves so all the selection of strong moves happens unconsciously and automatically and very very fast and and all that is in system one so you a system two verifies so along this line of thinking really what we are our machines that construct a pretty effective system one you could think of it that way so so we're now talking about humans but if we think about building artificial intelligence systems robots do you think all the features in bug that you have highlighted in human beings are useful for constructing AI systems so both systems are useful for perhaps while instilling in robots what is happening these days is that actually what is happening in deep learning is is more like a system one product than like a system to product I mean deep learning mattress patterns and anticipate what's going to happen so it's highly predictive what's right what deep learning doesn't have and you know many people think that this is the critical it it doesn't have the ability to reason so it it does and there is no system to bear but I think very importantly it doesn't have any causality or any way to represent meaning and to represent real interaction so until that is solved the you know what can be accomplished is marvelous and very exciting but limited that's actually really nice to think of current advances in machine learning is essentially system one advances so how far can we get with just system one if we think of learning and artificial systems and we know it's very clear that deep mind is already gone we're way beyond what people thought was possible I think I think the thing that has impressed me most about the developments in AI is the speed it's that things at least in the context of deep learning and maybe this is about to slow down but things moved a lot faster than anticipated the transition from solving solving chess to solving go was I mean that's the world rain how quickly it went the move from alphago to alpha 0 is sort of bewildering the speed at which they accomplish that now clearly there they're eight so there are many problems that you can solve that way but there's some problem for which who needs something else something like a reasoning where reasoning and also you know that one of the real mysteries psychologist there Gary Marcus who is also a critic of AI I mean he what he points out and I think he has a point is that humans learn quickly children don't need million examples they need two or three examples so clearly there is a fundamental difference and what enables what enable the machine to to learn quickly what you have to build into the machine because it's that you have to build some expectations or something in the machine to make it ready to learn quickly that's that at the moment seems to be unsolved I'm pretty sure that the mind is working on it but yeah there if they have solved it I haven't heard yet they're trying to actually them an open they are trying to start to get to use neural networks to reason so assemble knowledge of course causality is temporal causality is out of reach to most everybody you mentioned the benefits of system one is essentially that it's fast allows us to function in the world now some skilled you know its skill and it has a model of the world you know in a sense I mean there was the earlier phase of a I attempted to moral reasoning and they were moderately successful but you know reasoning by itself doesn't get you much deep learning has been much more successful in terms of you know what they can do but now it's an interesting question whether its approaching its limits what do you think I think absolutely so I just talked to John laocoon he mentioned you know I know him so he thinks that the limits were not going to hit the limits with you all networks that ultimately this kind of system on pattern matching will start to start to look like system two with without significant transformation of the architecture so I'm more with the but the majority of the people who think that yes new all networks will hit a limit in their capability he on the one hand I have heard him tell the missus obvious essentially that you know what they have accomplished it's not a big deal that they have just touched that basically you know they can't do unsupervised learning in in an effective way and but you're telling me that he thinks that the current within the current architecture you can do causality and reasoning so he's very much a pragmatist in a sense that saying that were very far away that they're still yeah I think there's this idea that he says is uh we can only see one or two mountain peaks ahead and there might be either a few more after or thousands more after yeah so that kind of idea right but nevertheless it doesn't see a the final answer not fundamentally looking like one that we currently have so neural networks being a huge part that you know I mean that's very likely because because pattern matching is so much of what's going on and you can think of neural networks as processing information sequentially yeah I mean you know there is there is an important aspect to for example you get systems that translate and they do a very good job but they really don't know what they're talking about and and and for that I'm really quite surprised for that you would need you would need an AI that has sensation an AI that is in touch with the world awareness and maybe even something resembles consciousness kind of ideas li awareness of you know awareness of what's going on so that the the words have meaning who can get are in touch with some perception or some action yeah so that's a big thing for yarn and as well here first is grounding to the physical space so so that's what we're talking about the same yeah so but so how you ground I mean the grounding without grounding then you get you get a machine that doesn't know what it's talking about because it is talking about the world ultimately the question open question is what it means to ground I mean we're very human centric in our thinking but what does it mean for a machine to understand what it means to be in this world does it need to have a body does he need to have a finiteness like we humans have all of these elements it's very nice to know I'm you know I'm not sure about having a body but having a perceptual system having a body would be very helpful to me if if you think about human mimicking human ooh but having a perception that seems to be central so that you can build you can accumulate knowledge about the world so if you can you can imagine a human completely paralyzed and there's a lot that the human brain could learn you know with a paralyzed body so if we got a machine that could do that it would be a big deal and then the flip side of that something you see in children and something in machine learning world is called active learning maybe it is is being able to play with the world how important for developing system owners or system to do you think it is to play with the world be able to interact with me a lot a lot of what you learn as you learn to anticipate the outcomes of your actions I mean you can see that how babies learn it you know with their hands they are they learn you know to connect you know the movement so their hands with something that clearly is something that happens in the brain and and and the ability of the brain to learn new patterns so you know it's the kind of thing that you get with artificial limbs that you connect it and then people learn to operate the artificial limb you know really impressively quickly at least from from what I hear so and we have a system that is ready to learn the world's reaction at the risk of going into way too mysterious of land what do you think it takes to build a system like that obviously we're very far from understanding how the brain works but how difficult is it to build this mind of ours you know I mean I think that yonder Coons answer that we don't know how many mountains there are I think that's a very good answer I think that you know if you if you look at what cool Ray Kurzweil is saying that strikes me as of the war but but I think people are much more realistic than that were actually they Mesa sabe is and Yanis and so the people are actually doing the work fairly realistic I think - maybe phrase it another way from a perspective not of building it but from understanding it how complicated are human beings in the following sense you know I work with autonomous vehicles and pedestrians so we tried to model pedestrians how difficult is it to model a human being their perception of the world the two systems they operate under sufficiently to be able to predict whether the pedestrians gonna cross the road or not I'm you know I'm fairly optimistic about that actually because what we're talking about is a huge amount of information that every vehicle has and that feeds into one system into one gigantic system and so anything that any vehicle learns becomes part of what the whole system knows and with a sister multiplier like that there is a lot that you can do so human beings are very complicated but and and you know system is going to make mistakes but human makes mistakes I think that they'll be able to I think they are able to anticipate pedestrians otherwise a lot would happen they're able to you know they're able to get into a roundabout and into the end to traffic so they must know both to expect though to anticipate how people will react when they're sneaking in and there's a lot of learning that's involved in that currently the pedestrians are treated as things that cannot be hid and not treated as agents with whom you interact in a game theoretic way so I mean it's not it's a totally open problem and every time somebody tries to solve it it seems to be harder than we think and nobody's really tried to seriously solve the problem of that dance because I'm not sure if you've thought about the problem of pedestrians but you're really putting your life in the hands of the driver you know there is a dance as part of the dance that would be quite complicated but for example when I cross the street and there is vehicle approaching I look the driver in the eye and I think many people do that and you know that's a signal that that I'm sending and I would be sending that machine to an autonomous vehicle and it had better understand it because it means I'm crossing so and there's another thing you do that actually so I'll tell you what you do because we watch I've watched hundreds of hours of video on this is when you step in the street you do that before you step on the street and when you step in the street you actually look awake away yeah yeah now what what is it what the saying is mean you're trusting that the car who hasn't slowed down yet will slow down and you're telling him yeah I'm committed yeah I mean this is like in a game of chicken so I'm committed and if I'm committed I'm looking away so there is you you just have to stop so the question is whether a machine that observes that needs to understand mortality here I'm not sure that it's got to understand so much it's got to anticipate so and here but you know you're surprising me because here I would think that maybe you can anticipate without understanding because I think this is clearly what's happening in playing go or in playing trace there's a lot of anticipation and there is zero understanding so I thought that you didn't need a model of the human yes and the model of the human mind to avoid hitting pedestrians but you are suggesting that I do yeah you do as and then it's then it's a lot harder so this is all and I have a follow-up question to see where your intuition lies is it seems that almost every robot human collaboration system is a lot harder than people realize so do you think it's possible for robots and humans to collaborate successfully if we talked a little bit about semi autonomous vehicles like in the Tesla autopilot but just in tasks in general if you think we talked about current you'll know where it's being kind of system one do you think those same systems can borrow humans for system to type tasks and collaborate successfully well I think that in any system where humans and the Machine interact that the human will be superfluous within a fairly short time and that is if the Machine has advanced enough so that it can really help the human then it may not need the human for a long now it would be very interesting if if there are problems that for some reason the machine doesn't you're not so but that people could solve then you would have to build into the machine and ability to recognize that it is in that kind of problematic situation and and to call the human that that cannot be easy without understanding that is its it must be very difficult to to program a recognition that you are in a problematic situation without understanding the problem but that's very true in order to understand the full scope of situations that are problematic you almost need to be smart enough to solve all those problems it's not clear to me how much the machine will need the human I think the example of chess is very instructive I mean there was a time at which Kasparov was saying that human machine combinations will beat everybody even stockfish doesn't need people yeah and alpha zero certainly doesn't need people the question is just like you said how many problems are like chess and how many problems are the ones where are not like chess where even well every problem probably in the end is like chess the question is how long is that transition period I mean you know that that's a question I would ask you in terms of men autonomous vehicle just driving is probably a lot more complicated than go to solve that yes and that's surprising because it's open no I mean you know I couldn't that's not surprising to me because the because that there is a hierarchical aspect to this which is recognizing a situation and then within the situation bringing bringing up the relevant knowledge and and for that hierarchical type of system to work you need a more complicated system currently a lot of people think because as human beings this is probably the the cognitive biases they think of driving is pretty simple because they think of their own experience this is actually a big problem for aai researchers or people thinking about AI because they evaluate how hard a particular problem is based on very limited knowledge but basically how hard it is for them to do the task yeah and then they take for granted I mean maybe you can speak to that because most people tell me driving is trivial and and humans in fact are terrible at driving is what people tell me and I see humans and humans are actually incredible at driving and driving is really terribly difficult yeah so is that just another element of the effects that you've described in your work on the psychology side oh no I mean I haven't really you know I I would say that my research has contributed nothing to understanding the ecology into understanding the structure of situations yeah and the complexity of problems so all all we know is very clear that that go it's endlessly complicated but it's very constrained so and in the real world there are far fewer constraints and and many more potential surprises so so that's obviously because it's not always obvious to people right so when you think about well I mean you know people thought that reasoning was hard and perceiving was easy but you know they quickly learned that actually modeling vision was tremendously complicated and modelling even proving theorems was relatively straightforward to push back in and out a little bit on the quickly part they haven't it took several decades to learn that and most people still haven't learned that I mean our intuition of course AI researchers have but you drift a little bit outside the specific a I feel the intuition is still perceptible yes all no I mean that's true I mean intuitions the intuitions of the public haven't changed radically and they are there as you said they're evaluating the complexity of problems by how difficult it is for them to solve the problems and that's got very little to do with the complexities of solving them in AI how do you think from the perspective of AI researcher do we deal with the intuitions of the public so in trying to think me arguably the combination of hype investment and the public intuition is what led to the AI winters I'm sure that same can be applied to tech or that the intuition of the public leads to media hype these two companies investing in the tech and then the text doesn't make the company's money and then there's a crash is there a way to educate people is there to fight the let's call it system 1 thinking in general no I think that's the simple answer and it's going to take a long time before the understanding of where those systems can do becomes you know button becomes public knowledge I and and then and the expectations you know there are several aspects that are going to be very complicated that the the fact that you have a device that cannot explain itself is a major major difficulty and and we're already seeing that I mean this is this is really something that is happening so it's happening in the judicial system so you have you have system that are clearly better at predicting parole violations then than judges but but they can't explain their reasoning and so people don't want to trust them we are seem to you in system one even use cues to make judgments about our environment so this explain ability point do you think humans can explain stuff no but so I mean there is a very interesting aspect of that humans think they can explain themselves right so when you say something and I ask you why do you believe that then reasons will occur to you and you were but actually my own belief is that in most cases the reasons are very little to do with why you believe what you believe so that the reasons are a story that that comes to your mind when you need to explain yourself but but but people traffic in those explanations I mean the human interaction depends on those shared fictions and and the stories that people tell themselves you just made me actually realize and we'll talk about stories in a second that not to be cynical about it but perhaps there's a whole movement of people trying to do explainable AI and really we don't necessarily need to explain hey I just need to explain itself it just needs to tell a convincing story yeah it doesn't missus the story doesn't necessarily need to reflect the truth is it just needs to be convincing there's something you can say exactly the same thing in a way that's sound cynical abysm sounds in a grave and so but but the objective brilliant of having an explanation is is to tell a story that would be acceptable to people and and and for it to be acceptable and to be a robustly acceptable it has to have some elements of truth but but the objective is for people to accept it it's quite brilliant actually but so on the and the stories that we tell sorry to ask me to ask you the question that most people know the answer to but you talk about two cells in terms of how life has lived the experience self and remembering self and you describe the distinction between the two well sure I mean the there is an aspect of of life that occasionally you know most of the time we just live and web experiences and they're better and they are worse and it goes on over time and mostly we forget everything happens we forget most of what happens then occasionally you when something ends or different points you evaluate the past and you form a memory and the memory is schematic it's not that you can roll a film of an interaction you construct in effect the elements of a story about it about an episode so there is the experience and there is a story that is created about the experience and that's what I call the remember II so I had the image of two selves so there is a self that lives and there is a self that evaluates life now the paradox and the deep paradox in that is that we have one system or one self that does the living but the other system the remembering self is all we get to keep and basically decision-making and and everything that we do is governed by our memories not by what actually happened it's it's governed by by the story that we told ourselves or by the story that we're keeping so that that's the distinction I mean there's a lot of ideas about the pursuit of happiness that come out of that what are the properties of happiness which emerge from yourself there are there are properties of how we construct stories that are really important so that I studied a few but but a couple are really very striking and one is that in stories time doesn't matter there's a sequence of events so there are highlight those not and and how long it took you know they lived happily ever after and three years later something it time really doesn't matter and in stories events matter but time doesn't that that leads to a very interesting set of problems because time is all we got to live I mean you know time is the currency of life and yet time is not represented basically in evaluative memories so that that creates a lot of paradoxes that I've thought about yeah they're fascinating but if you were to [Music] give advice on how one lives a happy life well this and such properties what's the optimal you know I give up I abandoned happiness research because I couldn't solve that problem I couldn't I couldn't see and in the first place it's very clear that if you do talk in terms of those two selves then that what makes the remembering self happy and what makes the experiencing self happy are different things and I I asked the question of suppose you're planning a vacation and you're just told that at the end of the vacation you'll get an amnesic drugs who remember nothing and they'll also destroy your your photos so there'll be nothing would you still go to the same vacation and and it's it turns out we go to vacations in large part to construct memories not to have experiences but to construct memories and it turns out that the vacation that you would want for yourself if you knew you would not remember is probably not the same vacation that you will want for yourself if you will remember so I have no solution to these problems but clearly those are big issues and you've thought about issues you've talked about sort of how many minutes or hours you spend about the vacation it's an interesting way to think about it because that's how you really experience the vacation outside the being in it but there's also a modern I don't know if you think about this or interact with it there's a modern way to magnify the remembering self which is by posting an Instagram on Twitter on social networks a lot of people live life for the picture that you take that you post somewhere and now thousands of people sharing and potentially petitioning millions and then you can relive it even much more than just those minutes do you think about that i magnification much you know I'm too old for social networks I you know I've never seen Instagram so I cannot really speak intelligently about those things I'm just too old but it's interesting to watch the exact times you describe I make a very big difference I mean and it will make it will also make a difference and that I don't know whether it's clear that in some ways the devices that serve us supplants function so you don't have to remember phone numbers you don't have you really don't have to know facts I mean the number of conversations I'm involved with when somebody says well let's look it up so it's it's in a way it's made conversations well it's it means that it's much less important to know things you know it used to be very important to know things this is changing so the requirements of that that we have for ourselves and for other people are changing because of all those supports and because and I have no idea but Instagram does connected so well I'll tell you train you I mean I wish I could just have the my remembering self could enjoy this conversation but I'll get to enjoy it even more by having watched by watching it and then talking to others will be about a hundred thousand people scary's is this to say well listen or watch this right it changes things it changes the experience of the world that you seek out experiences which could be shared in that way it's in and I haven't seen it's it's the same effects that you described and I don't think the psychology of that magnification has been described yet because in your world the sharing then was appear there was a time when people read books and you could assume that your friends had read the same books that you read so there was kind of invisible sharing a year it was a lot of sharing going on and there was a lot of assumed common knowledge and you know that was built in I mean it was obvious that you had read the New York Times it was obvious that you'd read the reviews I mean so a lot was taken for granted that was shared and you know when they were when there were three television channels it was obvious that you'd seen one of them probably the same so sharing sharing he's always been always was always there it was just different at the risk of inviting mockery from you let me say there that I'm also a fan of Sartre and Camus and existentialist philosophers and I'm joking of course about mockery but from the perspective of the two selves what do you think of the existentialist philosophy of life so trying to really emphasize the experiencing self as the proper way to or the best way to live life I don't know enough philosophy to and so that but it's not a you know the emphasis on an experience is also the emphasis in Buddhism right it's so that you just have got to to experience things and and and not to evaluate and not to pass judgment and not to score not to keep score so if when you look at the the grand picture of experience you think there's something to that that one one of the ways to achieve contentment and maybe even happiness is letting go of any of the things any of the procedures of the remembering self well yeah I mean I think you know if one could imagine a life in which people don't score themselves it it feels as if that would be a better life as if the self scoring and you know how am i doing a kind of question is not is not a very happy thing to have but I got out of that field because I couldn't solve that and and that was because my intuition was that the experiencing self that's reality but then it turns out that what people want for themselves there's not experience that they want memories and they want a good story about their life and so you cannot have a theory of happiness that doesn't correspond to what people want for themselves and when I when I realized that this this was where things were going I really sort of left the field of research do you think there's something instructive about this emphasis of reliving memories in building AI systems so currently artificial intelligence systems are more like experiencing self in that they react to the environment there's some pattern formation like learning so on but you really don't construct memories except in reinforcement learning everyone swather you replay over and over yeah but you know that would in principle would not be you know yes useful do you think it's a feature a bug of human beings that we that we look back oh I think that's definitely a feature that's not a bug I mean you you have to look back in order to look forward so without without looking back you couldn't you couldn't really intelligently look forward you're looking for the echoes of the same kind of experience in order to predict what the future holds yeah though Viktor Frankl in his book man's search for meaning I'm not sure if you've read describes his experience at the consecration a concentration camps during World War two as a way to describe that finding identifying a purpose in life a positive purpose in life can say one from suffering first of all do you connect with the philosophy they he describes they're not really I mean the so I can I can really see that somebody who has that feeling of per person meaning and so on that that could sustain you I in general don't have that feeling and I'm pretty sure that if I were in a concentration camp and give up and die you know so he talks he is he's a survivor yeah and you know he survived with that and I'm and I'm not sure how I central to survival the same years yeah I do know when I think about myself that I would have given up at oh yeah this isn't going anywhere and there is there is a sort of character that that that manages to survive in conditions like that and then because they survive they tell stories and it sounds as if they survived because of what they were doing we have no idea they survived because the kind of people that they are and the other kind of people survives them to tell them such stories of a particular guy so I'm not so that you don't think seeking purpose is a significant driver and are the units it's a very interesting question because when you ask people whether it's very important to add meaning in their life that's oh yes that's the most important thing but when you ask people what kind of a day did you have and and you know what were the experiences that you remember you don't get much meaning you get social experiences then and and some people say that for example in in in child you know in taking care of children the fact that they're your children and you're taking care of them makes a very big difference I think that's entirely true but it's more because the story that we are telling ourselves which is a very different story when we're taking care of our children or when we're taking here other thing jumping around a little bit in doing a lot of experiments let me ask a question most of the work I do for example is in the wall in the real world but most of the clean good-sized that you can do is in the lab so that distinction do you think we can understand the fundamentals of human behavior through controlled experiments in the lab if we talk about pupil diameter for example it's much easier to do when you can control lighting conditions yeah thanks so when we look at driving lighting variation destroys yeah absolutely your ability to use pupil diameter but in the lab for as I mentioned semi autonomous autonomous vehicles in driving simulators we can't we don't capture true honest human behavior in that particular domain so your what's your intuition how much of human behavior can we study in this controlled environment of the lab a lot but you'd have to verify it you know that you'll your conclusions are basically limited to the situation to the experimental situation then you have to jump the big inductive leap to the real world so and and that's the Flair that's where the difference I think between the good psychologist and others of the mediocre is in the sense of that your experiment captures something that's important and something that's real and others are just running experiments so what is that like the birth of an idea to his development in your mind to something that leads to an experiment is that similar to maybe like what I Steiner good physicists do is your intuition you basically use your intuition to build up but I mean you know it's it's very skilled intuition right I mean I just had that experience actually I had an idea that's turned out to be very good idea a couple of days ago and and you and you have a sense of that building up so I'm working with a collaborator and he essentially was saying you know what what are you doing what's what's going on and I was I really I couldn't exactly explain it but I knew this is going somewhere but you know I've been around that game for a very long time and so I can you you develop that anticipation that yes this this is worth following now that he's here that's part of the skill is that something you can reduce two words in describing a process in in the form of advice to others know follow your heart essentially you know it's it's like trying to explain what it's like to drive it's not you've got to break it apart and it's not and then you lose and then you lose the experience them you mentioned collaboration you've written about your collaboration with Amos Tversky that this is you writing the twelve or thirteen years in which most of our work was joint four years of interpersonal and intellectual bliss everything was interesting almost everything was funny and that was a current joy of seeing an idea take shape so many times in those years we shared the magical experience of one of us saying something which the other one would understand more deeply than a speaker had done contrary to the old laws of information theory it was common for us to find that more information was received than had been sent I have almost never had the experience with anyone else if you have not had it you don't know how marvelous collaboration can be so let me ask a bird perhaps a silly question how does one find in create such a collaboration that may be asking like how does one find love but yeah yeah to be you have to be lucky and and I think you have to have the character for that because I've had many collaborate I mean none worth as exciting as with almost be but Fahad and I'm having it was very so it's a skill I think I'm good at it not everybody is good at it and then it's the luck of finding people who are also good at it is there advice in a forum for a young scientist who also seeks to violate this law of information dairy I really think it's so much luck is involved and you know in in those really serious collaborations at least in my experience are a very personal experience and and I have to like the person I'm working with otherwise you know I mean there is that kind of collaboration which is like an exchange a commercial exchange of giving this you give me that but the the real ones are interpersonal they're between people like each other and and who like making each other think and who like the way that the other person responds to your thoughts you have to be lucky yeah I mean but I already noticed if I even just me showing up here evil you've quickly started to digging in a particular problem I'm working on and already new information started to emerge is that a process you just the process of curiosity of talking to people about problems and seeing I'm curious about anything to do with AI and robotics and on so and I knew that you were dealing with that so it was curious just follow your curiosity jumping around and a psychology front the dramatic sounding terminology of replication crisis but really just the at times this this effect at a time studies do not are not fully generalizable they don't you have being polite is it so I'm actually not fully familiar well the memory how bad it is right so what do you think is the source where do you think I think I know what's going on actually I mean I have a theory about what's going on and what's going on is that there is first of all a very important distinction between two types of experiments and one type is within subject so it's the same person has two experimental conditions and the other type is between subjects where some people have this condition are the people in that condition they're different world and between subject experiments are much harder to predict and much harder to anticipate and the reason and they're also more expensive because you need more people and it's just so between subject experiments is where the problem is it's not so much and within subject experiments it's really between and there is a very good reason why the intuitions of researchers about between subject experiments are wrong and that's because when you are a researcher you're in a within subject situation and it is you are imagining the two conditions and you see the causality and you feel it and but in the between subjects condition they don't like they see they live in one condition and the other one is just nowhere so our intuitions are very weak about between subject experiments and that I think is something that people haven't realized and and in addition because of that we have no idea about the power of manipulations of experimental manipulations because the same manipulation it's much more powerful when when you are in the two conditions then when you live in only one condition and so the experimenters have very poor intuitions about between subject experiments and and there is something else which is very important I think which is that almost all psychological hypotheses are true that is in the sense that you know directionally if you have a hypothesis that a really causes B that that it's not true that is causes the opposite of B maybe a just and very little effect but hypotheses are true mostly except mostly they're very weak they're much weaker than you think when you are having images of so the reason I'm excited about that is that I recently heard about some some friends of mine who they essentially funded 53 studies of behavioral change by 20 different teams of people with a very precise objective of changing the number of time that people go to the gym but you know and and the success rate was zero the knocks one of the 53 studies work now what's interesting about that is those are the best people in the field and they have no idea what's going on so they are not calibrated they think that it's going to be powerful because they can imagine it but actually it's just weak because the and you are focusing on on your manipulation and it feels powerful to you there's a thing that I've written about that's called the focusing illusion that is that when you think about something it looks very important more important than it really is more important than it really is but if you don't see that effect the 53 studies doesn't I mean you just report that so what was I guess the solution to that well I mean the the solution is for people to trust their intuitions less all to try out their intuitions before I mean experiments have to be pre-registered and by the time you run an experiment you have to be committed to it and you have to run the experiment seriously enough and in a public and so this is happening and the interesting thing is what what happens before and how do people prepare themselves and how they run pilot experiments it's going to train the way psychologies done and it's already happening do you ever hope for as my connect to the this study sample size yeah I do ever hope for the internet or do you know this is really happening MTurk yeah everybody is running experiments on him to look and and it's very cheap and very effective do you think that changes psychology essentially because you're think you can object it then truly it will I mean I you know I can't put my finger on how exactly but it that's been true in psychology with whenever an important new method came in it changes the feel so and an M torque is really a method because exact it makes it very much easier to do something to do some things is there are undergrad students will ask me you know how big a neural network should be for a particular problem so let me ask you an equivalent equivalent question how big how many subjects they study have for it to have a conclusive result well depends on the strength of the effect so if you're studying visual perception the perception of color many other are the classic results in in visual in color perception we've done on three or four people and I think and one of them was called a blind but or they'd partly colorblind but on vision you know you belong many people don't need a lot of replications for some type of neurological experiment neuro when you're studying weaker phenomena and especially when you're studying them between subjects then you need a lot more subjects than people have been running and that is that's one of the things that are happening in psychology now is that the power is a statistical power the experiment is increasing rapidly does that between subjects as the number of subjects goes to infinity approach well I mean you know goes to infinity is exaggerated but people the standard number of subjects for an experiment psychology with 30 or 40 and for a weak effect that's simply not enough and you may need a couple of hundred I mean it's that that sort of order of magnitude what are the major disagreements in theories and effects that you've observed throughout your career that's the stand today well you work on several fields yeah but what still is out there as major disagreement offs in your mind and I've had one extreme experience of you know controversy with somebody who really doesn't like the work that they must risky and I did and he's been after us for 30 years or more at least when I talk about it well I mean his name is good Giga answer he's a well-known German psychologist and that's the one controversy I have which I it's been unpleasant and no I don't particularly want to talk about it but it's there is their open questions even in your own mind every once in a while you know we talked about semi autonomous vehicles in my own mind I see what the data says but I also constantly torn do you have things where you or your studies have found something but you're also intellectually torn about what it means and there's been maybe disagreement you within your own mind about particularly I mean it's you know one of the things that are interesting is how difficult it is for people to change their mind essentially you know once they're committed people just don't change their mind about anything that matters and that is surprisingly but it's true about scientists so the controversy that I described in other it's been going on like thirty years and it's never going to be resolved and you build a system and you live within that system and other other systems of ideas look foreign to you and there is very little contact and very little mutual influence that happens a fair amount do you ever hopeful advice or message on that we think about science thinking about politics thinking about things that have impact on this world how can we change your mind I think that I mean on things that matter or a political or a little religious and people just don't don't change their mind and by and large and there is very little that you can do about it the what does happen is that if leaders change their mind so for example the public the American public doesn't really believe in climate change doesn't take it very seriously but if some religious leaders decided this is a major threat to humanity that would have a big effect so that we we have the opinions that we have not because we know why we have them but because we trust some people and we don't trust other people and so it's much less about evidence than it is about stories so the way one way to change your mind isn't at the individual level is that the leaders of the communities you look up with the stories change and therefore your mind changes with them so there's a guy named Alan Turing came up with a touring test yeah what what do you think is a good test of intelligence perhaps we're drifting in a topic that were maybe philosophizing about but what do you think is a good test for intelligence for an artificial intelligence system well the standard definition of you know official general intelligence is that it can do anything that people can do and it can do them better yes what what we are seeing is that in many domains you have domain-specific and you know devices or programs or software and they beat people easily in specified way but we are very far from is either generally ability a general-purpose intelligence so we in in machine learning people are approaching something more general I mean for alpha 0 ISM was much more general than than alphago and but it's still extraordinarily narrow and specific in what it can do so we're quite far from from something that can in every domain think like a human except better what aspects of the Turing test has been criticized its natural language conversation you know that it's too simplistic guys it's easy to quote unquote pass under under constraints specified it what aspect of conversation would impress you if you heard it is it humor is it what what would impress the heck out of you if if you saw it in conversation yeah I mean suddenly wit would yeah which would be impressive and and humor would be more impressive than just factual conversation which i think is is easy and illusions would be interesting and metaphors would be interesting I mean but new metaphors not practice metaphors so there's a lot that you know would be sort of impressive and that it's completely natural in conversation but that you really wouldn't expect there's the possibility of creating and a human level intelligence or super human level intelligence system excite you scare you well I mean how does it make you feel I find the whole thing fascinating absolutely fascinating exciting I think and exciting it's also terrifying you know but but I'm not going to be around to see it and so I'm curious about what is happening now but I also know that that predictions about it are silly we really have no idea but it will look like 30 years from now no idea speaking of silly bordering and the profound they may ask the question of in your view what is the meaning of it all the meaning of life he's a descendant of great apes that we are why what drives us as a civilization as a human being as a force behind everything that you've observed and studied is there any answer or is it all just a beautiful mess there is no answer that that I can understand and I'm not and I'm not actively looking for one do you think an answer exists no there is no answer that we can understand I'm not qualified to speak about what we cannot understand but there is I know that we cannot understand reality you know and I mean there's other thing that we can do I mean you know gravity waves and that's a big moment for Humanity and when you imagine that eeep you know being able to to go back to the Big Bang that's that but but the y-yeah the warrior than us the why is hopeless really day thank you so much it was an honor thank you for speaking thank you thanks for listening to this conversation and thank you to our presenting sponsor cash app downloaded use code Lex podcast you'll get ten dollars and ten dollars will go to first a stem education nonprofit that inspires hundreds of thousands of young minds to become future leaders and innovators if you enjoy this podcast subscribe on YouTube get five stars an apple podcast follow on Spotify supported on patreon or simply connect with me on Twitter and now let me leave you with some words of wisdom from Danielle Cartman intelligence is not only the ability to reason it is also the ability to find relevant material and memory and to deploy attention when needed thank you for listening and hope to see you next time you