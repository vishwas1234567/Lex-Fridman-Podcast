Speaker 1 :the following is a conversation with
 Leslie Kayla bling she's a roboticist and professor at MITshe's recognized for her work and
 reinforcement learning planning robot navigation and several other topics inAI she won the edge KY computers and
 thought award and was the editor-in-chief of the prestigiousjournal machine learning research this
 conversation is part of the artificial intelligence podcast at MIT and beyondif you enjoy it subscribe on youtube
 itunes or simply connect with me on twitter at Lex Friedman spelled Fri Dand now here's my conversation with


Speaker 0 :Leslie Kael Blaine what made me get
 excited about AI I can say that as I read girdle Ashur back when I was inhigh school that was pretty formative
 for me because it exposed the interestingness of primitives andcombination and how you can make complex
 things out of simple parts and ideas of AI and what kinds of programs mightgenerate intelligent behavior so so you


Speaker 1 :first fell in love with AI reasoning
 logic versus robots

Speaker 0 :yeah the robots came because my first
 job so I finished an undergraduate degree in philosophy at Stanford and wasabout to finish master's in computer
 science and I got hired at SR I in their AI lab and they were building a robot itwas a kind of a follow-on to shaky but
 all the shaky people were not there anymoreand so my job was to try to get this
 robot to do stuff and that's really kind of what got me interested in robots so

Speaker 1 :maybe taking a small step back your
 bachelor's in Stanford and philosophy did masters and PhD in computer sciencebut the bachelors in philosophy so what
 was that journey like what elements of philosophy do you think you bring to

Speaker 0 :your work in computer science so the
 part of the reason that I didn't do a computer science undergraduate degreewas that there wasn't one at Stanford at
 the time but that there's part of philosophy and in fact Stanford has aspecial sub major in something called
 now symbolic systems which is logic model theory formal semantics of naturallanguage and so that's actually a
 perfect preparation for work in AI and computer science that that's kind of

Speaker 1 :interesting so if you were interested in
 artificial intelligence what what kind of majors were people even thinkingabout taking what is it in your science
 was so besides philosophies what were you supposed to do if you werefascinated by the idea of creating


Speaker 0 :intelligence there weren't enough people
 who did that for that even to be at conversation okay I mean I thinkprobably probably philosophy I mean it's
 interesting in my class my graduating class of undergraduate philosophersprobably maybe slightly less
 than half went on in computer science slightly less than half went on in lawand like one or two went on in
 philosophy so it was a common kind of

Speaker 1 :connection do you think AI researchers
 have a role be part time philosophers or should they stick to the solid scienceand engineering without sort of taking
 the philosophizing tangents I mean you work with robots you think about what ittakes to create intelligent beings
 aren't you the perfect person to think about the big picture philosophy of it

Speaker 0 :all the parts of philosophy that are
 closest to AI I think or at least the closest to AI that I think about arestuff like belief and knowledge and
 denotation and that kind of stuff and that's you know it's quite formal andit's like just one step away from the
 kinds of computer science work that we do kind of routinely I think that thereare important questions still about what
 you can do with a machine and what you can't and so on although at least mypersonal view is that I'm completely a
 materialist and I don't think that there's any reason why we can't make arobot be behaviorally indistinguishable
 from a human and the question of whether it's in the distinguishable internallywhether it's a zombie or not in
 philosophy terms I actually don't I don't know and Idon't know if I care too much about that


Speaker 1 :right there there's a philosophical
 notions they're mathematical and philosophical because we don't know somuch of how difficult it is how
 difficult is a perception problem how difficult is the planning problem howdifficult is it to operate in this world
 successfully because our robots are not currently as successful human beings andmany tasks the the question about the
 gap between current robots and human beings borders a little bit onphilosophy you know the expanse of
 knowledge that's required to operate in this world and the ability to formcommon-sense knowledge the ability to
 reason about uncertainty much of the work you've been doing there's thoseopen questions there that I don't know
 require to activate a certain big-picture view to me that doesn't seem

Speaker 0 :like a philosophical gap
 to me it's a there is a big technical gap yes technical gap but I don't seeany reason why it's more than a


Speaker 1 :technical gap perfect so when you
 mention AI you know sorry and maybe can you describe to me whenyou first fell in love with robotics
 with robots or inspired which so you should mention flaky or shaky shakyflaky and what was the robot that first
 captured your imagination what's

Speaker 0 :possible right well this so the first
 robot I worked was like shakey was a robot that the SR I people had built butby the time I think when I arrived it
 was sitting in a corner of somebody's office dripping hydraulic fluid into apan but its iconic and really everybody
 should read the shaky tech report because it has so many good ideas in itI mean they invented a star search and
 symbolic planning and learning macro operators they had the level kind ofconfiguration space planning for the
 robot they had vision they had all this the basic ideas of a ton of things okay

Speaker 1 :take a step by the shaky have arms that


Speaker 0 :was a job could push objects and so it
 would move things around with which

Speaker 1 :

Speaker 0 :actuator itself with its base okay so it
 could but it and they had painted the baseboards black so it used it usedvision to localize itself in a map it
 detected objects it could detect objects that were surprising to it it would planand re plan based on what it saw it
 reasoned about whether to look and take pictures I mean it really had the basicsof of so many of the things that we


Speaker 1 :think about now how do you represent the
 space around it so it had

Speaker 0 :representations that are bunch of
 different levels of abstraction so it had I think a kind of an occupancy gridof some sort at the lowest level at the
 high level it was abstract symbolic kind of rooms and connectivity it's a word as

Speaker 1 :flaky coming yeah okay so


Speaker 0 :at us RI and we were building a
 brand-new robot as I said none of the people from the previous project werekind of there or involved anymore so we
 were kind of starting from scratch and my advisor was Stan resin shine he endedup being my thesis advisor and he was
 motivated by this idea of situated computation or situated automata and theidea was that the tools of logical
 reasoning were important but possibly only for the engineers or designers touse in the analysis of a system but not
 necessarily to be manipulated in the head of the system itself right so Imight use logic to prove a theorem about
 the behavior of my robot even if the robots not using logic and it's headedto prove theorems right so that was kind
 of the distinction and so the idea was to kind of use those principles to makea robot do stuff but a lot of the basic
 things we had to kind of learn for ourselves because I had zero backgroundin robotics I didn't know anything about
 control I don't know anything about sensors so we reinvented a lot of wheelson the way to getting that robot to do


Speaker 1 :stuff do you think that was an advantage
 or hindrance

Speaker 0 :oh no it's I mean I I'm big in favor of
 wheel reinvention actually I mean I think you learn a lot by doing it it'simportant though to eventually have the
 pointers to so that you can see what's really going on but I think you canappreciate much better the good
 solutions once you've messed around a little biton your own and found a bad one yeah I


Speaker 1 :think you mentioned reinventing
 reinforcement learning yeah and referring to rewards as pleasures by apleasure yeah I think yeah I think it's


Speaker 0 :a nice name for it it's more it's more


Speaker 1 :fun almost do you think you could tell
 the history of AI and machine learning reinforcement learning and how you thinkabout it from the 50s to now one thing


Speaker 0 :is that its oscillates right so things
 become fashionable and then they go out and then something else becomes cool andthat it goes out and so on and I think
 there's so there's some interesting sociological process that actuallydrives
 a lot of what's going on early days was kind of cybernetics and control rightand the idea that of homeostasis people
 have made these robots that could I don't know try to plug into the wallwhen they needed power and then come
 loose and roll around and do stuff and then I think over time the thought wellthat was inspiring but people said no no
 we want to get maybe closer to what feels like real intelligence or humanintelligence and then maybe the expert
 systems people tried to do that but maybe a little too superficially rightso oh we get the surface understanding
 of what intelligence is like because I understand how a steel mill works and Ican try to explain it to you and you can
 write it down in logic and then we can make a computer infer that and then thatdidn't work out but what's interesting I
 think is when a thing starts to not be working very well it's not only do wechange methods we change problems right
 so it's not like we have better ways of doing the problem of the experts thosepeople are trying to do we have no ways
 of trying to do that problem oh yeah I know I think maybe a few but we kind ofgive up on that problem and we switch to
 a different problem and we we work that for a while and we I guess there's a

Speaker 1 :broad community as a community and
 there's a lot of people who would argue you don't give up on the problem it'sjust you decrease the number of people
 working on it you almost kind of like put it on the shelfso we'll come back to this 20 years


Speaker 0 :later yeah I think that's right or you
 might decide that it's malformed like you might say it's wrong to just try tomake something that does superficial
 symbolic reasoning behave like a doctor you can't do that until you've had thesensorimotor experience of being a
 doctor or something right so there's arguments that say that that's problemwas not well formed or it could be that
 it is well for it but but we just weren't approaching it well you mention

Speaker 1 :that your favorite part of logic and
 symbolic systems is that they give short names for large setsso there is some use to this they use
 just as a symbolic reasoning though the looking at expert systems and symboliccomputing what do you think are the
 roadblocks that were hit in the eighties

Speaker 0 :and nineties ah okay so right so the
 fact that I'm not a fan of expert systems doesn't mean that I'm not a fanof some kinds of symbolic reasoning
 right so let's see road blocks but the main road block I think was that theidea that humans could articulate their
 knowledge effectively into into you know some kind of logical statements so it's

Speaker 1 :not just the cost the effort but really
 just the capability of doing it right

Speaker 0 :because we're all experts in vision
 right but not totally don't have introspective access into how we do thatright and it's true that I mean I think
 the idea was well of course even people then would know of course I wouldn't askyou to please write down the rules that
 you use for recognizing water bottle that's crazy and everyone understoodthat but we might ask you to please
 write down the rules you use for deciding I don't know what tie to put onor how to set up a microphone or
 something like that but even those things I think people maybe I think whatthey found I'm not sure about this but I
 think what they found was that that so-called experts could giveexplanations that sort of post hoc
 explanations for how and why they did things but they weren't necessarily verygood and then they different they
 depended on maybe some kinds of perceptual things which again theycouldn't really define very well so I
 think I think fundamentally I think that the underlying problem with that was theassumption that people could articulate
 how and why they make their decisions

Speaker 1 :all right so it's almost in call
 encoding the knowledge from converting from expert to something that a machinecould understand and reason with no no


Speaker 0 :not even just encoding but getting it
 out of you just not not writing it I mean yes hard also to write it down forthe computer yeah but I don't think that
 but can produce it you can tell me a story about why you do stuff but I'm notso sure that's the way great so there


Speaker 1 :are still on the hierarchical planning
 side places where symbolic reasoning is very useful so as you've talked about so

Speaker 0 :where so don't where's the gap yeah okay
 good so saying that humans can't provide a description of their reasoningprocesses that's ok fine but that
 doesn't mean that it's not good to do reasoning of various styles inside acomputer those are just two orthogonal
 points so then the question is what kind of reasoning should you do inside acomputer right and the answer is I think
 you need to do all different kinds of reasoning inside a computer depending onwhat kinds of problems you face I guess


Speaker 1 :the question is what kind of things can
 you encode symbolically so you can

Speaker 0 :reason about I think the idea about an
 even symbolic I don't even like that terminology because I don't know what itmeans
 technically informally I do believe in abstractions so abstractions arecritical right you cannot reason a
 completely fine grain about everything in your life right you can't make a planat the level of images and torques for
 getting a PhD right so you have to reduce the size of the state space andyou have to reduce the horizon if you're
 gonna reason about getting a PhD or even buying the ingredients to make dinnerand so so how can you reduce the spaces
 and the horizon of the reasoning you have to do and the answer is abstractionspatial abstraction temporal abstraction
 I think abstraction along the lines of goals is also interesting like you mightor well abstraction and decomposition
 goals this may be more of a decomposition thing so I think that'swhere these kinds of if you want to call
 it symbolic or discrete models come in you you talk about a room of your houseinstead of your pose you talk about
 you know doing something during the afternoon instead of at 2:54 and you dothat because it makes your reasoning
 problem easier and also because you have you don't have enough information toreason in high fidelity about your pose
 of your elbow at 2:35 this afternoon

Speaker 1 :anyway right when you're trying to get a
 PhD okay except for at that moment at

Speaker 0 :that moment you do have to use it about
 the pose of your elbow maybe but then you maybe you do that in some continuousjoint space kind of modeling so I again
 I my biggest point about all of this is that there should be the dogma is notthe thing right we shouldn't it
 shouldn't be that I'm in favor against symbolic reasoning and you're in favoragainst neural networks it should be
 that just just computer science tells us what the right answer to all thesequestions is smart enough to figure it
 out

Speaker 1 :oh yeah when you try to actually solve
 the problem with computers the right answer comes out you mentionedabstractions mm-hmm I mean you all
 networks form abstractions or rather there's there's automated ways to formstrategies and there's expert driven
 ways to form abstractions and export human driven ways and humans just seemsto be way better at forming abstractions
 currently and certain problems so when you're referring to 2:45 and PM versusafternoon how do we construct that
 taxonomy is there any room for automated construction of such abstractions oh I

Speaker 0 :think eventually yeah I mean I think
 when we get to be better and machine learning engineers will build algorithmsthat build awesome abstractions that are


Speaker 1 :useful in this kind of way that you
 describe yeah yeah so let's then step from the the abstraction discussion andlet's talk about BOM mdps partially
 observable Markov decision processes so uncertainty so first water Markov

Speaker 0 :decision processes and maybe how much of


Speaker 1 :our world could be models and mdps how
 much when you wake up in them morning me making breakfast how do youthink of yourself as an MDP so how do
 you think about MVPs and how they relate

Speaker 0 :to our world well so there's a stance
 question right so a stance is a position that I take with respect to a problem soI as a researcher or person who design
 systems can decide to make a model of the world around mein some terms right so I take this messy
 world and I say I'm gonna treat it as if it were a problem of this formal kindand then I can apply solution concepts
 around rhythms or whatever to solve that formal thang right so of course theworld is not anything it's not an MDP or
 a pom DP I don't know what it is but I can model aspects of it in some way orsome other way and when I model some
 aspect of it in a certain way that gives me some set of algorithms I can use you

Speaker 1 :can model the world in all kinds of ways
 some have some are more accepting of uncertainty more easily modelinguncertainty of the world some really
 force the world to be deterministic and so the certainly NDP's model theuncertainty of the world yes model some


Speaker 0 :uncertainty the model not present state
 uncertainty but they model uncertainty in the way the future will unfold right

Speaker 1 :so what are Markov decision process so


Speaker 0 :marketers process is a model it's a kind
 of model that you could make that says I I know completely the current state ofmy system and what it means to be a
 state is that I that all they have all the information right now that will letme make predictions about the future as
 well as I can so that remembering anything about my history wouldn't makemy predictions any better and but it but
 then it also says that that then I can take some actions that might change thestate of the world and that I don't have
 a deterministic model of those changes I have a probabilistic model of how theworld might change it's a it's a useful
 model for some kinds of systems I think it's a I mean it's certainly not a goodmodel for most problems I think because
 for most problems you don't actually knowState for most problems you it's
 partially observed so that's now a different problem class so okay that's

Speaker 1 :where the poverty P is the partially
 observable Markov decision process step n so how do they address the fact thatyou can't observe most your incomplete
 information about most of the world

Speaker 0 :around you right so now the idea is we
 still kind of postulate that there exists a state we think that there issome information about the world out
 there such that if we knew that we could make good predictions but we don't knowthe state and so then we have to think
 about how but we do get observations maybe I get images right here things areI feel things and those might be local
 or noisy and so therefore they don't tell me everything about what's going onand then I have to reason about given
 the history of actions I've taken in observations I've gotten what do I thinkis going on in the world and then given
 my own kind of uncertainty about what's going on in the world I can decide what

Speaker 1 :actions to take and so difficult is this
 problem of planning under uncertainty in your view and you know long experienceof modeling the world trying to deal
 with this uncertainty in special and

Speaker 0 :real of all systems optimal planning for
 even discrete hamdi peas can be undecidable depending on how you set itup and free so lots of people say I
 don't use pom D peas because they are intractable and I think that that's arekind of a very funny thing to say
 because the problem you have to solve is the problem you have to solve so if theproblem you have to solve is intractable
 that's what makes us AI people right so we saw we understand that the problemwe're solving is is compute wildly
 intractable that we can't we will never be able to solve it optimally at least Idon't yeah right so later we can come
 back to an idea about bounded optimality and something but anyway I don't wecan't come up with optimal solutions to
 these problems so we have to make approximations approximations inmodeling approximations in the solution
 algorithms and so on and so I don't have a problem with saying yeah my problemactually it is pom DP
 in continuous space with continuous observations and it's so computationallycomplex I can't even think about it's
 you know Big O whatever but that doesn't prevent me from it helps me gives mesome clarity to think about it that way
 and to then take steps to make approximation after approximation to getdown to something that's like computable
 in some reasonable time when you think

Speaker 1 :about optimality you know the community
 broadly is shifted on that I think a little bit in how much they value theidea of optimality of chasing an optimal
 solution positive views of chasing an optimal solution changed over the yearsand when you work with robots that's


Speaker 0 :interesting I think we have a little bit
 of a methodological crisis actually from the theoretical side I mean I do thinkthat theory is important in that right
 now we're not doing much of it so there's lots of empirical hacking aroundand training this and doing that and
 reporting numbers but is it good is it bad we don't know we very hard to saythings
 and if you look at like computer science theoryso people talked for a while everyone
 was about solving problems optimally or completely and and then there wereinteresting relaxation so people look at
 oh can I are their regret bounds or can I do some kind of you know approximationcan I prove something that I can
 approximately solve this problem or that I get closer to the solution as I spendmore time and so on what's interesting I
 think is that we don't have good approximate solution concepts for verydifficult problems right I like to you
 know I like to say that I I'm interested in doing a very bad job of very big

Speaker 1 :

Speaker 0 :problems but I would I wish I could say
 something I wish I had a I don't know some kind of a formal solution conceptthat I could use to say oh this this
 algorithm actually it gives me something like I know what I'm gonna get I can dosomething other than just run it and get


Speaker 1 :out so that having that notion is still
 somewhere deeply compelling to you the notion that you can say you can dropthing on the table says this you can
 expect this this out gonna give me some good results

Speaker 0 :I hope science will I mean there's
 engineering in there science I think that they're not exactly the same and Ithink right now we're making huge
 engineering like leaps and bounds so that engineering is running away aheadof the science which is cool and often
 how it goes right so we're making things and nobody knows how and why they workroughly but we need to turn that into


Speaker 1 :science there's some form it's yeah
 there's some room for formalizing we

Speaker 0 :need to know what the principles are why
 does this work why does that not work I mean for awhile people built bridges bytrying but now we can often predict
 whether it's going to work or not without building it can we do that forlearning systems or for robots so your


Speaker 1 :hope is
 from a materialistic perspective that intelligence artificial intelligencesystems robots okay I were just more
 fancier bridges believe space what's the difference between belief space andstate space I mentioned MDPs fond
 appease you reasoning about you sense the world there's a statewhat's this belief space idea I believe


Speaker 0 :space that is instead of thinking about
 what's the state of the world and trying to control that as a robot I think aboutwhat is the space of beliefs that I
 could have about the world what's if I think of a belief as a probabilitydistribution over ways the world could
 be a belief state is a distribution and then my control problem if I'm reasoningabout how to move through a world I'm
 uncertain about my control problem is actually the problem of controlling mybeliefs so I think about taking actions
 not just what effect they'll have on the world outside but what effect I'll haveon my own understanding of the world
 outside and so that might compel me to ask a question or look somewhere togather information which may not really
 change the world state but it changes my own belief about the world that's a

Speaker 1 :powerful way to to empower the agent to
 reason about the world to explore the world what kind of problems does itallow you to solve to to consider belief
 space versus just state space well any

Speaker 0 :problem that requires deliberate
 information gathering right so if in some problems like chess there's nouncertainty or maybe there's uncertainty
 about the opponent there's no uncertainty about the state and someproblems there's uncertainty but you
 gather information as you go right you might say oh I'm driving my autonomouscar down the road and it doesn't know
 perfectly where it is but the Llyod ours are all going all the time so I don'thave to think about whether to gather
 information but if you're a human driving down the road you sometimes lookover your shoulder to see what's going
 on behind you in the lane and you have toside whether you should do that now and
 you have to trade off the fact that you're not seeing in front of you andyou're looking behind you and how
 valuable is that information and so on and so to make choices about informationgathering you have to reasonably spaced
 also also I mean also to just take into account your own uncertainty beforetrying to do things so you might say if
 I understand where I'm standing relative to the door jamb pretty accurately thenit's okay for me to go through the door
 but if I'm really not sure where the door is then it might be better to notdo that right now


Speaker 1 :the degree of your uncertainty ball
 about the world is actually part of the thing you're trying to optimize informing the plan right so this idea of a
 long horizon of planning for a PhD or just even how to get out of the house orhow to make breakfast you show this
 presentation of the the WTF was the fork of robot looking at a sink and can youdescribe how we plan in this world of
 this idea of hierarchical planning we've mentioned this is a yeah how can a robothope to plan about something this was
 such a long hallway people since

Speaker 0 :probably reasoning began have thought
 about hierarchical reasoning the temporal hierarchy and particularspatial hierarchy but let's talk about
 temporal hierarchy so you might say oh I have this long execution I have to dobut I can divide it into some segments
 abstractly right so maybe you have to get out of house I have to get in thecar I have to drive so on and so you can
 plan if you can build abstractions so this we started out by talking aboutabstractions and we're back to that now
 if you can build abstractions in your state space and abstractions sort oftemporal abstractions then you can make
 plans at a high level and you can say I'm gonna go to town and then I'll haveto get gas and then I can go here and I
 can do this other thing and you can reason about the dependencies andconstraints among these
 actions again without thinking about the complete details what we do in ourhierarchical planning work is then say
 alright I make a plan at a high level of abstraction I have to have some reasonto think that it's feasible without
 working it out in complete detail and that's actually the interesting step Ialways like to talk about walking
 through an airport like you can plan to go to New York and arrive at the airportand then find yourself in an office
 building later you can't even tell me in advance what your plan is for walkingthrough the airport
 partly because you're too lazy to think about it maybe but partly also becauseyou just don't have the information you
 don't know what gate you're landing in or what people are gonna be in front ofyou or anything so there's no point in
 planning in detail but you have to have you have to make a leap of faith thatyou can figure it out once you get there
 and it's really interesting to me how you arrive at that how do you they sayyou have learned over your lifetime to
 be able to make some kinds of predictions about how hard it is toachieve some kinds of sub goals and
 that's critical like you would never plan to fly somewhere if you couldn'tdidn't have a model of how hard it was
 to do some of the intermediate steps so one of the things we're thinking aboutnow is how do you do this kind of very
 aggressive generalization to situations that you haven't been in and so on topredict how long will it take to walk
 through the Kuala Lumpur Airport like you give me an estimate and it wouldn'tbe crazy and you have to have an
 estimate of that in order to make plans that involve walking through the KualaLumpur Airport even if you don't need to
 know it in detail so I'm really interested in these kinds of abstractmodels and how do we acquire them but
 once we have them we can use them to do hierarchical reasoning which is I thinkit's very important yeah there's this


Speaker 1 :notion of gold' regression and preimage
 back chaining this idea of starting at the goal and it's just for these bigclouds of states you get I mean it's
 almost like saying to the airport you know you you know once you show upto the airport that that's you you're
 like a few steps away from the goal so like thinking of it this way it's kindof interesting I don't know if you have
 sort of further comments on them of starting at the goal why that yeah I

Speaker 0 :mean it's interesting that Simon herb
 Simon back in the early days of AI did talked a lot about means-ends reasoningand reasoning back from the goal there's
 a kind of an intuition that people have that the number of that state space isbig the number of actions you could take
 is really big so if you say here I sit and I want to search forward from whereI am what are all the things I could do
 that's just overwhelming if you say if you can reason at this other level andsay here's what I'm hoping to achieve
 what can I do to make that true that somehow the branching is smaller nowwhat's interesting is that like in the
 AI planning community that hasn't worked out in the class of problems that theylook at and the methods that they tend
 to use it hasn't turned out that it's better to go backward it's still kind ofmy intuition that it is but I can't
 prove that to you right now all right

Speaker 1 :I'd share your intuition at least for us
 mere humans speaking of which when you maybe never take it and take a look takea little step into that philosophy
 circle how hard would it when you think about human life you should give thoseexamples often how hard do you think it
 is to formulate human life is a planning problem or aspects of human life so whenyou look at robots you're often trying
 to think about object manipulation tasks about moving a thing when you when youtake a slight step outside the room let
 the robot leave and go get lunch or maybe try to pursue more fuzzy goals howhard do you think is that problem if you
 were to try to maybe put another way try to formulate human life as a planningproblem well that would be a mistake I


Speaker 0 :mean it's not all the planning problem
 right every think it's really really important that we understand that youhave to put together pieces and parts
 that have different styles of reasoning representation and learning I think Ithink it's it's seems probably clear to
 anybody that that you you can't all be this or all be that brains aren't alllike this are all like that right they
 have different pieces and parts and substructure and so on so I don't thinkthat there's any good reason to think
 that there's going to be like one true algorithmic thing that's gonna do thewhole job just a bunch of pieces


Speaker 1 :together designed to solve a bunch of
 specific problem one the specific styles

Speaker 0 :of problems I mean there's probably some
 reasoning that needs to go on in image space I think again there's this modelbased vs. model free idea it's I only
 enforce spent learning people talk about it oh should I learn I could learn apolicy just straight up a way of
 behaving I could learn it's popularly a value function that's some kind of weirdintermediate ground or I could learn a
 transition model or it tells me something about the dynamics of theworld if I take a trip if imagine that I
 learned in a transition model and I couple it with a planner and I draw abox around that I have a policy again
 it's just stored a different way right right it's in but it's just as much of apolicy as the other policy it's just
 I've made I think the way I see it is it's a time-space trade-off incomputation right a more overt policy
 representation maybe it takes more space but maybe I can compute quickly whataction I should take on the other hand
 maybe a very compact model of the world dynamics plus a plannerlet's make compute what action to take
 to just more slowly there's no I mean I don't think there'sno argument to be had it's just like a
 question of what form of computation is

Speaker 1 :best for us for the various subproblems


Speaker 0 :right so and and so like learning to do
 algebra manipulations for some reason is good I mean that's probably gonna wantnaturally is sort of a different
 representation than riding a unicycle at the time constraints on the unicycle orserious this thing space is maybe
 smaller I don't know but so I could be

Speaker 1 :the more human-sized of falling in love
 having a relationship that might be another yeah another style of no idea

Speaker 0 :

Speaker 1 :how to model that yeah that's let's
 first solve the algebra an object may patient what do you think is harderperception or planning perception that's


Speaker 0 :

Speaker 1 :understanding that's so what do you


Speaker 0 :

Speaker 1 :think is so hard about perception by
 understanding the world around you well

Speaker 0 :I think the big question is
 representational a hugely the question is representation so perception has madegreat strides lately right and we can
 classify images and we can play certain kinds of games of predict I to steer inthe car and all this sort of stuff I
 don't think we have a very good idea of what perception should deliver right soif you if you believe in modularity ok
 there's there's a very strong view which says we shouldn't build in anymodularity we should make a giant
 gigantic neural network trained it end-to-end to do the thing and that'sthe best way forward and it's hard to
 argue with that except on a sample complexity basis right so you might sayoh well if I want to do end-to-end Rio
 first of all anything on this giant giant neural network it's going to takea lot of data and a lot of like broken
 robot system so then the only answer is to say ok we have to build something inbuild in some structure or some bias we
 know from theory of machine learning the only way to cut down the samplecomplexity is to kind of cut down
 somehow cut down the hypothesis space you can do that by building in biasthere's all kinds of reason to think
 that nature built bias into humans [Music]convolution is a bias right it's a very
 strong bias and it's a very critical bias so my own view is that we shouldlook for more things that are like
 convolution but that other aspects of reasoning right soconvolution helps us a lot with a
 certain kind of spatial reasoning that's quite close to the imaging I thinkthere's other ideas like that maybe some
 amount of forward search maybe some notions of abstraction maybe the notionthat objects exist actually I think
 that's pretty important and a lot of people won't give you that to start withright so almost like a convolution in


Speaker 1 :the in the object semantic object space
 of some kind sometimes some kind of ideas in there that's right people who

Speaker 0 :started like the graph graph
 convolutions are an idea that are related to racial relationalrepresentations and so so I think there
 are so you I've come far afield from perception but I think I think the thingthat's going to make perception that
 kind of the next step is actually understanding better what it shouldproduce right so what are we going to do
 with the output of it right it's fine when what we're gonna do with the outputis Sudhir it's less clear when we're
 just trying to make a one integrated intelligent agent what should the outputof perception be we have no idea and how
 should that hook up to the other stuff we don't know so I think the pressingquestion is what kinds of structure can
 we build in that are like the moral equivalent of convolution that will makea really awesome super structure that
 then learning can kind of progress on efficiently I agree very compelling

Speaker 1 :description of actually where we stand
 with the perceptual mom you're teaching a course on embodying intelligence whatdo you think it takes to build a robot
 with human level intelligence I don't

Speaker 0 :know if we knew we would do it if you


Speaker 1 :were to I mean okay so do you think a
 robot needs to have a self-awareness consciousness fear of mortality or is itis it simpler than that or is
 consciousness a simple thing like do you think about these notions I don't think

Speaker 0 :much about consciousness even most
 philosophers who care about it will give you that you could havethat are zombies right that behave like
 humans but are not conscious and I at this moment we'd be happy enough forthat so I'm not really worried one way
 or the other to the technical side

Speaker 1 :you're not thinking of the use of
 self-awareness no but okay but then what

Speaker 0 :is self-awareness mean I mean that you
 need to have some part of the system that can observe other parts of thesystem and tell whether they're working
 well or not that seems critical so does that count this I mean does that kind ofself-awareness or not well it depends on
 whether you think that there's somebody at home who can articulate whetherthey're self-aware but clearly if I have
 like you know some piece of code that's counting how many times this proceduregets executed that's a kind of
 self-awareness right so there's a big spectrum it's clear you have to havesome of it right
 you know quite far away at many

Speaker 1 :dimensions but there's a direction of
 research that's most compelling to you for you know try to achieve human-levelintelligence in our robots well to me I


Speaker 0 :guess the thing that seems most
 compelling to me at the moment is this question of what to build in and what tolearn I think we're we don't we're
 missing a bunch of ideas and and we you know people you know don't you dare askme how many years it's gonna be until
 that happens because I won't even participate in the conversation becauseI think we're missing ideas and I don't
 know how long it's gonna take to find them so I won't ask you how many years

Speaker 1 :but maybe I'll ask you what it when
 you'll be sufficiently impressed that we've achieved it so what's what's agood test of intelligence do you like
 the Turing test the natural language in the robotic space is there somethingwait you would sit back and think us
 that's pretty impressive as a test as a benchmark do you think about these kindsof problems no I resist I mean I think


Speaker 0 :all the time that we spend arguing about
 those kinds of things could be better spent just making the robots work betterso you


Speaker 1 :competition so I mean there's a nature
 of benchmark benchmarks and data sets or touring test challenges or everybodykind of gets together and tries to build
 a better robot because they want to compete each other like the DARPAchallenge with the autonomous vehicles
 do you see the value of that I can get

Speaker 0 :

Speaker 1 :in the way I think in the way I mean


Speaker 0 :some people many people find it
 motivating and so that's good I find it anti motivating but I think Imean I think you get an interesting
 cycle where for a contest a bunch of smart people get super motivated andthey hack the brains out and much of
 what gets done is just hacks but sometimes really cool ideas emerge andthen that gives us something to chew on
 after that so I'm it's not a thing for me but I don't I don't regret that otherpeople do it yeah it's like he says with


Speaker 1 :everything else that makes is good so
 jumping topics a little bit he started the journal of machinelearning research and served as its
 editor-in-chief how did the publication come about and what do you think aboutthe current publishing model space and
 machine learning artificial intelligence

Speaker 0 :ok good so it came about because there
 was a journal called machine learning which still exists which was owned byKluwer and there was I was on the
 editorial board and we used to have these meetings and really where we wouldcomplain to Kluwer that it was too
 expensive for the libraries and that people couldn't publish and we wouldreally like to have some kind of relief
 on those friends and they would always sympathize but not do anything so wejust decided to make a new journal and
 there was the Journal of AI research which has was on the same model whichhad been and exists us for maybe five
 years or so and it was going on pretty well so uh we just made a new journal itwasn't I mean they don't know I guess it
 was work but it wasn't that hard so basically the editorial board probably75% of the editorial board of machine
 learning resigned and we founded the Neuse new journal

Speaker 1 :but it was sort of it was more open yeah


Speaker 0 :right so it's completely open its open
 access actually I I had a postdoc George Kennedy artists who wanted to call thesejournals free for all because there were
 I mean it both has no page charges and has no access restrictions and thereason and so lots of people I mean
 there were there were people who are mad about the existence of this journal whothought it was a fraud or something it
 would be impossible they said to run a journal like this with basically I meanfor a long time I didn't even have a
 bank account I paid for the lawyer to incorporate and the IP address and itcost a couple hundred dollars a year to
 run it's a little bit more now but not that much more but that's because Ithink computer scientists are competent
 and autonomous in a way that many scientists and other fields aren't Imean at doing these kinds of things we
 already typeset around papers we all have students and people who can hack awebsite together in an afternoon so the
 infrastructure for us was like not a problem but for other people in otherfields it's a harder thing to do yeah


Speaker 1 :and this kind of open access journal and
 there's nevertheless one of the most prestigious journals so it's not like aprestige and it can be achieved without
 any other paper it's not required yeah

Speaker 0 :for prestige it turns out yeah so on the


Speaker 1 :review process side of actually a long
 time ago I don't remember when I reviewed a paper where you were also areviewer and I remember reading your if
 you were being influenced by it and it was really well-writtenit influenced how I write future reviews
 you disagreed with me actually and you made it my review but much better so Ibut nevertheless the review process you
 know has its flaws and how do you think what do you think works well how can itbe improved so actually when I started


Speaker 0 :Djamel our I wanted to do something
 completely different and I didn't because it felt like weneeded a traditional Journal of record
 and so we just made jam art be almost like a normal Journal except for theopen-access parts of it basically
 increasingly of course publication is not even a sensible word you can publishsomething about putting it in archives
 that I can publish everything tomorrow so making stuff public is there's nobarrier we still need curation and
 evaluation I don't have time to read all of our kyv and you could argue that kindof social thumbs up being of articles
 suffice is right you might say oh heck with this we don't need journals at allwe'll put everything on archive and
 people will upload and down about the articles and then your CV will say ohman they he got a lot of buzz so that's
 good but I think there's still value in careful reading and commentary of thingsand it's hard to tell when people are
 voting and down voting or arguing about your paper on Twitter and reddit whetherthey know what they're talking about
 right so then I have the second order problem of trying to decide whoseopinions I should value and such so I
 don't know I what I if I had infinite time which I don't and I'm not gonna dothis because I really want to make
 robots work but if I felt inclined to do something more in a publicationdirection I would do this other thing
 which I thought about doing the first time which is to get together some setof people whose opinions I value and who
 were pretty articulate and I guess we would be public although we could beprivate I'm not sure and we would review
 papers we wouldn't publish them and you wouldn't submit them we were just finepapers and we would write reviews and we
 would make those reviews public and maybe if you you know so we're Leslie'sfriends who review papers and maybe
 eventually if if we are opinion was officially valued like theopinion of Jay mor is valued then you'd
 say in your CV that Leslie's friends gave my paper a five-star reading andthat would be just as good as saying I
 got it so you know accepted into this journal so I think I think we shouldhave good public commentary and organize
 it in some way but I don't really know how to do it it's interesting at timesthe way the way you describe text is


Speaker 1 :really interesting and you would do it
 for movies IMDB done know there's experts critics come in they writereviews but there's also regular yeah
 non critics humans write reviews and they're separated I like open review the

Speaker 0 :the eye I cleared
 process I think is interesting it's a step in the right direction but it's

Speaker 1 :still not as compelling as reviewing
 movies or video games I mean it sometimes almost it might be silly it'smy perspective to say but it boils down
 to the user interface how fun and easy it is to actually perform the reviewshow efficient how much you as a reviewer
 get street cred for being a good reviewer those element those humanelements come into play now it's a big


Speaker 0 :investment to do a good review of a
 paper and the flood of papers is that control right so you know there aren't3,000 new I don't know how many new
 movies are there any year I don't know but that's probably gonna be less thanhow many machine learning papers are in
 a year now and I'm worried I you know I I and right so I'm like an old person soof course I'm gonna say rawrrr things
 are moving too fast I'm a stick in the mud so I can say that but my particularflavor of that is I think the horizon
 for researchers has gotten very short that students want to publish a lot ofpapers and there's a huge there's value
 it's exciting and there's value in that and you get patted on the head for itand so on but and some of that is fine
 but I'm worried that we're driving out people who would spend two yearsthinking about something back in my day
 when we worked on our theses we did not publish papers you did your thesis foryears
 you picked a hard problem and then you worked and chewed on it and did stuffand wasted time and a long time and when
 it was roughly when it was done you would write papers and so I I don't knowhow to inside and I don't think that
 everybody has to work in that mode but I think there's some problems that arehard enough that it's important to have
 a longer her research horizon and I'm worried though we don't incentivize thatat all at this point in this current


Speaker 1 :structure right so what do you see as
 what are your hopes and fears about the future of AI and continuing this themeso AI has gone through a few winters ups
 and downs do you see another winter of AI comingare you more hopeful about making robots
 work as he said I think the cycles are

Speaker 0 :inevitable but I think each time we we
 get higher right I mean so you know it's like climbing some kind of landscapewith a noisy optimizer yeah so it's
 clear that the the you know the deep learning stuff has made deep andimportant improvements and so the
 high-water mark is now higher I there's no question but of course I think peopleare over sawing and eventually investors
 I guess and other people look around and say well you're not quite delivering onthis grand claim and that wild
 hypothesis it's so probably it's going to crash them out and then it's okay Imean but I don't I can't imagine that
 there's like some awesome monotonic improvement from here to human level III

Speaker 1 :so in you know I have to ask this
 question I probably anticipate answers the answers but do you have a worryshort term and long term about the
 existential threats of AI and maybe short-term lessexistential but more robots taking away
 jobs actually let me talk a little bit

Speaker 0 :about utility actually I had an
 interesting conversation with some military ethicists who wanted to talk tome about autonomous weapons and there
 they were interesting smart well-educated guys who didn't know toomuch about AI are machine learning and
 the first question they asked me was has your robot ever done something youdidn't expect and I like burst out
 laughing because anybody who's ever done something other robot right knows thatthey don't do it and what I realized was
 that their model of how we program a robot was completely wrong their modelof how we can put program robot was like
 Lego Mindstorms like oh go for it a meter turn left take a picture do thisdo that and so if you have that model of
 programming then it's true it's kind of weird that your robot would do somethingthat you didn't anticipate but the fact
 is and and actually so now this is my new educational mission if I have totalk to non experts I try to teach them
 the idea that we don't operate we operate at least one or maybe manylevels of abstraction about that and we
 say oh here's a hypothesis class maybe it's a space of plans or maybe it's aspace of classifiers or whatever but
 there's some set of answers and an objective function and then we work onsome optimization method that tries to
 optimize a solution a solution in that class and we don't know what solutionthat's going to come out right so I
 think it's important to communicate that so I read of course probably people wholisten to this they they know that
 lesson but I think it's really critical to communicate that lesson and then lotsof people are now talking about you know
 the value alignment problem so you want to be sure as robots or software systemsget more competent that their objectives
 are aligned with your objectives or that our objectives are compatible in someway or we have a good way of mediating
 when they have different objectives and so I think it is important to startthinking in terms like
 you don't have to be freaked out by the robot apocalypse - except that it'simportant to think about objective
 functions of value alignment yes and that you have to really everyone who'sdone optimization knows that you have to
 be careful what you wish for that ah you know sometimes you get the optimalsolution and you realize man that was
 that objective was wrong so pragmatically in the shortest term itseems to me that that those are really
 interesting and critical questions and the idea that we're gonna go from beingpeople who engineer algorithms to being
 people who engineer objective functions I think that's that's definitely goingto happen and that's gonna change our
 thinking and methodology and we're gonna you started at Stanford philosophy

Speaker 1 :that's where she comes I will go back to


Speaker 0 :because as we also know as machine
 learning people right when you're design in fact this is the lecture I gave inclass today when you design an objective
 function you have to worry about with hatsthere's the Hat that says what do I want
 and there's the hat that says but I know what my optimizer can do to some degreeand I have to take that into account
 okay so it's it's always a trade-off and we have to kind of be mindful of thatthe part about taking people's jobs I
 understand that that's important I don't understand sociology or economics orpeople very well so I don't know how to
 think about that so that's yeah so there

Speaker 1 :might be a sociological aspect there the
 economical aspect that's very difficult to say well okay I mean I think otherpeople should be thinking about it but


Speaker 0 :I'm just that's not my strength so what


Speaker 1 :do you think is the most exciting area
 of research in the short term for the community and for your for yourself well

Speaker 0 :so I mean there's the story I've been
 telling about how to engineer intelligent robots so that's what wewant to do we all kind of want to do
 well I mean some set of us want to do this and the question is what's the mosteffective strategy and we've tried and
 there's a bunch of different things you could do at the extremes right one superextreme is we do introspection then we
 write a program okay that has not worked out very wellanother extreme is we take a giant bunch
 of neural and we trying to train it up to dosomething I don't think that's gonna
 work either so the question is what's the middle ground and and again thisisn't a theological question or anything
 like that it's just like going how do just how do we what's the best way tomake this work out and I think it's
 clear it's a combination of learning to me it's clear it's a combination oflearning and not learning and what
 should that combination be and what's the stuff we built in so to me that'sthe most compelling question and when


Speaker 1 :you say engineer robots you mean
 engineering systems that work in the real world is that that's the emphasislast question which robots
 or robot is your favorite from science fiction so you can go with Star WarsArthur r2d2 or you can go with more
 modern maybe Hal this is this is back to

Speaker 0 :

Speaker 1 :you like to make robots work in the real
 world here not Madden I mean I love the

Speaker 0 :process and I care more about the
 process engineering process yeah I mean I do research because it's fun notbecause I care about what we produce
 well that's a that's a beautiful note

Speaker 1 :actually to end on Leslie thank you so
 much for talking today sure it's been

