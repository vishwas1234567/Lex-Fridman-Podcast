{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub\n",
    "import numpy as np\n",
    "import youtube_dl\n",
    "import pickle as pkl\n",
    "from pydub import AudioSegment\n",
    "from pathlib import Path\n",
    "import time\n",
    "import os\n",
    "from spectralcluster import SpectralClusterer\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, 'C:\\\\Users\\\\ybenc\\\\Documents\\\\Lex_Fridman_Podcasts\\\\Resemblyzer-master')  ## The resemblyzer \n",
    "## module is publicly available at https://github.com/resemble-ai/Resemblyzer\n",
    "# I am not importing it as I do with other modules because I have cloned the repo and modified it to match the needs of this \n",
    "# project. Mainly, I have modified the maximum silence duration allowed to avoid removing silences and modifying podcast time. \n",
    "# For more info about how I used this module and proceeded with the diarization, check out this excellent tutorial:\n",
    "# https://medium.com/saarthi-ai/who-spoke-when-build-your-own-speaker-diarization-module-from-scratch-e7d725ee279\n",
    "\n",
    "from resemblyzer import *\n",
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function turns the length of the youtube video, declared in special\n",
    "## format into a time in seconds\n",
    "def Convert_Time_To_Seconds(Time):\n",
    "    Decomposed_Time = np.int_(re.findall(r'\\d+', Time)) \n",
    "    if len(Decomposed_Time) == 2: ##Podcast shorter than 1 hour\n",
    "        Minutes = Decomposed_Time[0]\n",
    "        Seconds = Decomposed_Time[1]\n",
    "        Total_Time = Minutes*60+Seconds\n",
    "    elif len(Decomposed_Time) == 3: ##Podcast longer than 1 hour\n",
    "        Hours = Decomposed_Time[0]\n",
    "        Minutes = Decomposed_Time[1]\n",
    "        Seconds = Decomposed_Time[2]\n",
    "        Total_Time = Hours*3600 + Minutes*60 + Seconds\n",
    "    else:\n",
    "        print('Something fishy happened with this:', Time)\n",
    "    return Total_Time\n",
    "\n",
    "def Convert_Seconds_To_Human_Time(Time):\n",
    "\n",
    "    Int_Time = np.int_(Time) # get rid of any miliseconds and such \n",
    "    \n",
    "    if Time > 3600: \n",
    "        Hour = np.int_(Int_Time/60/60)\n",
    "        Minute = Int_Time%60\n",
    "        Second = Int_Time%3600\n",
    "        return str(str(Hour) + ':', str(Second) + ':', str(Second))\n",
    "    elif Time < 3600:\n",
    "        Minute = np.round((Int_Time/60, 0))\n",
    "        Second = np.round((Int_Time/60 - Minute)*60, 0)\n",
    "        return str(str(Minute) + ':' + str(Second))\n",
    "\n",
    "def find_nearest_index (Array, value):\n",
    "    #\"Element in nd 'Array' closest to the scalar 'value'\"\n",
    "    idx = np.abs(np.array(Array) - value).argmin()\n",
    "    return Array.index(np.array(Array).flat[idx])\n",
    "\n",
    "def Get_Youtube_Download_Parameters(filename):\n",
    "    filepath = str('Podcasts_Audio_Files/' + filename + '.wav')\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'quiet': True,\n",
    "        'outtmpl': filepath,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "    return ydl_opts, filepath\n",
    "\n",
    "def Audio_File_Processing(filename):\n",
    "    ## I have modified the source code of the resemblyzer module to avoid having deleted silences, which is what is \n",
    "    ## normally done in audio processing etc.. to save up space. Here, we keep even long moments of silences to avoid \n",
    "    ## losing track of the right time and not being able to correctly assign text to diarized speech\n",
    "    audio_file_path = 'Podcasts_Audio_Files\\\\' + filename + '.wav'\n",
    "    wav = preprocess_wav(audio_file_path)\n",
    "    encoder = VoiceEncoder(\"cpu\", verbose = False)\n",
    "    _, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True)\n",
    "    del wav, _, wav_splits #Deleting unused variable to save memory\n",
    "    \n",
    "    return cont_embeds\n",
    "\n",
    "def Spectral_Clustering(embedding):\n",
    "    clusterer = SpectralClusterer(\n",
    "        min_clusters=2,\n",
    "        max_clusters=3,\n",
    "        p_percentile=0.95,\n",
    "        gaussian_blur_sigma=1) #Sometimes, Lex's voice will be recognized as different between the introduction and the conv\n",
    "            # we hence put between 2 and 3 clusters\n",
    "    labels = clusterer.predict(embedding)\n",
    "    return labels\n",
    "\n",
    "\n",
    "## This functions turns the predictions from the clustering algorithm to a [[start_time, speaker]] array, with each row\n",
    "## representing a change in speaker\n",
    "def From_Clustering_To_Time_And_Speaker_Segmenting(predictions, video_duration_in_seconds):\n",
    "    \n",
    "    n_samples = predictions.shape[0]\n",
    "    sampling_rate = n_samples/video_duration_in_seconds #how many sample per second\n",
    "    \n",
    "    time_and_speaker_segment = []\n",
    "    time_and_speaker_segment.append([0, predictions[0]]) # Append beginning of the audio file and first Speaker\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        second =  i/sampling_rate \n",
    "        if i>0 and local_prediction[i] != local_prediction[i-1]: #If change in speaker, write new line. \n",
    "            time_and_speaker_segment.append([second, predictions[i]])\n",
    "            \n",
    "    return time_and_speaker_segment\n",
    "\n",
    "def Get_Podcast_Details(url, duration, title):\n",
    "    local_guest = title.split(':')[0]\n",
    "    local_podcast_number = title.split('#')[1].split(' ')[0]\n",
    "    local_theme = title.split(': ')[1].split(' |')[0]\n",
    "    local_filename = str(local_guest + ' - ' + local_theme + ' - ' + local_podcast_number)\n",
    "\n",
    "    return url, duration, local_guest, local_podcast_number, local_theme, local_filename\n",
    "\n",
    "def Save_As_Pickle(Variable, Folder, File):\n",
    "    with open(str(Folder + File + '.pickle'), 'wb') as f:\n",
    "        pkl.dump(Variable, f)\n",
    "        \n",
    "def Diarize_Transcript(segmented_time_speaker, URL, guest, folder, filename):\n",
    "    \n",
    "    #This function is about fusing the clustering predictions we have with the youtube transcripts. \n",
    "    #Youtube send the transcripts as segments of speechs of usually 3-6 seconds. Issues will often occur with beginning\n",
    "    # and ends of speech segments which will not be attributed to the correct speaker due to the mismatch between youtube\n",
    "    # segment times and clustering times by our diarization algorithm\n",
    "    \n",
    "    youtube_transcript = YouTubeTranscriptApi.get_transcript(URL.split('v=')[1]) #getting transcript\n",
    "    \n",
    "    speech_segment_starts = [] #This is start time of each segment of speech (usually 3-6 seconds segments)\n",
    "    speech_segment_texts = [] #This is the speech segment\n",
    "    \n",
    "    for speech_segment in youtube_transcript:\n",
    "        speech_segment_starts.append(speech_segment['start'])\n",
    "        speech_segment_texts.append(speech_segment['text'])\n",
    "        \n",
    "    # These are text only transcripts   \n",
    "    with open(str('Diarization/Transcripts/' + filename + '.txt'), 'a') as f1:\n",
    "        \n",
    "        for i in range(len(segmented_time_speaker) - 1):\n",
    "            local_speaker = str('Speaker ' + str(segmented_time_speaker[i][1]) + ' ')\n",
    "\n",
    "            intervention_start_time = segmented_time_speaker[i][0]\n",
    "            intervention_end_time = segmented_time_speaker[i+1][0]\n",
    "\n",
    "            transcript_start_index = find_nearest_index(speech_segment_starts, intervention_start_time)\n",
    "            transcript_end_index = find_nearest_index(speech_segment_starts, intervention_end_time)\n",
    "\n",
    "            intervention_text = ''\n",
    "            for k in range(transcript_end_index-transcript_start_index):\n",
    "                if k%3 == 0: ## This is to have new lines every once in a while to avoid having long lines on text files\n",
    "                    intervention_text += str(speech_segment_texts[transcript_start_index+k] + '\\n')\n",
    "                else:\n",
    "                    intervention_text += str(' ' + speech_segment_texts[transcript_start_index+k])\n",
    "                    \n",
    "            f1.write(local_speaker + ':' + intervention_text)\n",
    "            f1.write('\\n\\n')\n",
    "    f1.close()\n",
    "    \n",
    "    # These are text only transcripts   \n",
    "    with open(str('Diarization/Transcripts_With_Time/' + filename + '.txt'), 'a') as f2:\n",
    "        \n",
    "        for i in range(len(segmented_time_speaker) - 1):\n",
    "            local_speaker = str('Speaker ' + str(segmented_time_speaker[i][1]) + ' ')\n",
    "\n",
    "            intervention_start_time = segmented_time_speaker[i][0]\n",
    "            intervention_end_time = segmented_time_speaker[i+1][0]\n",
    "            \n",
    "            transcript_start_index = find_nearest_index(speech_segment_starts, intervention_start_time)\n",
    "            transcript_end_index = find_nearest_index(speech_segment_starts, intervention_end_time)\n",
    "            \n",
    "            human_start_time = str(datetime.timedelta(seconds= int(intervention_start_time)))\n",
    "\n",
    "            intervention_text = ''\n",
    "            for k in range(transcript_end_index-transcript_start_index):\n",
    "                if k%3 == 0: ## This is to have new lines every once in a while to avoid having long lines on text files\n",
    "                    intervention_text += str(speech_segment_texts[transcript_start_index+k] + '\\n')\n",
    "                else:\n",
    "                    intervention_text += str(' ' + speech_segment_texts[transcript_start_index+k])\n",
    "                    \n",
    "            f2.write(human_start_time + '\\n')\n",
    "            f2.write(local_speaker + ':' + intervention_text)\n",
    "            f2.write('\\n\\n')\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load URLs, podcast titles and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 140 podcasts\n"
     ]
    }
   ],
   "source": [
    "with open('URLs_Lex_Fridman.pkl', 'rb') as f:\n",
    "    URLs = pkl.load(f)\n",
    "    \n",
    "with open('Titles_Lex_Fridman.pkl', 'rb') as f:\n",
    "    Titles = pkl.load(f)\n",
    "    \n",
    "with open('Durations_Lex_Fridman.pkl', 'rb') as f:\n",
    "    Verbose_Times = pkl.load(f)\n",
    "    \n",
    "Times_In_Seconds = []\n",
    "for verbose_ti in Verbose_Times:\n",
    "    Times_In_Seconds.append(Convert_Time_To_Seconds(verbose_ti))\n",
    "    \n",
    "print('There are', len(Titles), 'podcasts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each podcast, we download the audio from youtube into a wav file and run the diarization process on it. The diarization process is done in two main phases: 1) audio data preprocessing and 2) spectral clustering to separate between two distinct speakers. \n",
    "We then save the predictions into distinct variables named after the podcast, with speaker information (speaker 0 or speaker 1) and start of each speaker intervention. \n",
    "\n",
    "The diarization is then fused with the youtube transcripts to generate the full conversation - this is done in the next section of this notebook\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Could not generate transcript of podcast: 140 with guest: Lisa Feldman Barrett\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 139 with guest: Andrew Huberman\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 138 with guest: Yaron Brook\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 137 with guest: Alex Filippenko\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 136 with guest: Dan Carlin\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 135 with guest: Charles Isbell\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 134 with guest: Eric Weinstein\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 131 with guest: Chris Lattner\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 124 with guest: Stephen Wolfram\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 103 with guest: Ben Goertzel\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "79 - Diarizing podcast 61 with guest: Melanie Mitchell and theme: Concepts, Analogies, Common Sense &amp; Future of AI\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "93 - Diarizing podcast 47 with guest: Sean Carroll and theme: Quantum Mechanics and the Many-Worlds Interpretation\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 43 with guest: Gary Marcus\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "104 - Diarizing podcast 36 with guest: Yann LeCun and theme: Deep Learning, ConvNets, and Self-Supervised Learning\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "112 - Diarizing podcast 28 with guest: Chris Urmson and theme: Self-Driving Cars at Aurora, Google, CMU, and DARPA\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "113 - Diarizing podcast 27 with guest: Kai-Fu Lee and theme: AI Superpowers - China and Silicon Valley\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "114 - Diarizing podcast 26 with guest: Sean Carroll and theme: The Nature of the Universe, Life, and Intelligence\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "115 - Diarizing podcast 25 with guest: Jeff Hawkins and theme: Thousand Brains Theory of Intelligence\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "116 - Diarizing podcast 24 with guest: Rosalind Picard and theme: Affective Computing, Emotion, Privacy, and Health\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "----Could not generate transcript of podcast: 23 with guest: Gavin Miller\n",
      "----This is likely because there was no available youtube transcript of this podcast\n",
      "\n",
      "\n",
      "118 - Diarizing podcast 22 with guest: Rajat Monga and theme: TensorFlow\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "119 - Diarizing podcast 21 with guest: Chris Lattner and theme: Compilers, LLVM, Swift, TPU, and ML Accelerators\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "120 - Diarizing podcast 20 with guest: Oriol Vinyals and theme: DeepMind AlphaStar, StarCraft, and Language\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "121 - Diarizing podcast 19 with guest: Ian Goodfellow and theme: Generative Adversarial Networks (GANs)\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "122 - Diarizing podcast 18 with guest: Elon Musk and theme: Tesla Autopilot\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "123 - Diarizing podcast 17 with guest: Greg Brockman and theme: OpenAI and AGI\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "124 - Diarizing podcast 16 with guest: Eric Weinstein and theme: Revolutionary Ideas in Science, Math, and Society\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "125 - Diarizing podcast 15 with guest: Leslie Kaelbling and theme: Reinforcement Learning, Planning, and Robotics\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "126 - Diarizing podcast 14 with guest: Kyle Vogt and theme: Cruise Automation\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "127 - Diarizing podcast 13 with guest: Tomaso Poggio and theme: Brains, Minds, and Machines\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "128 - Diarizing podcast 12 with guest: Tuomas Sandholm and theme: Poker and Game Theory\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 - Diarizing podcast 11 with guest: Juergen Schmidhuber and theme: Godel Machines, Meta-Learning, and LSTMs\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "130 - Diarizing podcast 10 with guest: Pieter Abbeel and theme: Deep Reinforcement Learning\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "131 - Diarizing podcast 9 with guest: Stuart Russell and theme: Long-Term Future of Artificial Intelligence\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "132 - Diarizing podcast 8 with guest: Eric Schmidt and theme: Google\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "133 - Diarizing podcast 7 with guest: Jeff Atwood and theme: Stack Overflow and Coding Horror\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "134 - Diarizing podcast 6 with guest: Guido van Rossum and theme: Python\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "135 - Diarizing podcast 5 with guest: Vladimir Vapnik and theme: Statistical Learning\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "136 - Diarizing podcast 4 with guest: Yoshua Bengio and theme: Deep Learning\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "137 - Diarizing podcast 3 with guest: Steven Pinker and theme: AI in the Age of Reason\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "138 - Diarizing podcast 2 with guest: Christof Koch and theme: Consciousness\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n",
      "139 - Diarizing podcast 1 with guest: Max Tegmark and theme: Life 3.0\n",
      "Download Youtube audio into a wav file...\n",
      "Audio preprocessing...\n",
      "Spectral clustering...\n",
      "Getting the predictions in a segmented [[start_time, speaker]] format...\n",
      "Generating diarized transcript...\n",
      "Completed this transcription.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Buggy_Podcasts = []\n",
    "for i in range(len(URLs)):\n",
    "    \n",
    "    #Getting podcast details\n",
    "    local_url, local_duration_in_seconds, local_guest, local_podcast_number, local_theme, \\\n",
    "                        local_filename = Get_Podcast_Details(URLs[i], Times_In_Seconds[i], Titles[i])\n",
    "    \n",
    "    if not os.path.exists(str('Diarization/Transcripts/' + str(local_filename + '.txt'))): ## If transcript has not already been generated:\n",
    "    \n",
    "        try:\n",
    "\n",
    "            YouTubeTranscriptApi.get_transcript(local_url.split('v=')[1]) ## Check if Youtube Transcript exists\n",
    "\n",
    "            print(i, '- Diarizing podcast', local_podcast_number, 'with guest:', local_guest, 'and theme:', local_theme)\n",
    "\n",
    "            print('Download Youtube audio into a wav file...')\n",
    "            youtube_download_options, local_file_path = Get_Youtube_Download_Parameters(local_filename) #This get the download parameters\n",
    "            with youtube_dl.YoutubeDL(youtube_download_options) as ydl:\n",
    "                ydl.download([local_url])\n",
    "\n",
    "            print('Audio preprocessing...')\n",
    "            local_embedding = Audio_File_Processing(local_filename) \n",
    "            Save_As_Pickle(local_embedding, 'Diarization/Embeddings/', local_filename)\n",
    "\n",
    "            print('Spectral clustering...')\n",
    "            local_prediction = Spectral_Clustering(local_embedding)\n",
    "            Save_As_Pickle(local_prediction, 'Diarization/Clustering_Predictions/', local_filename)\n",
    "            del local_embedding ##Deleting variables to free up memory\n",
    "\n",
    "            print('Getting the predictions in a segmented [[start_time, speaker]] format...')\n",
    "            segmented_time_and_speaker = From_Clustering_To_Time_And_Speaker_Segmenting(local_prediction, local_duration_in_seconds)\n",
    "            Save_As_Pickle(segmented_time_and_speaker, 'Diarization/Segmented/', local_filename)\n",
    "\n",
    "            print('Generating diarized transcript...')\n",
    "            Diarize_Transcript(segmented_time_and_speaker, local_url, local_guest, 'Diarization/Transcripts/', local_filename)\n",
    "\n",
    "            print('Completed this transcription.')\n",
    "\n",
    "        except:\n",
    "            print('----Could not generate transcript of podcast:', local_podcast_number, 'with guest:', local_guest)\n",
    "            print('----This is likely because there was no available youtube transcript of this podcast')\n",
    "            Buggy_Podcasts.append(Titles[i])\n",
    "        print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lisa Feldman Barrett: Love, Evolution, and the Human Brain | Lex Fridman Podcast #140 ', 'Andrew Huberman: Neuroscience of Optimal Performance | Lex Fridman Podcast #139 ', 'Yaron Brook: Ayn Rand and the Philosophy of Objectivism | Lex Fridman Podcast #138 ', 'Alex Filippenko: Supernovae, Dark Energy, Aliens &amp; the Expanding Universe | Lex Fridman Podcast #137 ', 'Dan Carlin: Hardcore History | Lex Fridman Podcast #136 ', 'Charles Isbell: Computing, Interactive AI, and Race in America | Lex Fridman Podcast #135 ', 'Eric Weinstein: On the Nature of Good and Evil, Genius and Madness | Lex Fridman Podcast #134 ', 'Chris Lattner: The Future of Computing and Programming Languages | Lex Fridman Podcast #131 ', 'Stephen Wolfram: Fundamental Theory of Physics, Life, and the Universe | Lex Fridman Podcast #124 ', 'Ben Goertzel: Artificial General Intelligence | Lex Fridman Podcast #103 ', 'Gary Marcus: Toward a Hybrid of Deep Learning and Symbolic AI | Lex Fridman Podcast #43 ', 'Gavin Miller: Adobe Research | Lex Fridman Podcast #23 ']\n"
     ]
    }
   ],
   "source": [
    "print(Buggy_Podcasts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
